"site","date","headline","url_address","text"
"mastery",2018-09-14,"How to Develop a Reusable Framework to Spot-Check Algorithms in Python","https://machinelearningmastery.com/spot-check-machine-learning-algorithms-in-python/","Spot-checking algorithms is a technique in applied machine learning designed to quickly and objectively provide a first set of results on a new predictive modeling problem. Unlike grid searching and other types of algorithm tuning that seek the optimal algorithm or optimal configuration for an algorithm, spot-checking is intended to evaluate a diverse set of algorithms rapidly and provide a rough first-cut result. This first cut result may be used to get an idea if a problem or problem representation is indeed predictable, and if so, the types of algorithms that may be worth investigating further for the problem. Spot-checking is an approach to help overcome the ¡°hard problem¡± of applied machine learning and encourage you to clearly think about the higher-order search problem being performed in any machine learning project. In this tutorial, you will discover the usefulness of spot-checking algorithms on a new predictive modeling problem and how to develop a standard framework for spot-checking algorithms in python for classification and regression problems. After completing this tutorial, you will know: Let¡¯s get started. How to Develop a Reusable Framework for Spot-Check Algorithms in PythonPhoto by Jeff Turner, some rights reserved. This tutorial is divided into five parts; they are: We cannot know beforehand what algorithms will perform well on a given predictive modeling problem. This is the hard part of applied machine learning that can only be resolved via systematic experimentation. Spot-checking is an approach to this problem. It involves rapidly testing a large suite of diverse machine learning algorithms on a problem in order to quickly discover what algorithms might work and where to focus attention. Spot-checking may require that you work with a small sample of your dataset in order to turn around results quickly. Finally, the results from spot checking are a jumping-off point. A starting point. They suggest where to focus attention on the problem, not what the best algorithm might be. The process is designed to shake you out of typical thinking and analysis and instead focus on results. You can learn more about spot-checking in the post: Now that we know what spot-checking is, let¡¯s look at how we can systematically perform spot-checking in Python. In this section we will build a framework for a script that can be used for spot-checking machine learning algorithms on a classification or regression problem. There are four parts to the framework that we need to develop; they are: Let¡¯s take a look at each in turn. The first step of the framework is to load the data. The function must be implemented for a given problem and be specialized to that problem. It will likely involve loading data from one or more CSV files. We will call this function load_data(); it will take no arguments and return the inputs (X) and outputs (y) for the prediction problem. The next step is to define the models to evaluate on the predictive modeling problem. The models defined will be specific to the type predictive modeling problem, e.g. classification or regression. The defined models should be diverse, including a mixture of: Each model should be a given a good chance to perform well on the problem. This might be mean providing a few variations of the model with different common or well known configurations that perform well on average. We will call this function define_models(). It will return a dictionary of model names mapped to scikit-learn model object. The name should be short, like ¡®svm¡® and may include a configuration detail, e.g. ¡®knn-7¡¯. The function will also take a dictionary as an optional argument; if not provided, a new dictionary is created and populated. If a dictionary is provided, models are added to it. This is to add flexibility if you would like to have multiple functions for defining models, or add a large number of models of a specific type with different configurations. The idea is not to grid search model parameters; that can come later. Instead, each model should be given an opportunity to perform well (i.e. not optimally). This might mean trying many combinations of parameters in some cases, e.g. in the case of gradient boosting. The next step is the evaluation of the defined models on the loaded dataset. The scikit-learn library provides the ability to pipeline models during evaluation. This allows the data to be transformed prior to being used to fit a model, and this is done in a correct way such that the transforms are prepared on the training data and applied to the test data. We can define a function that prepares a given model prior to evaluation to allow specific transforms to be used during the spot checking process. They will be performed in a blanket way to all models. This can be useful to perform operations such as standardization, normalization, and feature selection. We will define a function named make_pipeline() that takes a defined model and returns a pipeline. Below is an example of preparing a pipeline that will first standardize the input data, then normalize it prior to fitting the model. This function can be expanded to add other transforms, or simplified to return the provided model with no transforms. Now we need to evaluate a prepared model. We will use a standard of evaluating models using k-fold cross-validation. The evaluation of each defined model will result in a list of results. This is because 10 different versions of the model will have been fit and evaluated, resulting in a list of k scores. We will define a function named evaluate_model() that will take the data, a defined model, a number of folds, and a performance metric used to evaluate the results. It will return the list of scores. The function calls make_pipeline() for the defined model to prepare any data transforms required, then calls the cross_val_score() scikit-learn function. Importantly, the n_jobs<U+00A0>argument is set to -1 to allow the model evaluations to occur in parallel, harnessing as many cores as you have available on your hardware. It is possible for the evaluation of a model to fail with an exception. I have seen this especially in the case of some<U+00A0>models from the statsmodels library. It is also possible for the evaluation of a model to result in a lot of warning messages. I have seen this especially in the case of using XGBoost models. We do not care about exceptions or warnings when spot checking. We only want to know what does work and what works well. Therefore, we can trap exceptions and ignore all warnings when evaluating each model. The function named robust_evaluate_model() implements this behavior. The evaluate_model() is called in a way that traps exceptions and ignores warnings. If an exception occurs and no result was possible for a given model, a None result is returned. Finally, we can define the top-level function for evaluating the list of defined models. We will define a function named evaluate_models() that takes the dictionary of models as an argument and returns a dictionary of model names to lists of results. The number of folds in the cross-validation process can be specified by an optional argument that defaults to 10. The metric calculated on the predictions from the model can also be specified by an optional argument and defaults to classification accuracy. For a full list of supported metrics, see this list: Any None results are skipped and not added to the dictionary of results. Importantly, we provide some verbose output, summarizing the mean and standard deviation of each model after it was evaluated. This is helpful if the spot checking process on your dataset takes minutes to hours. Note that if for some reason you want to see warnings and errors, you can update the evaluate_models() to call the evaluate_model() function directly, by-passing the robust error handling. I find this useful when testing out new methods or method configurations that fail silently. Finally, we can evaluate the results. Really, we only want to know what algorithms performed well. Two useful ways to summarize the results are: The line summaries are quick and precise, although assume a well behaving Gaussian distribution, which may not be reasonable. The box and whisker plots assume no distribution and provide a visual way to directly compare the distribution of scores across models in terms of median performance and spread of scores. We will define a function named summarize_results() that takes the dictionary of results, prints the summary of results, and creates a boxplot image that is saved to file. The function takes an argument to specify if the evaluation score is maximizing, which by default is True. The number of results to summarize can also be provided as an optional parameter, which defaults to 10. The function first orders the scores before printing the summary and creating the box and whisker plot. Now that we have specialized a framework for spot-checking algorithms in Python, let¡¯s look at how we can apply it to a classification problem. We will generate a binary classification problem using the make_classification() function. The function will generate 1,000 samples with 20 variables, with some redundant variables and two classes. As a classification problem, we will try a suite of classification algorithms, specifically: I tried LDA and QDA, but they sadly crashed down in the C-code somewhere. Further, I added multiple configurations for a few of the algorithms like Ridge, kNN, and SVM in order to give them a good chance on the problem. The full define_models() function is listed below. That¡¯s it; we are now ready to spot check algorithms on the problem. The complete example is listed below. Running the example prints one line per evaluated model, ending with a summary of the top 10 performing algorithms on the problem. We can see that ensembles of decision trees performed the best for this problem. This suggests a few things: A box and whisker plot is also created to summarize the results of the top 10 well performing algorithms. The plot shows the elevation of the methods comprised of ensembles of decision trees. The plot enforces the notion that further attention on these methods would be a good idea. Boxplot of top 10 Spot-Checking Algorithms on a Classification Problem If this were a real classification problem, I would follow-up with further spot checks, such as: Next, we will see how we can apply the framework to a regression problem. We can explore the same framework for regression predictive modeling problems with only very minor changes. We can use the make_regression() function to generate a contrived regression problem with 1,000 examples and 50 features, some of them redundant. The defined load_dataset() function is listed below. We can then specify a get_models() function that defines a suite of regression methods. Scikit-learn does offer a wide range of linear regression methods, which is excellent. Not all of them may be required on your problem. I would recommend a minimum of linear regression and elastic net, the latter with a good suite of alpha and lambda parameters. Nevertheless, we will test the full suite of methods on this problem, including: The full get_models() function is listed below. By default, the framework uses classification accuracy as the method for evaluating model predictions. This does not make sense for regression, and we can change this something more meaningful for regression, such as mean squared error. We can do this by passing the metric=¡¯neg_mean_squared_error¡¯ argument when calling evaluate_models() function. Note that by default scikit-learn inverts error scores so that that are maximizing instead of minimizing. This is why the mean squared error is negative and will have a negative sign when summarized. Because the score is inverted, we can continue to assume that we are maximizing scores in the summarize_results() function and do not need to specify maximize=False as we might expect when using an error metric. The complete code example is listed below. Running the example summarizes the performance of each model evaluated, then prints the performance of the top 10 well performing algorithms. We can see that many of the linear algorithms perhaps found the same optimal solution on this problem. Notably those methods that performed well use regularization as a type of feature selection, allowing them to zoom in on the optimal solution. This would suggest the importance of feature selection when modeling this problem and that linear methods would be the area to focus, at least for now. Reviewing the printed scores of evaluated models also shows how poorly nonlinear and ensemble algorithms performed on this problem. A box and whisker plot is created, not really adding value to the analysis of results in this case. Boxplot of top 10 Spot-Checking Algorithms on a Regression Problem In this section, we explore some handy extensions of the spot check framework. I find myself using XGBoost and gradient boosting a lot for straight-forward classification and regression problems. As such, I like to use a course grid across standard configuration parameters of the method when spot checking. Below is a function to do this that can be used directly in the spot checking framework. By default, the function will use XGBoost models, but can use the sklearn gradient boosting model if the use_xgb argument to the function is set to False. Again, we are not trying to optimally tune GBM on the problem, only very quickly find an area in the configuration space that may be worth investigating further. This function can be used directly on classification and regression problems with only a minor change from ¡°XGBClassifier¡± to ¡°XGBRegressor¡± and ¡°GradientBoostingClassifier¡± to ¡°GradientBoostingRegressor¡°. For example: To make this concrete, below is the binary classification example updated to also define XGBoost models. Running the example shows that indeed some XGBoost models perform well on the problem. Boxplot of top 10 Spot-Checking Algorithms on a Classification Problem with XGBoost The above results also highlight the noisy nature of the evaluations, e.g. the results of extra trees in this run are different from the run above (0.858 vs 0.869). We are using k-fold cross-validation to produce a population of scores, but the population is small and the calculated mean will be noisy. This is fine as long as we take the spot-check results as a starting point and not definitive results of an algorithm on the problem. This is hard to do; it takes discipline in the practitioner. Alternately, you may want to adapt the framework such that the model evaluation scheme better matches the model evaluation scheme you intend to use for your specific problem. For example, when evaluating stochastic algorithms like bagged or boosted decision trees, it is a good idea to run each experiment multiple times on the same train/test sets (called repeats) in order to account for the stochastic nature of the learning algorithm. We can update the evaluate_model() function to repeat the evaluation of a given model n-times, with a different split of the data each time, then return all scores. For example, three repeats of 10-fold cross-validation will result in 30 scores from each to calculate a mean performance of a model. Alternately, you may prefer to calculate a mean score from each k-fold cross-validation run, then calculate a grand mean of all runs, as described in: We can then update the robust_evaluate_model() function to pass down the repeats argument and the evaluate_models() function to define a default, such as 3. A complete example of the binary classification example with three repeats of model evaluation is listed below. Running the example produces a more robust estimate of the scores. There will still be some variance in the reported means, but less than a single run of k-fold cross-validation. The number of repeats may be increased to further reduce this variance, at the cost of longer run times, and perhaps against the intent of spot checking. I am a big fan of avoiding assumptions and recommendations for data representations prior to fitting models. Instead, I like to also spot-check multiple representations and transforms of input data, which I refer to as views. I explain this more in the post: We can update the framework to spot-check multiple different representations for each model. One way to do this is to update the evaluate_models() function so that we can provide a list of make_pipeline() functions that can be used for each defined model. The chosen pipeline function can then be passed along down to the robust_evaluate_model() function and to the evaluate_model() function where it can be used. We can then define a bunch of different pipeline functions; for example: Then create a list of these function names that can be provided to the evaluate_models() function. The complete example of the classification case updated to spot check pipeline transforms is listed below. Running the example shows that we differentiate the results for each pipeline by adding the pipeline number to the beginning of the algorithm description name, e.g. ¡®0rf¡® means RF with the first pipeline, which is no transforms. The ensembles of trees algorithms perform well on this problem, and these algorithms are invariant to data scaling. This means that their results on each pipeline will be similar (or the same) and in turn they will crowd out other algorithms in the top-10 list. This section provides more resources on the topic if you are looking to go deeper. In this tutorial, you discovered the usefulness of spot-checking algorithms on a new predictive modeling problem and how to develop a standard framework for spot-checking algorithms in python for classification and regression problems. Specifically, you learned: Have you used this framework or do you have some further suggestions to improve it?
Let me know in the comments. Do you have any questions?
Ask your questions in the comments below and I will do my best to answer. ¡¦with just a few lines of scikit-learn code Discover how in my new Ebook:Machine Learning Mastery With Python Covers self-study tutorials and end-to-end projects like:Loading data, visualization, modeling, tuning, and much more¡¦ Skip the Academics. Just Results. Click to learn more. hi Jason,
have you tried using the autoML tools such as autoKeras & Auto-sklearn packages?
(I¡¯ve also used AutoWeka in the weka package <U+2013> very limited, and Rapidminer Auto-Modelling). I generally don¡¯t use them. Have you? Is this possible in R? Yes, with the caret package. I even have examples on the blog, search ¡°spot check¡±. This is truly one of the best resources for ML on the web Thanks, I¡¯m happy it helps. Hello Sir,  Awesome post on spot checking algorithm. This is really a great one <U+2013> one stop shop! I have couple of basic questions here <U+2013>  1) How the similar approach along with pipeline can be applied to different Keras models -sequential, functional and KerasRegressor/KerasClassifier (with layers/dropouts/optimizers etc.)?  2) Do we need to reset states/layers in evaluate models prior to build/apply pipeline? 3) Post evaluation and finalizing the model, do we need to rebuild model, compile, fit to predict the test dataset or use the existing compiled model to fit and predict? Will predicted values/scores vary for each runs due to different weight initializations? Thanking you in anticipation for your response. Neural nets might be too big/slow for this type of framework and you may have to grid search manually. Regardless of model, you should redefine and refit for each eval. A finalized model is refit on all available data. Good well rounded post.
Would really appreciate similar spot checking for (not too deep) neural nets framework in keras or tensorflow. Comment  Name (required)  Email (will not be published) (required)  Website Hi, I'm Jason Brownlee, Ph.D.

My goal is to make developers like YOU awesome at applied machine learning."
"mastery",2018-09-12,"A Gentle Introduction to a Standard Human Activity Recognition Problem","https://machinelearningmastery.com/how-to-load-and-explore-a-standard-human-activity-recognition-problem/","Human activity recognition is the problem of classifying sequences of accelerometer data recorded by specialized harnesses or smart phones into known well-defined movements. It is a challenging problem given the large number of observations produced each second, the temporal nature of the observations, and the lack of a clear way to relate accelerometer data to known movements. Classical approaches to the problem involve hand crafting features from the time series data based on fixed-size windows and training machine learning models, such as ensembles of decision trees. The difficulty is that this feature engineering requires deep expertise in the field. Recently, deep learning methods such as recurrent neural networks and one-dimensional convolutional neural networks or CNNs have been shown to provide state-of-the-art results on challenging activity recognition tasks with little or no data feature engineering. In this tutorial, you will discover a standard human activity recognition dataset for time series classification and how to explore the dataset prior to modeling. After completing this tutorial, you will know: Let¡¯s get started. A Gentle Introduction to a Standard Human Activity Recognition ProblemPhoto by tgraham, some rights reserved. This tutorial is divided into 8 parts; they are: Human Activity Recognition or HAR for short, is the problem of predicting what a person is doing based on a trace of their movement using sensors. Movements are often normal indoor activities such as standing, sitting, jumping, and going up stairs. Sensors are often located on the subject such as a smartphone or vest and often record accelerometer data in three dimensions (x, y, z). The idea is that once the subject¡¯s activity is recognized and known, an intelligent computer system can then offer assistance. It is a challenging problem because there is no clear analytical way to relate the sensor data to specific actions in a general way. It is technically challenging because of the large volume of sensor data collected (e.g. tens or hundreds of observations per second) and the classical use of hand crafted features and heuristics from this data in developing predictive models. More recently, deep learning methods have been achieving success on HAR problems given their ability to automatically learn higher-order features. Sensor-based activity recognition seeks the profound high-level knowledge about human activities from multitudes of low-level sensor readings. Conventional pattern recognition approaches have made tremendous progress in the past years. However, those methods often heavily rely on heuristic hand-crafted feature extraction, which could hinder their generalization performance. [¡¦] Recently, the recent advancement of deep learning makes it possible to perform automatic high-level feature extraction thus achieves promising performance in many areas. <U+2014> Deep Learning for Sensor-based Activity Recognition: A Survey Take my free 7-day email crash course now (with sample code). Click to sign-up and also get a free PDF Ebook version of the course. Download Your FREE Mini-Course The dataset ¡°Activity Recognition from Single Chest-Mounted Accelerometer Data Set¡± was collected and made available by Casale, Pujol, et al. from the University of Barcelona in Spain. It is freely available from the UCI Machine Learning repository: The dataset was described and used as the basis for a sequence classification model in their 2011 paper ¡°Human Activity Recognition from Accelerometer Data Using a Wearable Device¡°. The dataset is comprised of uncalibrated accelerometer data from 15 different subjects, each performing 7 activities. Each subject wore a custom-developed chest-mounted accelerometer and data was collected at 52Hz (52 observations per second). Photographs of the custom chest-mounted systems worn by each subject.Taken from ¡°Human Activity Recognition from Accelerometer Data Using a Wearable Device¡±. The seven activities were performed and recorded by each subject in a continuous sequence. The specific activities performed were: The paper used a subset of the data, specifically 14 subjects and 5 activities. It is not immediately clear why the other 2 activities (2 and 6) were not used. Data have been collected from fourteen testers, three women and eleven men with age between 27 and 35. [¡¦] The data set collected is composed by 33 minutes of walking up/down stairs, 82 minutes of walking, 115 minutes of talking, 44 minutes of staying standing and 86 minutes of working at computer. <U+2014> Human Activity Recognition from Accelerometer Data Using a Wearable Device, 2011. The focus of the paper was the development of hand-crafted features from the data, and the developing of machine learning algorithms. Data was split into windows of one second of observations (52) with a 50% overlap between windows. We extract features from data using windows of 52 samples, corresponding to 1 second of accelerometer data, with 50% of overlapping between windows. From each window, we propose to extract the following features: root mean squared value of integration of acceleration in a window, and mean value of Minmax sums. [¡¦] Still, in order to complete the set of features we add features that have proved to be useful for human activity recognition like: mean value, standard deviation, skewness, kurtosis, correlation between each pairwise of accelerometer axis(not including magnitude), energy of coefficients of seven level wavelet decomposition. In this way, we obtain a 319-dimensional feature vector. <U+2014> Human Activity Recognition from Accelerometer Data Using a Wearable Device, 2011. A suite of machine learning models were fit and evaluated using 5-fold cross-validation and achieved an accuracy of 94%. Confusion Matrix of Random Forest evaluated on the dataset.Taken from ¡°Human Activity Recognition from Accelerometer Data Using a Wearable Device¡±. The dataset can be downloaded directly from the UCI Machine Learning Repository. Unzip the dataset into a new directory called ¡®HAR¡®. The directory contains a list of CSV files, one per subject (1-15) and a readme file. Each file contains 5 columns, the row number, x, y, and z accelerometer readings and a class number from 0 to 7, where class 0 means ¡°no activity¡± and classes 1-7 correspond to the activities listed in the previous section. For example, below are the first 5 rows from the file ¡°1.csv¡°: To get started, we can load each file as a single NumPy array and drop the first column. The function below named load_dataset() will load all CSV files in the HAR directory, drop the first column and return a list of 15 NumPy arrays. The complete example is listed below. Running the example loads all of the data and prints the number of loaded subjects. Note, the files in the directory are navigated in file-order, which may not be the same as the subject order, e.g. 10.csv comes before 2.csv in file order. I believe this does not matter in this tutorial. Now that we know how to load the data, we can explore it with some visualizations. A good first visualization is to plot the data for a single subject. We can create a figure with a plot for each variable for a given subject, including the x, y, and z accelerometer data, and the associated class class values. The function plot_subject() below will plot the data for a given subject. We can tie this together with the data loading in the previous section and plot the data for the first loaded subject. Running the example creates a line plot for each variable for the first loaded subject. We can see some very large movement in the beginning of the sequence that may be an outlier or unusual behavior that could be removed. We can also see that the subject performed some actions multiple times. For example, a closer look at the plot of the class variable (bottom plot) suggests the subject performed activities in the following order, 1, 2, 0, 3, 0, 4, 3, 5, 3, 6, 7. Note that activity 3 was performed twice. Line plots of x, y, z and class for the first loaded subject. We can re-run this code and plot the second loaded subject (which might be 10.csv). Running the example creates a similar plot. We can see more detail, suggesting that the large outlier seen at the beginning of the previous plot might be washing out values from that subject¡¯s trace. We see as similar sequence of activities, with activity 3 occurring twice again. We can also see that some activities are performed for much longer than others. This may impact the ability of a model to discriminate between the activities, e.g. activity 3 (standing) for both subjects has very little data relative to the other activities performed. Line plots of x, y, z and class for the second loaded subject. The previous section raised a question around how long or how many observations we have for each activity across all of the subjects. This may be important if there is a lot more data for one activity than another, suggesting that less-well-represented activities may be harder to model. We can investigate this by grouping all observations by activity and subject, and plot the distributions. This will give an idea of how long each subject spends performing each activity over the course of their trace. First, we can group the activities for each subject. We can do this by creating a dictionary for each subject and store all trace data by activity. The group_by_activity() function below will perform this grouping for each subject. Next, we can calculate the total duration of each activity for each subject. We know that the accelerometer data was recorded at 52Hz, so we can divide the lengths of each trace per activity by 52 in order to summarize the durations in seconds. The function below named plot_durations() will calculate the durations for each activity per subject and plot the results as a boxplot. The box-and-whisker plot is a useful way to summarize the 15 durations per activity as it describes the spread of the durations without assuming a distribution. The complete example of plotting the distribution of activity durations is listed below. Running the example plots the distribution of activity durations per subject. We can see that there is relatively fewer observations for activities 0 (no activity), 2 (standing up, walking and going up/down stairs), 5 (going up/down stairs) and 6 (walking and talking). This might suggest why activities 2 and 6 were excluded from the experiments in the original paper. We can also see that each subject spent a lot of time on activity 1 (standing Up, walking and going up/down stairs) and activity 7 (talking while standing). These activities may be over-represented. There may be benefit in preparing model data that undersamples these activities or over samples the other activities. Boxplot of the distribution of activity durations per subject Next, it may be interesting to look at the trace data for each subject. One approach would be to plot all traces for a single subject on a single graph, then line up all graphs vertically. This will allow for a comparison across subjects and across traces within a subject. The function below named plot_subjects() will plot the accelerometer data for each of the 15 subjects on a separate plot. The trace for each of the x, y, and z data are plotted as orange, green and blue respectively. The complete example is listed below. Running the example creates a figure with 15 plots. We are looking at the general rather than specific trends across the traces. Each subject may have a different full trace length, so direct comparisons by the x-axis may not be reasonable (e.g. performing similar activities at the same time). We are not really concerned with this aspect of the problem anyway. Line plots of accelerometer trace data for all 15 subjects. The traces seem to have the same general scale, but the amplitude differences between the subjects suggest that per-subject rescaling of the data might make more sense than cross-subject scaling. This might make sense for training data, but may be methodologically challenging for scaling the data for a test subject. It would require or assume that the entire trace would be available prior to predicting activities. This would be fine for offline use of a model, but not-online use of the model. It also suggests, that online use of a model might be a lot easier with pre-calibrated trace data (e.g. data coming in at a fixed scale). The point in the previous section about the possibility of markedly different scales across the different subjects might introduce challenges in modeling this dataset. We can explore this by plotting a histogram of the distribution of observations for each axis of accelerometer data. As with the previous section, we can create a plot for each subject, then align the plots for all subjects vertically with the same x-axis to help spot obvious differences in the spreads. The updated plot_subjects() function for plotting histograms instead of line plots is listed below. The hist() function is used to create a histogram for each axis of accelerometer data, and a large number of bins (100) is used to help spread out the data in the plot. The subplots also all share the same x-axis to aid in the comparison. The complete example is listed below Running the example creates a single figure with 15 plots, one for each subject, and 3 histograms on each plot for each of the 3 axis of accelerometer data. The three colors blue, orange and green represent the x, y and z axises. This plot suggest that the distribution of each axis of accelerometer is Gaussian or really close to Gaussian. This may help with simple outlier detection and removal along each axis of the accelerometer data. The plot really helps to show both the relationship between the distributions within a subject and differences in the distributions between the subjects. Within each subject, a common pattern is for the x (blue) and z (green) are grouped together to the left and y data (orange) is separate to the right. The distribution of y is often sharper where as the distributions of x and z are flatter. Across subjects, we can see a general clustering of values around 2,000 (whatever the units are), although with a lot of spread. This marked difference in distributions does suggest the need to at least standardize (shift to zero mean and unit variance) the data per axis and per subject before any cross-subject modeling is performed. Histograms of accelerometer data for each subject In this section we will explore some ideas and approaches for data preparation and modeling for this problem based on the above exploration of the dataset. These may help in both modeling this dataset in particular, but also human activity recognition and even time series classification problems in general. There are many ways to frame the data as a predictive modeling problem, although all center around the idea of time series classification. Two main approaches to consider are: The latter, cross-subject, is more desirable, but the former may also be interesting if the goal is to deeply understand a given subject, e.g. a personalized model within a home. Two main approaches for framing the data during modeling include: The former approach may be less realistic in terms of the actual use of the model, but may be an easier problem to model. The latter was the framing of the problem used in the original paper, where 1-second windows were prepared with a 50% overlap. I fail to see the benefit of the overlap in the framing of the problem, other than doubling the size of the training dataset, that may benefit deep neural networks. In fact, I expect it may result in an overfit model. The data suggest some preparation schemes that may be helpful during modeling: As noted in a previous section, the standardization of data per-subject does introduce methodological issues, and may be used regardless, defended as the need for calibrated observations from the original hardware system. I would recommend exploring this problem using neural networks. Unlike the approach used in the paper that used feature engineering and domain-specific hand-crafted features, it would be useful and general to model the raw data directly (downsampled or otherwise). First, I¡¯d recommend discovering a baseline in performance using a robust method such as random forest or gradient boosting machines. Then explore neural network approaches specifically suited to time series classification problems. Two types of neural network architectures that might be appropriate are: A third is a hybrid of the two: CNNs are able to extract features from input sequences, such as windows of input accelerometer data. RNNs, such as LSTMs are able to learn from long sequences of input data directly, and learn long-term relationships in the data. I would expect there is little causal relationship in the sequence data, other than each subject looks like they are performing the same artificial sequence of actions, which we would not want to learn. Naively, this might suggest that CNNs would be a better fit for predicting the activity given a sequence of observed accelerometer data. One-dimensional CNNs have been widely used for this type of problem, with one channel for each axis of the accelerometer data. A good simple starting point would be to fit a CNN model on windows of sequence data directly. This is the approach described in the 2014 paper titled ¡°Convolutional Neural Networks for Human Activity Recognition using Mobile Sensors¡°, and made clearer with the figure below taken from the paper. Example of 1D CNN Architecture for Human Activity RecognitionTaken from ¡°Convolutional Neural Networks for Human Activity Recognition using Mobile Sensors¡±. A CNN LSTM could be used where the CNN learns a representation for a sub-sequence of observations, then the LSTM learns across these subsequences. For example, a CNN could distill one second of accelerometer data, this could then be repeated for 30 seconds, to provide 30 time steps of CNN-interpreted data to the LSTM. I¡¯d expect all three approaches may be interesting on this problem and problems like it. I don¡¯t expect overlapping of the windows would be useful, and in fact might result in minor misleading results if portions of the trace data is available in both train and test dataset during cross-validation. Nevertheless, it would increase the amount of training data. I think it is important that the data are exposed to the model while maintaining the temporal ordering of the observations. It is possible that multiple windows from a single activity will look similar for a given subject and a random shuffling and separation of windows to train an test data may lead to misleading results. I would not recommend randomly shuffled k-fold cross-validation was was used in the original paper. I expect that this would lead to optimistic results, with one-second windows of data from all across each the traces of the 15 subjects mixed together for training and testing. Perhaps a fair evaluation of models in this data would be to use leave-one-out cross validation or LOOCV by subject. This is where a model is fit on the first 14 subjects and evaluated on all windows of the 15th subject. This process is repeated where each subject is given a chance to be used as the hold-out test dataset. The segmentation of the dataset by subject avoids any issues related to the temporal ordering of individual windows during model evaluation as all windows will are guaranteed new/unseen data. If you explore any of these modeling ideas, I¡¯d love to know. This section provides more resources on the topic if you are looking to go deeper. In this tutorial, you discovered a standard human activity recognition dataset for time series classification. Specifically, you learned: Do you have any questions?
Ask your questions in the comments below and I will do my best to answer. ¡¦with just a few lines of python code Discover how in my new Ebook:Deep Learning for Time Series Forecasting It provides self-study tutorials on topics like: CNNs, LSTMs,Multivariate Forecasting, Multi-Step Forecasting and much more¡¦ Skip the Academics. Just Results. Click to learn more. Comment  Name (required)  Email (will not be published) (required)  Website Hi, I'm Jason Brownlee, Ph.D.

My goal is to make developers like YOU awesome at applied machine learning."
"mastery",2018-09-10,"Indoor Movement Time Series Classification with Machine Learning Algorithms","https://machinelearningmastery.com/indoor-movement-time-series-classification-with-machine-learning-algorithms/","Indoor movement prediction involves using wireless sensor strength data to predict the location and motion of subjects within a building. It is a challenging problem as there is no direct analytical model to translate the variable length traces of signal strength data from multiple sensors into user behavior. The ¡®indoor user movement¡® dataset is a standard and freely available time series classification problem. In this tutorial, you will discover the indoor movement prediction time series classification problem and how to engineer features and evaluate machine learning algorithms for the problem. After completing this tutorial, you will know: Let¡¯s get started. Indoor Movement Time Series Classification with Machine Learning AlgorithmsPhoto by Nola Tularosa, some rights reserved. This tutorial is divided into five parts; they are: The ¡®indoor user movement¡® prediction problem involves determining whether an individual has moved between rooms based on the change in signal strength measured by wireless detectors in the environment. The dataset was collected and made available by Davide Bacciu, et al. from the University of Pisa in Italy and first described in their 2011 paper ¡°Predicting User Movements in Heterogeneous Indoor Environments by Reservoir Computing¡± as a dataset for exploring a methodology that seems like recurrent neural networks called ¡®reservoir computing.¡¯ The problem is a special case of the more generic problem of predicting indoor user localization and movement patterns. Data was collected by positioning four wireless sensors in the environment and one on the subject. The subject moved through the environment while the four wireless sensors detected and recorded a time series of sensor strength. The result is a dataset comprised of variable length time series with four variates describing trajectory through a well-defined static environment, and the classification of whether the movement led to the subject changing rooms in the environment. It is a challenging problem because there is no obvious and generic way to relate signal strength data to subject location in an environment. The relationship between the RSS and the location of the tracked object cannot be easily formulated into an analytical model, as it strongly depends on the characteristics of the environment as well as on the wireless devices involved. I <U+2014> Predicting User Movements in Heterogeneous Indoor Environments by Reservoir Computing, 2011. The data was collected under controlled experimental conditions. Sensors were placed in three pairs of two connected rooms containing typical office furniture. Two sensors were placed in the corners of each of the two rooms and the subject walked one of six predefined paths through the rooms. Predictions are made at a point along each path that may or may not lead to a change of room. The cartoon below makes this clear, showing the sensor locations (A1-A4), the six possible paths that may be walked, and the two points (M) where a prediction will be made. Overview of two rooms, sensor locations and the 6 pre-defined paths.Taken from ¡°Predicting User Movements in Heterogeneous Indoor Environments by Reservoir Computing.¡± Three datasets were collected from the three pairs of two rooms in which the paths were walked and sensor measurements taken, referred to as Dataset 1, Dataset 2, and Dataset 3. The table below, taken from the paper, summarizes the number of paths walked in each of the three datasets, the total number of room changes and non-room-changes (class label), and the lengths of the time series inputs. Summary of sensor data collected from the three pairs of two rooms.Taken from ¡°Predicting User Movements in Heterogeneous Indoor Environments by Reservoir Computing.¡± Technically, the data is comprised of multivariate time series inputs and a classification output and may be described as a time series classification problem. The RSS values from the four anchors are organized into sequences of varying length corresponding to trajectory measurements from the starting point until marker M. A target classification label is associated to each input sequence to indicate whether the user is about to change its location (room) or not. <U+2014> Predicting User Movements in Heterogeneous Indoor Environments by Reservoir Computing, 2011. Take my free 7-day email crash course now (with sample code). Click to sign-up and also get a free PDF Ebook version of the course. Download Your FREE Mini-Course The dataset is freely available from the UCI Machine Learning Repository: The data can be downloaded as a .zip file that contains the following salient files: The provided data is already normalized. Specifically, each input variable is normalized into the range [-1,1] per dataset (pair of rooms), and the output class variable is marked -1 for no transition between rooms and +1 for a transition through the rooms. [¡¦] put data comprises time series of 4 dimensional RSS measurements (NU = 4) corresponding to the 4 anchors [¡¦] normalized in the range [<U+2212>1, 1] independently for each dataset <U+2014> Predicting User Movements in Heterogeneous Indoor Environments by Reservoir Computing, 2011. The scaling of data by dataset may (or may not) introduce additional challenges when combining observations across datasets if the pre-normalized distributions differ greatly. The time series for one trace in a given trace file are provided in temporal order, where one row records the observations for a single time step. The data is recorded at 8Hz, meaning that one second of clock time elapses for eight time steps in the data. Below is an example of a trace, taken from ¡®dataset/MovementAAL_RSS_1.csv¡®, which has the output target ¡®1¡¯ (a room transition occurred), from group 1 (the first pair of rooms) and is the path 1 (a straight shot from left to right between the rooms). The datasets were used in two specific ways (experimental settings or ES) to evaluate predictive models on the problem, designated ES1 and ES2, as described in the first paper. The ES1 case evaluates a model to generalize movement within two pairs of known rooms, that is, rooms with known geometry. The ES2 case attempts to generalize movement from two rooms to a third unseen room: a harder problem. The 2011 paper, reports performance of about 95% classification accuracy on ES1 and about 89% on ES2, which after some testing of a suite of algorithms myself is very impressive. In this section, we will load the data into memory and explore it with summarization and visualization to help better understand how the problem might be modeled. First, download the dataset and unzip the downloaded archive into your current working directory. The targets, groups, and path files can be loaded directly as Pandas DataFrames. The signal strength traces are stored in separate files in the dataset/ directory. These can be loaded by iterating over all files in the directory and loading the sequences as directly. Because each sequence has a variable length (variable number of rows), we can store the NumPy array for each trace in a list. We can tie all of this together into a function named load_dataset() and load the data into memory. The complete example is listed below. Running the example loads the data and shows that 314 traces were correctly loaded from disk along with their associated outputs (targets as -1 or +1), dataset number, (group as 1, 2 or 3) and path number (path as 1-6). We can now take a closer look at the loaded data to better understand or confirm our understanding of the problem. We know from the paper that the dataset is reasonably balanced in terms of the two classes. We can confirm this by summarizing the class breakdown of all observations. Next, we can review the distribution of the sensor strength values for each of the four anchor points by plotting a histogram of the raw values. This requires that we create one array with all rows of observations so that we can plot the distribution of each column. The vstack() NumPy function will do this job for us. Finally, another interesting aspect to look at is the distribution of the length of the traces. We can summarize this distribution using a histogram. Putting this all together, the complete example of loading and summarizing the data is listed below. Running the example first summarizes the class distribution for the observations. The results confirm our expectations of the full dataset being nearly perfectly balanced in terms of observations of both class outcomes. Next, a histogram of the sensor strength for each anchor point is created, summarizing the data distributions. We can see that the distributions for each variable are close to normal showing Gaussian-like shapes. We can also see perhaps too many observations around -1. This might indicate a generic ¡°no strength¡± observation that could be marked or even filtered out from the sequences. It might be interesting to investigate whether the distributions change by path type or even dataset number. Histograms for the sensor strength values for each anchor point Finally, a histogram of the sequence lengths is created. We can see clusters of sequences with lengths around 25, 40, and 60. We can also see that if we wanted to trim long sequences that a maximum length of around 70 time steps might be appropriate. The smallest length appears to be 19. Histogram of sensor strength sequence lengths We are working with time series data, so it is important that we actually review some examples of the sequences. We can group traces by their path and plot an example of one trace for each path. The expectation is that traces for different paths may look different in some way. We can also plot each series from one trace along with the trend predicted by a linear regression model. This will make any trends in the series obvious. We can fit a linear regression for a given series using the lstsq() NumPy Function. The function regress() below takes a series as a single variable, fits a linear regression model via least squares, and predicts the output for each time step returning a sequence that captures the trend in the data. We can use the function to plot the trend for the time series for each variable in a single trace. Tying all of this together, the complete example is listed below. Running the example creates a plot containing six figures, one for each of the six paths. A given figure shows the line plots of a single trace with the four variables of the trace, one for each anchor point. Perhaps the chosen traces are representative of each path, perhaps not. We can see some clear differences with regards to: Ideally, if these changes in behavior are predictive, a predictive model must extract these features, or be presented with a summary of these features as input. Line plots of one trace (4 variables) for each of the six paths. A second plot is created showing the line plots for the four series in a single trace along with the trend lines. We can see that, at least for this trace, there is a clear trend in the sensor strength data as the user moves around the environment. This may suggest the opportunity to make the data stationary prior to modeling or using the trend for each series in a trace (observations or coefficients) as inputs to a predictive model. Line plots for the time series in a single trace with trend lines There are many ways to fit and evaluate a model on this data. Classification accuracy seems like a good first-cut evaluation metric given the balance of the classes. More nuance can be sought in the future by predicting probabilities and exploring thresholds on an ROC curve. I see two main themes in using this data: The ES1 and ES2 cases described in the paper and summarized above explore these questions and provide a useful starting point. First, we must partition the loaded traces and targets into the three groups. In the case of ES1, we can use k-fold cross-validation where k=5 to use the same ratio from the paper and the repeated evaluation provides some robustness to the evaluation. We can use the cross_val_score() function from scikit-learn to evaluate a model and then calculate the mean and standard deviation of the scores. In the case of ES2, we can fit the model on datasets 1 and 2 and test model skill on dataset 3 directly. There is flexibility in how the input data is framed for the prediction problem. Two approaches come to mind: Both are interesting approaches. As a first pass, we will prepare the more traditional fixed-length vector input via manual feature engineering. Below are some ideas on features that could be included in the vector: Additionally, data scaling is probably not required of the raw values as the data has already been scaled to the range -1 to 1. Scaling may be required if new features are added with different units. Some of the variables do show some trend, suggesting that perhaps a differencing of the variables may help in teasing out a signal. The distribution of each variable is nearly Gaussian, so some algorithms may benefit from standardization, or perhaps even a Box-Cox transform. In this section, we will spot-check the default configuration for a suite of standard machine learning algorithms with different sets of engineered features. Spot-checking is a useful technique to flush out quickly whether there is any signal to be learned in the mapping between inputs and outputs with engineered features as most of the tested methods will pick something up. The method can also suggest methods that might be worth further investigating. A downside is that each method is not given its best chance (configuration) to show what it can do on the problem, meaning any methods that are further investigated will be biased by the first results. In these tests, we will look at a suite of six different types of algorithms, specifically: We will test the default configurations of these methods on features that focus on the end of the time series variables as they are likely the most predictive of whether a room transition will occur or not. The last n observations are likely to be predictive of whether the movement leads to a transition in rooms. The smallest number of time steps in the trace data is 19, therefore, we will use n=19 as a starting point. The function below named create_dataset() will create a fixed-length vector using the last n observations from each trace in a flat one-dimensional vector, then add the target as the last element of the vector. This flattening of the trace data is required for simple machine learning algorithms. We can load the dataset as before and sort it into the datasets 1, 2, and 3 as described in the ¡°Model Evaluation¡± section. We can then call the create_dataset() function to create the datasets required for the ES1 and ES2 cases, specifically ES1 combines datasets 1 and 2, whereas ES2 uses datasets 1 and 2 as a training set and dataset 3 as a test set. The complete example is listed below. Running the example creates three new CSV files, specifically ¡®es1.csv¡®, ¡®es2_train.csv¡®, and ¡®es2_test.csv¡® for the ES1 and ES2 cases respectively. The shapes of these datasets are also summarized. Next, we can evaluate models on the ES1 dataset. After some testing, it appears that standardizing the dataset results in better model skill for those methods that rely on distance values (KNN and SVM) and generally has no effect on other methods. Therefore a Pipeline is used to evaluate each algorithm that first standardizes the dataset. The complete example of spot checking algorithms on the new dataset is listed below. Running the example prints the estimated performance of each algorithm, including the mean and standard deviation over 5-fold cross-validation. The results suggest SVM might be worth looking at in more detail at 58% accuracy. The results are also presented as box-and-whisker plots showing the distribution of scores. Again, SVM appears to have good average performance and tight variance. Spot-check Algorithms on ES1 with last 19 observations We can pad each trace to a fixed length. This will then provide the flexibility to include more of the prior n observations in each sequence. The choice of n must also be balanced with the increase in padded values added to shorter sequences that in turn may negatively impact the performance of the model on those sequences. We can pad each sequence by adding the 0.0 value to the beginning of each variable sequence until a maximum length, e.g. 200 time steps, is reached. We can do this using the pad() NumPy function. The updated version of the create_dataset() function with padding support is below. We will try n=25 to include 25 of the last observations in each sequence in each vector. This value was found with a little trial and error, although you may want to explore whether other configurations result in better skill. Running the script again with the new function creates updated CSV files. Again, re-running the spot-check script on the data results in a small lift in model skill for SVM and also suggests that KNN might be worth investigating further. The box plots for KNN and SVM show good performance and relatively tight standard deviations. Spot-check Algorithms on ES1 with last 25 observations We can update the spot-check to grid search a suite of k values for the KNN algorithm to see if the skill of the model can be further improved with a little tuning. The complete example is listed below. Running the example prints the mean and standard deviation of the accuracy with k values from 1 to 21. We can see that a k=7 results in the best skill of 62.872%. The box and whisker plots of accuracy scores for k values show that k values around seven, such as five and six, also produce stable and well-performing models on the dataset. Spot-check KNN neighbors on ES1 with last 25 observations Now that we have some idea of a representation (n=25) and a model (KNN, k=7) that have some skill over a random prediction, we can test the approach on the harder ES2 dataset. Each model is trained on the combination of dataset 1 and 2, then evaluated on dataset 3. The k-fold cross-validation procedure is not used, so we would expect the scores to be noisy. The complete spot checking of algorithms for ES2 is listed below. Running the example reports the model accuracy on the ES2 scenario. We can see that KNN does well and that the KNN with seven neighbors found to perform well on ES1 also performs well on ES2. A bar chart of the accuracy scores helps to make the relative difference in performance between the methods clearer. Bar chart of model accuracy on ES2 The chosen representation and model configurations do have skill over a naive prediction with 50% accuracy. Further tuning may result in models with better skill, and we are a long way from the 95% and 89% accuracy reported in the paper on ES1 and ES2 respectively. This section lists some ideas for extending the tutorial that you may wish to explore. If you explore any of these extensions, I¡¯d love to know. This section provides more resources on the topic if you are looking to go deeper. In this tutorial, you discovered the indoor movement prediction time series classification problem and how to engineer features and evaluate machine learning algorithms for the problem. Specifically, you learned: Do you have any questions?
Ask your questions in the comments below and I will do my best to answer. ¡¦with just a few lines of python code Discover how in my new Ebook:Deep Learning for Time Series Forecasting It provides self-study tutorials on topics like: CNNs, LSTMs,Multivariate Forecasting, Multi-Step Forecasting and much more¡¦ Skip the Academics. Just Results. Click to learn more. Hi Jason.
Many thanks for this great and helpful tutorial.
I went through the paper of Davide Bacciu, et al. (2011) ¡°Predicting User Movements in Heterogeneous Indoor Environments by Reservoir Computing¡±. His approach consisting in Reservoir Computing and LI-ESN seems impressively efficient.
Do you see any opporunity to implement such approach in Python?
All the best,
Remi Not at this stage. I¡¯m skeptical of the ability to reproduce the results in most papers. Hello Jason, Great tutorials on Multivariate Time Series and LSTM; really enjoyed reading them and learned a lot. I am new to the field (still taking online deep learning courses) and have a general question (I better say I need a general suggestion). Suppose I have a multivariate time series data, and I want to build a classifier model (three-class classification with values 0, 1, or 2). What is the best approach to tackle this problem? LSTM or multi-channel CNN? And have you written any other tutorials? Thanks I recommend testing a suite of methods in order to discover what works best for your specific dataset. Comment  Name (required)  Email (will not be published) (required)  Website Hi, I'm Jason Brownlee, Ph.D.

My goal is to make developers like YOU awesome at applied machine learning."
