"site","date","headline","url_address","text"
"vidhya",2018-09-27,"Building DataHack Summit 2018 <U+2013> India¡¯s Most Advanced AI Conference. Are you Ready?","https://www.analyticsvidhya.com/blog/2018/09/building-datahack-summit-2018-indias-most-advanced-ai-conference-are-you-ready/","

Course on Computer Vision Using Deep Learning | Limited Period Offer at only Rs 11999 | Use COUPON CODE: CVLAUNCH60 |
Buy Now 

 Usain Bolt created a World record by running 200m sprint in<U+00A0>19.30 seconds in 2008. What do you think he thought while he was preparing for 2009? He had his mind set to beat his own personal best and he did! Why am I talking about Bolt here? Well, I find myself in a similar situation. DataHack Summit 2017 was an unprecedented success. We created India¡¯s largest conference with unilateral focus on data science practitioners. The community loved the focus, the content and the knowledge sharing at the event. If you haven¡¯t seen already <U+2013> check out the highlights below. What are we thinking now as we are building India¡¯s most advanced data science conference? If you cut through my mind and get a peek inside <U+2013> this is what you will find <U+0001F642> The venue is bigger than last year but tickets are selling like hot cakes so make sure you grab yours before they¡¯re sold out. Prices go up on September 30th so avail the discount today! Head over here to book your seat<U+00A0>for India¡¯s most advanced conference on AI, Machine Learning, Deep Learning, and IoT! Let¡¯s take a quick tour around DHS 2018 to see how it¡¯s shaping up and what we have in store for you. If there is one place we bet our reputation on <U+2013> it is the content we create and we curate. DataHack Summit 2018 will be an epitome of this. To be honest, we are having a tough time saying no to very exciting talk proposals. Here are a few<U+00A0>eminent speakers in AI and ML who will be speaking at DataHack Sumit 2018: The most exciting thing which people would see are the<U+00A0>Hack sessions.<U+00A0>They saw a tremendous response from the audience last year, and have been expanded to reflect the latest breakthrough developments. Below are a few topics to whet your appetite (click on each session to read more about what will be covered): And here are a few awesome hackers, who will be performing live hack sessions: Check out the full speaker line-up<U+00A0>here. We will top up the sessions and Hack Sessions with an exclusive Startup Showcase and Research Track. We will showcase some of the most exciting AI and ML startups across the globe to showcase their offerings. Prepare to have your mind blown by some of the most amazing uses of AI and ML in a variety of domains. In addition to this, there is an entire track dedicated to cutting-edge research! We are giving individuals the opportunity to come and present their work in front of our community. This year¡¯s venue is none other than the NIMHANS Convention Center in Bengaluru. There are three auditoriums (yes, three!) <U+2013> so you are going to see 3 parallel tracks. So you can look forward to more sessions, more industry leaders, and more engagement! And all this space means an opportunity for even more events. There will be more hack sessions this year, and each session will have an even bigger audience than before. DataHack Summit 2018 will have bigger and swankier LED screens as well! So regardless of where you¡¯re sitting, the presentation and code will be visible from all corners of the room. Reserve your seat TODAY! There is an incredible deal on offer and prices will go up on September 30th. So act now and become a part of India¡¯s most advanced AI and ML conference."
"vidhya",2018-09-27,"A Multivariate Time Series Guide to Forecasting and Modeling (with Python codes)","https://www.analyticsvidhya.com/blog/2018/09/multivariate-time-series-guide-forecasting-modeling-python-codes/","

Course on Computer Vision Using Deep Learning | Limited Period Offer at only Rs 11999 | Use COUPON CODE: CVLAUNCH60 |
Buy Now 

 Time is the most critical factor that decides whether a business will rise or fall. That¡¯s why we see sales in stores and e-commerce platforms aligning with festivals. These businesses analyze years of spending data to understand the best time to throw open the gates and see an increase in consumer spending. But how can you, as a data scientist, perform this analysis? Don¡¯t worry, you don¡¯t need to build a time machine! Time Series modeling is a powerful technique that acts as a gateway to understanding and forecasting trends and patterns. But even a time series model has different facets. Most of the examples we see on the web deal with univariate time series. Unfortunately, real-world use cases don¡¯t work like that. There are multiple variables at play, and handling all of them at the same time is where a data scientist will earn his worth. In this article, we will understand what a multivariate time series is, and how to deal with it. We will also take a case study and implement it in Python to give you a practical understanding of the subject. This article assumes some familiarity with univariate time series, its properties and various techniques used for forecasting. Since this article will be focused on multivariate time series, I would suggest you go through the following articles which serve as a good introduction to univariate time series: But I¡¯ll give you a quick refresher of what a univariate time series is, before going into the details of a multivariate time series. Let¡¯s look at them one by one to understand the difference. A univariate time series, as the name suggests, is a series with a single time-dependent variable. For example, have a look at the sample dataset below that consists of the temperature values (each hour), for the past 2 years. Here, temperature is the dependent variable (dependent on Time). If we are asked to predict the temperature for the next few days, we will look at the past values and try to gauge and extract a pattern. We would notice that the temperature is lower in the morning and at night, while peaking in the afternoon. Also if you have data for the<U+00A0>past few years, you would observe that it is colder during the months of November to January, while being comparatively hotter in April to June. Such observations will help us in predicting future values. Did you notice that we used only one variable (the temperature of the past 2 years,)? Therefore, this is called Univariate Time Series Analysis/Forecasting. A Multivariate time series has more than one time-dependent variable. Each variable depends not only on its past values but also has some dependency on other variables. This dependency is used for forecasting future values. Sounds complicated? Let me explain. Consider the above example. Now suppose our dataset includes perspiration percent, dew point, wind speed, cloud cover percentage, etc. along with the temperature value for the past two years. In this case, there are multiple variables to be considered to optimally predict temperature. A series like this would fall under the category of multivariate time series. Below is an illustration of this: Now that we understand what a multivariate time series looks like, let us understand how can we use it to build a forecast. In this section, I will introduce you to one of the most commonly used methods for multivariate time series forecasting <U+2013> Vector Auto Regression (VAR). In a VAR model, each variable is a linear function of the past values of itself and the past values of all the other variables. To explain this in a better manner, I¡¯m going to use a simple visual example: We have two variables, y1 and y2. We need to forecast the value of these two variables at time t, from the given data for past n values. For simplicity, I have considered the lag value to be 1. For calculating y1(t), we will use the past value of y1 and y2. Similarly, to calculate y2(t), past values of both y1 and y2 will be used. Below is a simple mathematical way of representing this relation: Here, These equations are similar to the equation of an<U+00A0>AR process. Since the AR process is used for univariate time series data, the future values are linear combinations of their own past values only. Consider the AR(1) process: y(t) = a + w*y(t-1) +e In this case, we have only one variable <U+2013> y, a constant term <U+2013> a, an error term <U+2013> e, and a coefficient <U+2013> w. In order to accommodate the multiple variable terms in each equation for VAR, we will use vectors.<U+00A0> We can write the equations (1) and (2) in the following form : The two variables are y1 and y2, followed by a constant, a coefficient metric, lag value, and an error metric. This is the vector equation for a VAR(1) process. For a VAR(2) process, another vector term for time (t-2) will be added to the equation to generalize for p lags: The above equation represents a VAR(p) process with variables y1, y2 ¡¦yk. The same can be written as: The term ¥åt in the equation represents multivariate vector white noise. For a multivariate time series,<U+00A0>¥åt should be a continuous random vector that satisfies the following conditions: Recall the temperate forecasting example we saw earlier. An argument can be made for it to be treated as a multiple univariate series. We can solve it using simple univariate forecasting methods like AR. Since the aim is to predict the temperature, we can simply remove the other variables (except temperature) and fit a model on the remaining univariate series. Another simple idea is to forecast values for each series individually using the techniques we already know. This would make the work extremely straightforward! Then why should you learn another forecasting technique? Isn¡¯t this topic complicated enough already? From the above equations (1) and (2), it is clear that each variable is using the past values of every variable to make the predictions. Unlike AR, VAR is able to understand and use the relationship between several variables. This is useful for describing the dynamic behavior of the data and also provides better forecasting results. Additionally, implementing VAR is as simple as using any other univariate technique (which you will see in the last section). We know from studying the univariate concept that a stationary time series will more often than not give us a better set of predictions. If you are not familiar with the concept of stationarity, please go through this article first: A Gentle Introduction to handling non-stationary Time Series. To summarize, for a given univariate time series: y(t) = c*y(t-1) + ¥å t The series is said to be stationary if the value of |c| < 1. Now, recall the equation of our VAR process: Note: I is the identity matrix. Representing the equation in terms of Lag operators, we have: Taking all the y(t) terms on the left-hand side: The coefficient of y(t) is called the lag polynomial. Let us represent this as ¥Õ(L): For a series to be stationary, the eigenvalues of |¥Õ(L)-1| should be less than 1 in modulus. This might seem complicated given the number of variables in the derivation. This idea has been explained using a simple numerical example in the following video. I highly encourage watching it to solidify your understanding: Similar to the Augmented Dickey-Fuller test for univariate series, we have Johansen¡¯s test for checking the stationarity of any multivariate time series data. We will see how to perform the test in the last section of this article. If you have worked with univariate time series data before, you¡¯ll be aware of the train-validation sets. The idea of creating a validation set is to analyze the performance of the model before using it for making predictions. Creating a validation set for time series problems is tricky because we have to take into account the time component. One cannot directly use the train_test_split or k-fold validation since this will disrupt the pattern in the series. The validation set should be created considering the date and time values. Suppose we have to forecast the temperate, dew point, cloud percent, etc. for the next two months using data from the last two years. One possible method is to keep the data for the last two months aside and train the model on the remaining 22 months. Once the model has been trained, we can use it to make predictions on the validation set. Based on these predictions and the actual values, we can check how well the model performed, and the variables for which the model did not do so well. And for making the final prediction, use the complete dataset (combine the train and validation sets). In this section, we will implement the Vector AR model on a toy dataset. I have used the Air Quality dataset for this and you can download it from here. The data type of the<U+00A0>Date_Time column is object<U+00A0>and we need to change it to datetime. Also, for preparing the data, we need the index to have datetime. Follow the below commands: The next step is to deal with the missing values. Since the missing values in the data are replaced with a value -200, we will have to impute the missing value with a better number. Consider this <U+2013> if the present dew point value is missing, we can safely assume that it will be close to the value of the previous hour. Makes sense, right? Here, I will impute -200 with the previous value. You can choose to substitute the value using the average of a few previous values, or the value at the same time on the previous day (you can share your idea(s) of imputing missing values in the comments section below). Below is the result of the test: We can now go ahead and create the validation set to fit the model, and test the performance of the model: The predictions are in the form of an array, where each list represents the predictions of the row. We will transform this into a more presentable format. Output of the above code: After the testing on validation set, lets fit the model on the complete dataset Before I started this article, the idea of working with a multivariate time series seemed daunting in its scope. It is a complex topic, so take your time in understanding the details. The best way to learn is to practice, and so I hope the above Python implemenattion will be useful for you. I enocurage you to use this approach on a dataset of your choice. This will further cement your understanding of this complex yet highly useful topic. If you have any suggestions or queries, share them in the comments section. HI. Thanks for sharing the knowledge and the great article! Could you pls add some details regarding the stationarity test process described in the article : the test is done and the results are presented but it is not clear if it could be concluded that the data is stationary; after the test is done no further actions to make the data stationary are performed¡¦why so. Thanks"
"vidhya",2018-09-27,"The Winning Approaches from codeFest 2018 <U+2013> NLP, Computer Vision and Machine Learning!","https://www.analyticsvidhya.com/blog/2018/09/the-winning-approaches-from-codefest-2018-nlp-computer-vision-and-machine-learning/","

Course on Computer Vision Using Deep Learning | Limited Period Offer at only Rs 11999 | Use COUPON CODE: CVLAUNCH60 |
Buy Now 

 Analytics Vidhya¡¯s hackathons are one of the best ways to evaluate how far you¡¯ve traveled in your data science journey. And what better way than to put your skills to the test against the top data scientists from around the globe? Participating in these hackathons also helps you understand where you need to improve and what else you can learn to get a better score in the next competition. And a very popular demand after each hackathon is to see how the winning solution was designed and the thought process behind it. There¡¯s a lot to learn from this, including how you can develop your own unique framework for future hackathons. We are all about listening to our community, so we decided to curate the winning approaches from our recently concluded hackathon series, codeFest! This was a series of three hackathons in partnership with IIT-BHU, conducted between 31st August and 2nd September. The competition was intense, with more than 1,900 aspiring data scientists going head-to-head to grab the ultimate prize! Each hackathon had a unique element to it. Interested in finding out more? You can view the details of each competition below: It¡¯s time to check out the winners¡¯ approaches! Abhinav Gupta and Abhishek Sharma. The participants were given a list of tweets from customers about various tech firms who manufacture and sell mobiles, computers, laptops, etc. The challenge was to find the tweets which showed a negative sentiment towards such companies or products. The metric used for evaluating the performance of the classification model was weighted F1-Score. Abhinav and Abhishek have summarized their approach in a very intuitive manner, explaining everything from preprocessing and feature engineering to model building. Pre-processing: Feature Extraction: Classifiers used: They<U+00A0>hypertuned each of the above classifiers and found that LSTM (with attention mechanism) produced the best result. Ensemble Deepak Rawat. The Vista hackathon had a pretty intriguing problem statement. The participants had to build a model that counted the number of people in a given group selfie/photo. The dataset provided had already been split, wherein the training set consisted of images with coordinates of the bounding boxes and headcount for each image. The evaluation metric for this competition was RMSE (root mean squared error) over the headcounts predicted for test images. Check out Deepak¡¯s approach in his own words below: Mask R-CNN and<U+00A0>ResNet101 Both stages are connected to the backbone structure. Pre-processing  Model Building Raj Shukla. As a part of enigma competition, the target was to predict the number of upvotes on a question based on other information provided. For every question <U+2013> its tag, number of views received, number of answers, username and reputation of the question author, was provided. Using this information, the participant had to predict the upvote count that the question will receive. The evaluation metric for this competition was RMSE (root mean squared error). Below is the data dictionary for your reference: Here is Raj¡¯s approach to cracking the Enigma hackathon: Feature Engineering: My focus was on feature engineering, i.e., using the existing features to create new features. Below are some key features I cooked up:"
"vidhya",2018-09-24,"Reinforcement Learning Guide: Solving the Multi-Armed Bandit Problem from Scratch in Python","https://www.analyticsvidhya.com/blog/2018/09/reinforcement-multi-armed-bandit-scratch-python/","

Course on Computer Vision Using Deep Learning | Limited Period Offer at only Rs 11999 | Use COUPON CODE: CVLAUNCH60 |
Buy Now 

 Do you have a favorite coffee place in town? When you think of having a coffee, you might just go to this place as you¡¯re almost sure that you will get the best coffee. But this means you¡¯re missing out on the coffee served by this place¡¯s cross-town competitor. And if you try out all the coffee places one by one, the probability of tasting the worse coffee of your life would be pretty high! But then again, there¡¯s a chance you¡¯ll find an even better coffee brewer. But what does all of this have to do with reinforcement learning? Cafe Coffee Day vs Starbucks I¡¯m glad you asked. The dilemma in our coffee tasting experiment arises from incomplete information. In other words, we need to gather enough information to formulate the best overall strategy and then explore new actions. This will eventually lead to minimizing the overall bad experiences. A multi-armed bandit is a simplified form of this analogy. It is used to represent similar kinds of problems and finding a good strategy to solve them is already helping a lot of industries. In this article, we will first understand what actually is a multi-armed bandit problem, it¡¯s various use cases in the real-world, and then explore some strategies on how to solve it. I will then show you how to solve this challenge in Python using a click-through rate optimization dataset. A bandit is defined as someone who steals your money. A one-armed bandit is a simple slot machine wherein you insert a coin into the machine, pull a lever, and get an immediate reward. But why is it called a bandit? It turns out all casinos configure these slot machines in such a way that all gamblers end up losing money! A multi-armed bandit is a complicated slot machine wherein instead of 1, there are several levers which a gambler can pull, with each lever giving a different return. The probability distribution for the reward corresponding to each lever is different and is unknown to the gambler. The task is to identify which lever to pull in order to get maximum reward after a given set of trials. This problem statement is like a single step Markov decision process, which I discussed in this article. Each arm chosen is equivalent to an action, which then leads to an immediate reward. Exploration Exploitation in the context of<U+00A0> Bernoulli MABP The below table shows the sample results for a 5-armed Bernoulli bandit with arms labelled as 1, 2, 3, 4 and 5: This is called Bernoulli, as the reward returned is either 1 or 0. In this example, it looks like the arm number 3 gives the maximum return and hence one idea is to keep playing this arm in order to obtain the maximum reward (pure exploitation). Just based on the knowledge from the given sample, 5 might look like a bad arm to play, but we need to keep in mind that we have played this arm only once and maybe we should play it a few more times (exploration) to be more confident. Only then should we decide which arm to play (exploitation). Bandit algorithms are being used in a lot of research projects in the industry. I have listed some of their use cases in this section. The well being of patients during clinical trials is as important as the actual results of the study. Here, exploration is equivalent to identifying the best treatment, and exploitation is treating patients as effectively as possible during the trial. Clinical Trials Routing is the process of selecting a path for traffic in a network, such as telephone networks or computer networks (internet). Allocation of channels to the right users, such that the overall throughput is maximised, can be formulated as a MABP. Network Routing The goal of an advertising campaign is to maximise revenue from displaying ads. The advertiser makes revenue every time an offer is clicked by a web user. Similar to MABP, there is a trade-off between exploration, where the goal is to collect information on an ad¡¯s performance using click-through rates, and exploitation, where we stick with the ad that has performed the best so far. Online Ads Building a hit game is challenging. MABP can be used to test experimental changes in game play/interface and exploit the changes which show positive experiences for players. Game Designing In this section, we will discuss some strategies to solve a multi-armed bandit problem. But before that, let¡¯s get familiar with a few terms we¡¯ll be using from here on. The expected payoff or expected reward can also be called an action-value function. It is represented by q(a) and defines the average reward for each action at a time t. Suppose the reward probabilities for a K-armed bandit are given by {P1, P2, P3 ¡¦¡¦ Pk}. If the ith arm is selected at time t, then Qt(a) = Pi. The question is, how do we decide whether a given strategy is better than the rest? One direct way is to compare the total or average reward which we get for each strategy after n trials. If we already know the best action for the given bandit problem, then an interesting way to look at this is the concept of regret. Let¡¯s say that we are already aware of the best arm to pull for the given bandit problem. If we keep pulling this arm repeatedly, we will get a maximum expected reward which can be represented as a horizontal line (as shown in the figure below): But in a real problem statement, we need to make repeated trials by pulling different arms till we am approximately sure of the arm to pull for maximum average return at a time t. The loss that we incur due to time/rounds spent due to the learning is called regret. In other words, we want to maximise my reward even during the learning phase.<U+00A0>Regret is very aptly named, as it quantifies exactly how much you regret not picking the optimal arm. Now, one might be curious as to how does the regret change if we are following an approach that does not do enough exploration and ends exploiting a suboptimal arm. Initially there might be low regret but overall we are far lower than the maximum achievable reward for the given problem as shown by the green curve in the following figure. Based on how exploration is done, there are several ways to solve the MABP. Next, we will discuss some possible solution strategies. A naive approach could be to calculate the q, or action value function, for all arms at each timestep. From that point onwards, select an action which gives the maximum q. The action values for each action will be stored at each timestep by the following function: It then chooses the action at each timestep that maximises the above expression, given by: However, for evaluating this expression at each time t, we will need to do calculations over the whole history of rewards. We can avoid this by doing a running sum.<U+00A0>So, at each time t, the q-value for each action can be calculated using the reward: The problem here is this approach only exploits, as it always picks the same action without worrying about exploring other actions that might return a better reward. Some exploration is necessary to actually find an optimal arm, otherwise we might end up pulling a suboptimal arm forever. One potential solution could be to now, and we can then explore new actions so that we ensure we are not missing out on a better choice of arm. With epsilon probability, we will choose a random action (exploration) and choose an action with maximum qt(a) with probability 1-epsilon. With probability 1- epsilon <U+2013> we choose action with maximum value (argmaxa Qt(a)) With probability epsilon <U+2013> we randomly choose an action from a set of all actions A For example, if we have a problem with two actions <U+2013> A and B, the epsilon greedy algorithm works as shown below: This is much better than the greedy approach as we have an element of exploration here. However, if two actions have a very minute difference between their q values, then even this algorithm will choose only that action which has a probability higher than the others. The solution is to make the probability of choosing an action proportional to q. This can be done using the softmax function, where the probability of choosing action a at each step is given by the following expression: The value of epsilon is very important in deciding how well the epsilon greedy works for a given problem. We can avoid setting this value by keeping epsilon dependent on time. For example, epsilon can be kept equal to 1/log(t+0.00001). It will keep reducing as time passes, to the point where we starting exploring less and less as we become more confident of the optimal action or arm. The problem with random selection of actions is that after sufficient timesteps even if we know that some arm is bad, this algorithm will keep choosing that with probability epsilon/n. Essentially, we are exploring a bad action which does not sound very efficient. The approach to get around this could be to favour exploration of arms with a strong potential in order to get an optimal value. Upper Confidence Bound (UCB) is the most widely used solution method for multi-armed bandit problems. This algorithm is based on the principle of optimism in the face of uncertainty. In other words, the more uncertain we are about an arm, the more important it becomes to explore that arm. The intuitive reason this works is that when acting optimistically in this way, one of two things happen: UCB is actually a family of algorithms. Here, we will discuss UCB1. Steps involved in UCB1: We will not go into the mathematical proof for UCB. However, it is important to understand the expression that corresponds to our selected action. Remember, in the random exploration we just had Q(a) to maximise, while here we have two terms. First is the action value function, while the second is the confidence term. Regret Comparison Among all the algorithms given in this article, only the UCB algorithm provides a strategy where the regret increases as log(t), while in the other algorithms we get linear regret with different slopes. An important assumption we are making here is that we are working with the same bandit and distributions from which rewards are being sampled at each timestep stays the same. This is called a stationary problem. To explain it with another example, say you get a reward of 1 every time a coin is tossed, and the result is head. Say after 1000 coin tosses due to wear and tear the coin becomes biased then this will become a non-stationary problem. To solve a non-stationary problem, more recent samples will be important and hence we could use a constant discounting factor alpha and we can rewrite the update equation like this: Note that we have replaced Nt(at) here with a constant alpha, which ensures that the recent samples are given higher weights, and increments are decided more by such recent samples. There are other techniques which provide different solutions to bandits with non-stationary rewards. You can read more about them in this paper. As mentioned in the use cases section, MABP has a lot of applications in the online advertising domain. Suppose an advertising company is running 10 different ads targeted towards a similar set of population on a webpage. We have results for which ads were clicked by a user here.<U+00A0>Each column index represents a different ad. We have a 1 if the ad was clicked by a user, and 0 if it was not. A sample from the original dataset is shown below: This is a simulated dataset and it has Ad #5 as the one which gives the maximum reward. First, we will try a random selection technique, where we randomly select any ad and show it to the user. If the user clicks the ad, we get paid and if not, there is no profit. Total reward for the random selection algorithm comes out to be 1170. As this algorithm is not learning anything, it will not smartly select any ad which is giving the maximum return. And hence even if we look at the last 1000 trials, it is not able to find the optimal ad. Now, let¡¯s try the Upper Confidence Bound algorithm to do the same: The total_reward for UCB comes out to be 2125. Clearly, this is much better than random selection and indeed a smart exploration technique that can significantly improve our strategy to solve a MABP.  After just 1500 trials, UCB is already favouring Ad #5 (index 4) which happens to be the optimal ad, and gets the maximum return for the given problem."
"vidhya",2018-09-23,"10 Mind-Blowing TED Talks on Artificial Intelligence Every Data Scientist & Business Leader Must Watch","https://www.analyticsvidhya.com/blog/2018/09/best-ted-talks-artificial-intelligence-must-watch/","

Course on Computer Vision Using Deep Learning | Limited Period Offer at only Rs 11999 | Use COUPON CODE: CVLAUNCH60 |
Buy Now 

 TED talks are simply fascinating. They provide tightly knit stories in short doses with mind-blowing information and experiences. It is amazing how much knowledge has been shared in this world using this simple and powerful medium. With Artificial Intelligence and Machine Learning getting so much attention in the spheres of research and business, I started looking out for TED talks on Artificial Intelligence in particular. I was in for such a treat <U+2013> information treat to be precise. I gained much more from watching these TED talks than I have from following some of the most popular YouTube channels out there. Hence, I thought of sharing this incredible content with our community. To save your time <U+2013> I have done all the hard work of watching all the talks on this topic till date and I have shortlisted the best ones for you. Ready for high-quality knowledge enrichment? Dig in! Note: If you are looking to understand what AI is all about and how it¡¯ll impact your career, there¡¯s no better place than our ¡®AI and ML for Business Leaders¡® course! It¡¯s a comprehensive course that gives you the lowdown on what AI and ML are, the common techniques used in the industry, which functions and roles are getting impacted and how, among other things. Check it out today! We all know how creative AI can be, but some of the things Maurice Conti and his team came up with are mindblowing. Using AI for designing new things, like cars, bridges, drones, entire buildings, etc. is no longer limited to the silver screen. This video paints a vivid picture of how AI and humans can (and hopefully will) work together in the future to accomplish tasks neither could perform by themselves. The digital era we find ourselves in the midst of is run by algorithms. They¡¯re everywhere <U+2013> from predicting stock prices to recommending the next movie you should watch. And these algorithms are only going to embed themselves even deeper into our lifestream. This is a thoughtfully curated talk by Kevin Slavin looks at how these algos are shaping our world, and asks a very pressing question <U+2013> at what point do we admit we¡¯ve lost control of them? Nick Bostrom, author of the popular book ¡®Superintelligence¡¯, looks at a future where machines will become smarter than humans. Will machines rule us then? Will humans have any power in that world? These are just some of the questions Nick wants all of us to think about before we heedlessly build AI systems. It¡¯s a deep topic, and quite fitting that it comes from a philosopher. Keeping up the trend of superintelligent AI, Sam Harris delivers a riveting presentation on why we should be scared of building smart AI systems. Sam is a neuroscientist and philosopher, and he delves into both these domains to present a concerning perspective on the future. One of my favorite talks in this list. Can you imagine a world where drivers don¡¯t exist? Or at least, they aren¡¯t human? Well, you better buckle up, because that world is transforming into a reality in front of us. Chris Urmson, former head of Google¡¯s driverless car program, gives us the lowdown on how autonomous<U+00A0>vehicles take decisions in real-time about what to do next. Computer vision is the hottest research field in machine learning right now. It has spawned applications like real-time facial recognition and object detection. But how does it work? The wonderful Fei-Fei Li delivers this thrilling talk on how machines are being trained using computer vision techniques. This talk was delivered three years ago, and the state-of-the-art algorithms have since come quite a long way. Shows how quickly AI is advancing! Continuing our theme of computer vision talks, here¡¯s Joseph Redmon demonstrating how object detection works in real-time. I remember watching this a few months back and being left awed by the demo. It still has the same effect! Joseph built his model using the YOLO framework. Pretty cool, right? Driverless cars are the primary beneficiaries of these advances. Anthony Goldbloom is the co-founder and CEO of Kaggle and an all-around nice person. He¡¯s as good a person as any to give a perspective on the jobs machines will automate in the future (in fact some of the things he mentioned are already happening as I type this!). The key takeaway from this talk is that we need to upskill ourselves at every opportunity we get, otherwise the risk of being left behind will always hang like a shadow over us. Tom Gruber is the co-creator of Siri, so he knows what he¡¯s talking about. He takes a more positive view on the advances in AI and how it can help us enhance the way we live our day-to-day lives.<U+00A0>He shares his vision for a future where AI helps us achieve superhuman performance in perception, creativity, and cognitive function. Music and AI <U+2013> a perfect combination. Pierre Barreau demonstrates AIVA, an artificial intelligence system that creates musical scores! The system has been trained on over 30,000 music compositions (including from the likes of Mozart). Pierre shows us a glimpse of how AIVA was designed using deep neural networks, and the visualizations are spectacular. This is by no means an exhaustive list. There are plenty more Ted Talks available on both the official platform and YouTube that relate to AI. But the reason I¡¯ve chosen these talks is to give you a sense of what industry leaders and experts think about this topic. They are at the forefront of this domain and control a lot about the way we approach things."
