"site","date","headline","url_address","text"
"vidhya",2018-09-06,"An End-to-End Guide to Understand the Math behind XGBoost","https://www.analyticsvidhya.com/blog/2018/09/an-end-to-end-guide-to-understand-the-math-behind-xgboost/","

MEGA-LAUNCH Offer on Computer Vision Using Deep Learning | Use COUPON CODE: CVLAUNCH60 for 60% Discount |
Course Starts 4th September | 
Buy Now 

 Ever since its introduction in 2014, XGBoost has been lauded as the holy grail of machine learning hackathons and competitions. From predicting ad click-through rates to classifying high energy physics events, XGBoost has proved its mettle in terms of performance <U+2013> and speed. I always turn to XGBoost as my first algorithm of choice in any ML hackathon. The accuracy it consistently gives, and the time it saves, demonstrates how useful it is. But how does it actually work? What kind of mathematics power XGBoost? We¡¯ll figure out the answers to these questions soon. Tianqi Chen, one of the co-creators of XGBoost, announced (in 2016) that the innovative system features and algorithmic optimizations in XGBoost have rendered it 10 times faster than most sought after machine learning solutions. A truly amazing technique! In this article, we will first look at the power of XGBoost, and then deep dive into the inner workings of this popular and powerful technique. It¡¯s good to be able to implement it in Python or R, but understanding the nitty-gritties of the algorithm will help you become a better data scientist. Note: We recommend going through the below article as well to fully understand the various terms and concepts mentioned in this article: The beauty of this powerful algorithm lies in its scalability, which drives fast learning through parallel and distributed computing and offers efficient memory usage. It¡¯s no wonder then that CERN recognized it as the best approach to classify signals from the Large Hadron Collider. This particular challenge posed by CERN required a solution that would be scalable to process data being generated at the rate of 3 petabytes per year and effectively distinguish an extremely rare signal from background noises in a complex physical process. XGBoost emerged as the most useful, straightforward and robust solution. Now, let¡¯s deep dive into the inner workings of XGBoost. XGBoost is an ensemble learning method. Sometimes, it may not be sufficient to rely upon the results of just one machine learning model. Ensemble learning offers a systematic solution to combine the predictive power of multiple learners. The resultant is a single model which gives the aggregated output from several models. The models that form the ensemble,<U+00A0>also known as base learners, could be either from the same learning algorithm or different learning algorithms. Bagging and boosting are two widely used ensemble learners. Though these two techniques can be used with several statistical models, the most predominant usage has been with decision trees. Let¡¯s briefly discuss bagging before taking a more detailed look at the concept of boosting. While decision trees are one of the most easily interpretable models, they exhibit highly variable behavior. Consider a single training dataset that we randomly split into two parts. Now, let¡¯s use each part to train a decision tree in order to obtain two models. When we fit both these models, they would yield different results. Decision trees are said to be associated with high variance due to this behavior. Bagging or boosting aggregation helps to reduce the variance in any learner. Several decision trees which are generated in parallel, form the base learners of bagging technique. Data sampled with replacement is fed to these learners for training. The final prediction is the averaged output from all the learners. In boosting, the trees are built sequentially such that each subsequent tree aims to reduce the errors of the previous tree. Each tree learns from its predecessors and updates the residual errors. Hence, the tree that grows next in the sequence will learn from an updated version of the residuals. The base learners in boosting are weak learners in which the bias is high, and the predictive power is just a tad better than random guessing. Each of these weak learners contributes some vital information for prediction, enabling the boosting technique to produce a strong learner by effectively combining these weak learners. The final strong learner brings down both the bias and the variance. In contrast to bagging techniques like Random Forest, in which trees are grown to their maximum extent, boosting makes use of trees with fewer splits. Such small trees, which are not very deep, are highly interpretable. Parameters like the number of trees or iterations, the rate at which the gradient boosting learns, and the depth of the tree, could be optimally selected through validation techniques like k-fold cross validation. Having a large number of trees might lead to overfitting. So, it is necessary to carefully choose the stopping criteria for boosting. Boosting consists of three simple steps: To improve the performance of F1, we could model after the residuals of F1 and create a new model F2: This can be done for ¡®m¡¯ iterations, until residuals have been minimized as much as possible: Here, the additive learners do not disturb the functions created in the previous steps. Instead, they impart information of their own to bring down the errors. Consider the following data where the years of experience is predictor variable and salary (in thousand dollars) is the target. Using regression trees as base learners, we can create a model to predict the salary. For the sake of simplicity, we can choose square loss as our loss function and our objective would be to minimize the square error. As the first step, the model should be initialized with a function F0(x). F0(x) should be a function which minimizes the loss function or MSE (mean squared error), in this case: Taking the first differential of the above equation with respect to ¥ã, it is seen that the function minimizes at the mean i=1nyin. So, the boosting model could be initiated with: F0(x) gives the predictions from the first stage of our model. Now, the residual error for each instance is (yi <U+2013> F0(x)). We can use the residuals from F0(x) to create h1(x). h1(x) will be a regression tree which will try and reduce the residuals from the previous step. The output of h1(x) won¡¯t be a prediction of y; instead, it will help in predicting the successive function F1(x) which will bring down the residuals. The additive model h1(x) computes the mean of the residuals (y <U+2013> F0) at each leaf of the tree. The boosted function F1(x) is obtained by summing F0(x) and h1(x). This way h1(x) learns from the residuals of F0(x) and suppresses it in F1(x). This can be repeated for 2 more iterations to compute h2(x) and h3(x). Each of these additive learners, hm(x), will make use of the residuals from the preceding function, Fm-1(x). The MSEs for F0(x), F1(x) and F2(x) are 875, 692 and 540. It¡¯s amazing how these simple weak learners can bring about a huge reduction in error! Note that each learner, hm(x), is trained on the residuals. All the additive learners in boosting are modeled after the residual errors at each step. Intuitively, it could be observed that the boosting learners make use of the patterns in residual errors. At the stage where maximum accuracy is reached by boosting, the residuals appear to be randomly distributed without any pattern. Plots of Fn<U+00A0>and hn In the case discussed above, MSE was the loss function. The mean minimized the error here. When MAE (mean absolute error) is the loss function, the median would be used as F0(x) to initialize the model. A unit change in y would cause a unit change in MAE as well. For MSE, the change observed would be roughly exponential. Instead of fitting hm(x) on the residuals, fitting it on the gradient of loss function, or the step along which loss occurs, would make this process generic and applicable across all loss functions.  Gradient descent helps us minimize any differentiable function. Earlier, the regression tree for hm(x) predicted the mean residual at each terminal node of the tree. In gradient boosting, the average gradient component would be computed. For each node, there is a factor ¥ã with which hm(x) is multiplied. This accounts for the difference in impact of each branch of the split. Gradient boosting helps in predicting the optimal gradient for the additive model, unlike classical gradient descent techniques which reduce error in the output at each iteration. The following steps are involved in gradient boosting: XGBoost is a popular implementation of gradient boosting. Let¡¯s discuss some features of XGBoost that make it so interesting. So that was all about the mathematics that power the popular XGBoost algorithm. If your basics are solid, this article must have been a breeze for you. It¡¯s such a powerful algorithm and while there are other techniques that have spawned from it (like CATBoost), XGBoost remains a game changer in the machine learning community. If you have any feedback on the article, or questions on any of the above concepts, connect with me in the comments section below. Ramya Bhaskar Sundaram <U+2013> Data Scientist, Noah Data It¡¯s safe to say my forte is advanced analytics. The charm and magnificence of statistics have enticed me, all through my journey as a Data Scientist. There is a definite beauty in how the simplest of statistical techniques can bring out the most intriguing insights from data. My fascination for statistics has helped me to continuously learn and expand my skill set in the domain.My experience spans across multiple verticals: Renewable Energy, Semiconductor, Financial Technology, Educational Technology, E-Commerce Aggregator, Digital Marketing, CRM, Fabricated Metal Manufacturing, Human Resources. Nice explanation ! Hi. Nice article. Thanks for sharing. Couple of clarification
1. what¡¯s the formula for calculating the h1(X)
2. How did the split happen x23. Hi Srinivas,"
"vidhya",2018-09-02,"The 5 Best Machine Learning GitHub Repositories & Reddit Threads from August 2018","https://www.analyticsvidhya.com/blog/2018/09/best-machine-learning-github-repositories-reddit-threads-august-2018/","

MEGA-LAUNCH Offer on Computer Vision Using Deep Learning | Use COUPON CODE: CVLAUNCH60 for 60% Discount |
Course Starts 4th September | 
Buy Now 

 When I started using GitHub early last year, I had never imagined how useful it would become for me. Initially I only used it to upload my own code, assuming that was the extent to which GitHub would prove it¡¯s usefulness. But as I joined Analytics Vidhya and my scope of research expanded, I was enthralled by how vast this platform really is. Apart from allowing me access to open source codes and projects from top companies like Google, Microsoft, NVIDIA, Facebook, etc., it opened up avenues to collaborate on existing projects with fellow machine learning enthusiasts. I cannot tell you how amazing it feels to have contributed to a project that other people use. It¡¯s a feeling like no other. And this, of course, led me to write this monthly series which I hope you have found beneficial in your own line of work. This month¡¯s article contains some pretty sweet repositories. There¡¯s a project from NVIDIA which looks at video-to-video translations, a neat Google repository that makes reinforcement learning way easier to learn than ever before, and I¡¯ve also included a useful automated object detection library. There¡¯s a ton of more information below, including an entertaining R package. In our Reddit section, we have diverse discussions ranging from multiple expert reviews of Julia to real-life data leakage stories. As a data scientist, you need to be on top of your game at all times, and that includes being updated with all the latest developments. Reddit, and AVBytes, should definitely be on your go-to list. You can check out the top GitHub repositories and top Reddit discussions (from April onwards) we have covered each month below: There has been tremendous progress in the image-to-image translation field. However the video processing field has rarely seen many breakthroughs in recent times. Until now. NVIDIA, already leading the way in using deep learning for image and video processing, has open sourced a technique that does video-to-video translation, with mind-blowing results. They have open sourced their code on GitHub so you can get started with using this technique NOW. The code is a PyTorch implementation of vid2vid and you can use it for: Check out our coverage of this repository here. If you¡¯ve worked or researched in the field of reinforcement learning, you will have an idea of how difficult (if not impossible) it is to reproduce existing approaches. Dopemine is a TensorFlow framework that has been created and open sourced with the hope of accelerating progress in this field and making it more flexible and reproducible. If you¡¯ve been wanting to learn reinforcement learning but were scared by how complex it is, this repository comes as a golden opportunity. Available in just 15 Python files, the code comes with detailed documentation and a free dataset! You can additionally read up on this repository here. Object detection is thriving in the deep learning community, but it can be a daunting challenge for newcomers. How many pixels and frames to map? How to increase the accuracy of a very basic model? Where do you even begin? You don¡¯t need to fret too much about this anymore <U+2013> thanks to MIT¡¯s algorithm that automates object detection with stunning precision. Their approach is called ¡®Semantic Soft Segmentation (SSS)¡¯. What takes an expert, say 10 minutes to manually edit, you can now do in a matter of seconds! The above image is a nice illustration of how this algorithm works, and how it¡¯ll look when you implement it on your machine. View our coverage of this technique in more detail here. Pose estimation is seeing a ton of interest from researchers this year and publications like MIT have published studies marking progress in this field. From helping elderly people receive the right treatment to commercial applications like making a human virtually dance, pose estimation is poised to become the next best thing commercially. This repository is Microsoft¡¯s official PyTorch implementation of their popular paper <U+2013><U+00A0>Simple Baselines for Human Pose Estimation and Tracking. They have offered baseline models and benchmarks that are good enough to hopefully inspire new ideas in this line of research. This one is for all the R users out there. We usually download R packages from CRAN so I personally haven¡¯t felt the need to go to GitHub, but this package is one that I found very interesting. chorrrds helps you extract, analyze, and organize music chords. It even comes pre-loaded with several music datasets. You can actually directly install it from CRAN, or use the devtools package to download it from GitHub. Find out more about how to do this, and more details, in this article. In case you haven¡¯t been following OpenAI in the last couple of months, their team has been hard at work trying to hype up their latest innovation <U+2013> OpenAI Five. It¡¯s a team of five neural network working together to become better at playing Dota. And these neural networks were doing extremely well, until they ran into the first professional Dota playing team. This Reddit thread looks at the team¡¯s defeat from all angles, and the machine learning perspective really stands out. Even if you haven¡¯t read their research paper, this thread has enough information to get you up to speed in a jiffy. There are well over 100 comments on this topic, a truly knowledge-rich discussion. Most of us in the data science and machine learning space have used Notebooks for various tasks, like data cleaning, model building, etc. I¡¯m actually yet to meet someone who hasn¡¯t used Notebooks at some point in their data science journey. We don¡¯t usually question the limitations of these notebooks, do we? Now here¡¯s an interesting take on why Notebooks aren¡¯t actually as useful as we think. Make sure you scroll through the entire discussion, there are some curious as well as insightful comments from fellow data scientists. And as a bonus, you can also check out the really well made presentation deck. TensorFlow 2.0 was teased a couple of weeks ago by Google and is expected to be launched in the next few months. This thread is equal parts funny and serious. TensorFlow users from around the world have given their take on what they are expecting, and what they want to see added. Quite a lot of comments are around the usefulness of Eager Execution. This has been a long awaited update so big things are being expected. Will Google deliver? The Julia programming language has been doing the rounds on social media lately after a few articles were written on how it might replace Python in the future. I¡¯ve had requests to review the language and have directed everyone to this thread. What better place to check out the pros and cons of a programming language than a hardcore ML Reddit thread? Rather than reading one perspective, you get access to multiple reviews, each adding a unique point of view. What I liked about this discussion was that plenty of existing Julia users have added their two cents. The consensus seems to be that it is showing a lot of promise (especially the latest release, Julia 1.0), but it has a while to go before it catches up with Python. We are all caught up in trying to solve real-world problems that we tend to forget issues that might crop up in existing projects. You might be surprised at the kind of stories people have told here <U+2013> including one where they had duplicate entries for one row, and that was making the model overfit the training data massively. There are some useful links as well for further reading on the kind of data leakage problems that have come up in the industry. Have you ever been a victim of data leakage? Share your story in this Reddit thread and participate in the discussion!"
"vidhya",2018-09-02,"DataHack Radio Episode #9: Data Science at Airbnb & Lyft with Dr. Alok Gupta","https://www.analyticsvidhya.com/blog/2018/09/datahack-radio-lyft-dr-alok-gupta/","

MEGA-LAUNCH Offer on Computer Vision Using Deep Learning | Use COUPON CODE: CVLAUNCH60 for 60% Discount |
Course Starts 4th September | 
Buy Now 

 Airbnb and Lyft have transformed their respective industries in recent years using data science as their guiding light.<U+00A0>In episode 9 of our DataHack Radio series, Dr. Alok Gupta gave us some very interesting insights into how Airbnb and Lyft use data science.<U+00A0>For instance, did you know that Spark is Airbnb¡¯s machine learning tool of choice? Dr. Alok is currently working as the Director of Data Science and Head of Growth Science at Lyft. He has a deep passion for mathematics and has used that throughout his career, including his four year stint at Airbnb. You will learn a lot in this podcast about how a data science leader thinks about challenging problems, and how leading tech start-ups scale up their operations from the ground up. This article summarizes the key points Dr. Alok discussed during this podcast. This is another valuable addition to the DataHack Radio podcast series, and I highly recommend listening to it as soon as possible! Subscribe to DataHack Radio NOW and listen to this, as well as all previous episodes, on any of the below platforms: Dr. Alok completed his undergraduate in mathematics from Cambridge University and proceeded to do his Masters in Finance and Mathematics from Imperial College, London. During his time there, he developed an interest in stochastic finance and statistics and decided to pursue this as his Ph.D at Oxford University, which he successfully completed in 2010. During his Ph.D years, the infamous recession struck and created chaos in the industry so he wasn¡¯t sure which industry to apply to. He ended up in financial trading at Deutsche Bank where he had an opportunity to design and build algorithms with profit and loss objectives. As part of his role at Deutsche Bank, he moved from London to New York, where he worked for around a year and a half. He discovered the role of a data scientist while in New York, and realized the similarities between that, and his own role as a Quant Trader in finance. This led to him applying at a number of companies and he finally got his break in 2014 at Airbnb as a data scientist and the rest, as he said, is history. The overlaps between a data scientist and a quant trader were plenty, including understanding the problem and framing it in a way that made business sense. There were other intersections, like opportunity sizing, detective analysis, impact estimation, etc. Of course one of the most interesting commonalities was actually solving the problem <U+2013> deciding which mathematical, or statistical, techniques do we need to apply, what is the objective function, how do we get to the optimal solution, among others. But there were a couple of crucial differences between these two roles as well, as Alok discovered in his initial days at Airbnb. The metric that you¡¯re trying to optimize in finance is taken as given (for example, trying to optimize PnL is a concrete objective). Whereas in the technology space, this was vague and needed to be understood at a far more granular level before performing any data science task. Experimentation is another tricky and challenging aspect in technology (there are a number of assignment units, different methodologies for measurements, etc.), whereas in finance you run an algorithm, see how much money it makes, and you¡¯re done! When Alok joined Airbnb in 2014, the entire company was some 1,000 employees strong, with the data science team consisting of just 10 people (when he left earlier this year, the team had grown to around 110!). He started as the Data Scientist on their Risk and Safety fraud prediction team, where he built models for both online and offline fraud detection. One year into his role, Alok started to build his own data science team in the Customer Support optimization space. Airbnb has some 10,000 customer support employees globally that use channels like phone, chat, email, SMS, etc. to help their customers resolve issues. This, as you can see, was a challenge ripe for machine learning. Alok has explained how his team took this as an optimization problem in the podcast and the different features they considered for the final model. A very fascinating section, this. In his last 2 years at Airbnb he switched focus completely to work on acquisition of new guests. This included sourcing different marketing channels, working on search engine optimization, recommendation systems, etc. Alok has described the acquisition process in a lot of depth which will benefit anyone who works in data science, regardless of the industry. The way he and his team approached the problem and worked their way through it can serve as a roadmap for all aspiring data scientists. Most of the data scientists at Airbnb use tools and services like Amazon Web Services (AWS), HIVE, etc. to pull or extract the data they needed. Python and R are used to perform local analysis and Alok saw an increasing number of data scientists moving to Python as it¡¯s easier to productionize Python scripts. For building models and solutions when confronted with large datasets, Airbnb¡¯s machine learning tool of choice was Spark.<U+00A0>Airbnb has also invested in building it¡¯s own centralized machine learning platform that can enable non-data scientists and non-engineers to spin up their own ML models without needing to have a lot of programming experience. Alok led the way in pioneering a knowledge sharing tool within the organization which was shared between data scientists and non-data scientists. The idea behind it was to get everyone on the same page regarding the happenings internally, and it was almost always written in Python or R as a Markdown document. This also helped them get peer reviews on any technical stuff and the quality of analysis was raised to unprecedented levels. At Lyft, all the folks working in the analytics and data science domain are grouped under the umbrella of scientists. Acquisition, engagement, and retention (of passengers and drivers) are some of the problems they are currently working on simultaneously. In his role as the head of Growth Science, Alok has been exposed to the supply side of things, a new and exciting challenge for him. The data science team under Alok currently consists of 40 people (at the time of recording this podcast). Quiet a few challenges he is facing in his current role, which he started just four months ago, he has already seen at Airbnb, so he feels at home in that respect."
