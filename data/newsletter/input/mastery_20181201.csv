"site","date","headline","url_address","text"
"mastery",2018-11-30,"How to Reduce Generalization Error in Deep Neural Networks With Activity Regularization in Keras","https://machinelearningmastery.com/how-to-reduce-generalization-error-in-deep-neural-networks-with-activity-regularization-in-keras/","Activity regularization provides an approach to encourage a neural network to learn sparse features or internal representations of raw observations. It is common to seek sparse learned representations in autoencoders, called sparse autoencoders, and in encoder-decoder models, although the approach can also be used generally to reduce overfitting and improve a model¡¯s ability to generalize to new observations. In this tutorial, you will discover the Keras API for adding activity regularization to deep learning neural network models. After completing this tutorial, you will know: Let¡¯s get started. How to Reduce Generalization Error in Deep Neural Networks With Activity Regularization in KerasPhoto by Johan Neven, some rights reserved. This tutorial is divided into three parts; they are: Keras supports activity regularization. There are three different regularization techniques supported, each provided as a class in the keras.regularizers module: Each of the l1 and l2 regularizers takes a single hyperparameter that controls the amount that each activity contributes to the sum. The l1_l2 regularizer takes two hyperparameters, one for each of the l1 and l2 methods. The regularizer class must be imported and then instantiated; for example: Activity regularization is specified on a layer in Keras. This can be achieved by setting the activity_regularizer argument on the layer to an instantiated and configured regularizer class. The regularizer is applied to the output of the layer, but you have control over what the ¡°output¡± of the layer actually means. Specifically, you have flexibility as to whether the layer output means that the regularization is applied before or after the ¡®activation¡® function. For example, you can specify the function and the regularization on the layer, in which case activation regularization is applied to the output of the activation function, in this case, relu. Alternately, you can specify a linear activation function (the default, that does not perform any transform) which means that the activation regularization is applied on the raw outputs, then, the activation function can be added as a subsequent layer. The latter is probably the preferred usage of activation regularization as described in ¡°Deep Sparse Rectifier Neural Networks¡± in order to allow the model to learn to take activations to a true zero value in conjunction with the rectified linear activation function. Nevertheless, the two possible uses of activation regularization may be explored in order to discover what works best for your specific model and dataset. Let¡¯s take a look at how activity regularization can be used with some common layer types. The example below sets l1 norm activity regularization on a Dense fully connected layer. The example below sets l1 norm activity regularization on a Conv2D convolutional layer. The example below sets l1 norm activity regularization on an LSTM recurrent layer. Now that we know how to use the activity regularization API, let¡¯s look at a worked example. In this section, we will demonstrate how to use activity regularization to reduce overfitting of an MLP on a simple binary classification problem. Although activity regularization is most often used to encourage sparse learned representations in autoencoder and encoder-decoder models, it can also be used directly within normal neural networks to achieve the same effect and improve the generalization of the model. This example provides a template for applying activity regularization to your own neural network for classification and regression problems. We will use a standard binary classification problem that defines two two-dimensional concentric circles of observations, one circle for each class. Each observation has two input variables with the same scale and a class output value of either 0 or 1. This dataset is called the ¡°circles¡± dataset because of the shape of the observations in each class when plotted. We can use the make_circles() function to generate observations from this problem. We will add noise to the data and seed the random number generator so that the same samples are generated each time the code is run. We can plot the dataset where the two variables are taken as x and y coordinates on a graph and the class value is taken as the color of the observation. The complete example of generating the dataset and plotting it is listed below. Running the example creates a scatter plot showing the concentric circles shape of the observations in each class. We can see the noise in the dispersal of the points making the circles less obvious. Scatter Plot of Circles Dataset with Color Showing the Class Value of Each Sample This is a good test problem because the classes cannot be separated by a line, e.g. are not linearly separable, requiring a nonlinear method such as a neural network to address. We have only generated 100 samples, which is small for a neural network, providing the opportunity to overfit the training dataset and have higher error on the test dataset: a good case for using regularization. Further, the samples have noise, giving the model an opportunity to learn aspects of the samples that don¡¯t generalize. We can develop an MLP model to address this binary classification problem. The model will have one hidden layer with more nodes that may be required to solve this problem, providing an opportunity to overfit. We will also train the model for longer than is required to ensure the model overfits. Before we define the model, we will split the dataset into train and test sets, using 30 examples to train the model and 70 to evaluate the fit model¡¯s performance. Next, we can define the model. The hidden layer uses 500 nodes and the rectified linear activation function. A sigmoid activation function is used in the output layer in order to predict class values of 0 or 1. The model is optimized using the binary cross entropy loss function, suitable for binary classification problems and the efficient Adam version of gradient descent. The defined model is then fit on the training data for 4,000 epochs and the default batch size of 32. We will also use the test dataset as a validation dataset. We can evaluate the performance of the model on the test dataset and report the result. Finally, we will plot the performance of the model on both the train and test set each epoch. If the model does indeed overfit the training dataset, we would expect the line plot of accuracy on the training set to continue to increase and the test set to rise and then fall again as the model learns statistical noise in the training dataset. We can tie all of these pieces together, the complete example is listed below. Running the example reports the model performance on the train and test datasets. We can see that the model has better performance on the training dataset than the test dataset, one possible sign of overfitting. Your specific results may vary given the stochastic nature of the neural network and the training algorithm. Because the model is severely overfit, we generally would not expect much, if any, variance in the accuracy across repeated runs of the model on the same dataset. A figure is created showing line plots of the model accuracy on the train and test sets. We can see the expected shape of an overfit model where test accuracy increases to a point and then begins to decrease again. Line Plots of Accuracy on Train and Test Datasets While Training Showing an Overfit We can update the example to use activation regularization. There are a few different regularization methods to choose from, but it is probably a good idea to use the most common, which is the L1 vector norm. This regularization has the effect of encouraging a sparse representation (lots of zeros), which is supported by the rectified linear activation function that permits true zero values. We can do this by using the keras.regularizers.l1 class in Keras. We will configure the layer to use the linear activation function so that we can regularize the raw outputs, then add a relu activation layer after the regularized outputs of the layer. We will set the regularization hyperparameter to 1E-4 or 0.0001, found with a little trial and error. The complete updated example with the L1 norm constraint is listed below: Running the example reports the model performance on the train and test datasets. We can see that activity regularization resulted in a slight drop in accuracy on the training dataset down from 100% to 96% and a lift in accuracy on the test set up from 78% to 82%. Reviewing the line plot of train and test accuracy, we can see that it no longer appears that the model has overfit the training dataset. Model accuracy on both the train and test sets continues to increase to a plateau. Line Plots of Accuracy on Train and Test Datasets While Training With Activity Regularization For completeness, we can compare results to a version of the model where activity regularization is applied after the relu activation function. The complete example is listed below. Running the example reports the model performance on the train and test datasets. We can see that, at least on this problem and with this model, activation regularization after the activation function did not improve generalization error; in fact, it made it worse. Reviewing the line plot of train and test accuracy, we can see that indeed the model still shows the signs of having overfit the training dataset. Line Plots of Accuracy on Train and Test Datasets While Training With Activity Regularization, Still Overfit This suggests that it may be worth experimenting with both approaches for implementing activity regularization with your own dataset, to confirm that you are getting the most out of the method. This section lists some ideas for extending the tutorial that you may wish to explore. If you explore any of these extensions, I¡¯d love to know. This section provides more resources on the topic if you are looking to go deeper. In this tutorial, you discovered the Keras API for adding activity regularization to deep learning neural network models. Specifically, you learned: Do you have any questions?
Ask your questions in the comments below and I will do my best to answer. train_acc = model.evaluate(trainX, trainy, verbose=0)
_, test_acc = model.evaluate(testX, testy, verbose=0)
print(¡®Train: %.3f, Test: %.3f¡¯ % (train_acc, test_acc)) <<< Does not work here is the error TypeError: must be real number, not list The example does work. Ensure your libraries are up to date and that you¡¯re using Python 3.
Ensure that you¡¯re running the example from the command line. Does that help? Comment  Name (required)  Email (will not be published) (required)  Website"
"mastery",2018-11-28,"Activation Regularization for Reducing Generalization Error in Deep Learning Neural Networks","https://machinelearningmastery.com/activation-regularization-for-reducing-generalization-error-in-deep-learning-neural-networks/","Deep learning models are capable of automatically learning a rich internal representation from raw input data. This is called feature or representation learning. Better learned representations, in turn, can lead to better insights into the domain, e.g. via visualization of learned features, and to better predictive models that make use of the learned features. A problem with learned features is that they can be too specialized to the training data, or overfit, and not generalize well to new examples. Large values in the learned representation can be a sign of the representation being overfit. Activity or representation regularization provides a technique to encourage the learned representations, the output or activation of the hidden layer or layers of the network, to stay small and sparse. In this post, you will discover activation regularization as a technique to improve the generalization of learned features in neural networks. After reading this post, you will know: Let¡¯s get started. Activation Regularization for Reducing Generalization Error in Deep Learning Neural NetworksPhoto by Nicholas A. Tonelli, some rights reserved. This tutorial is divided into five parts; they are: Deep learning models are able to perform feature learning. That is, during the training of the network, the model will automatically extract the salient features from the input patterns or ¡°learn features.¡± These features may be used in the network in order to predict a quantity for regression or predict a class value for classification. These internal representations are tangible things. The output of a hidden layer within the network represent the learned features by the model at that point in the network. There is a field of study focused on the efficient and effective automatic learning of features, often investigated by having a network reduce an input to a small learned feature before using a second network to reconstruct the original input from the learned feature. Models of this type are called auto-encoders, or encoder-decoders, and their learned features can be useful to learn more about the domain (e.g. via visualization) and in predictive models. The learned features, or ¡°encoded inputs,¡± must be large enough to capture the salient features of the input but also focused enough to not over-fit the specific examples in the training dataset. As such, there is a tension between the expressiveness and the generalization of the learned features. More importantly, when the dimension of the code in an encoder-decoder architecture is larger than the input, it is necessary to limit the amount of information carried by the code, lest the encoder-decoder may simply learn the identity function in a trivial way and produce uninteresting features. <U+2014> Unsupervised Learning of Invariant Feature Hierarchies with Applications to Object Recognition, 2007. In the same way that large weights in the network can signify an unstable and overfit model, large output values in the learned features can signify the same problems. It is desirable to have small values in the learned features, e.g. small outputs or activations from the encoder network. The loss function of the network can be updated to penalize models in proportion to the magnitude of their activation. This is similar to ¡°weight regularization¡± where the loss function is updated to penalize the model in proportion to the magnitude of the weights. The output of a layer is referred to as its ¡®activation,¡¯ as such, this form of penalty or regularization is referred to as ¡®activation regularization.¡¯ ¡¦ place a penalty on the activations of the units in a neural network, encouraging their activations to be sparse. <U+2014> Page 254, Deep Learning, 2016. The output of an encoder or, generally, the output of a hidden layer in a neural network may be considered the representation of the problem at that point in the model. As such, this type of penalty may also be referred to as ¡®representation regularization.¡¯ The desire to have small activations or even very few activations with mostly zero values is also called a desire for sparsity. As such, this type of penalty is also referred to as ¡®sparse feature learning.¡¯ One way to limit the information content of an overcomplete code is to make it sparse. <U+2014> Unsupervised Learning of Invariant Feature Hierarchies with Applications to Object Recognition, 2007. The encouragement of sparse learned features in autoencoder models is referred to as ¡®sparse autoencoders.¡¯ A sparse autoencoder is simply an autoencoder whose training criterion involves a sparsity penalty on the code layer, in addition to the reconstruction error <U+2014> Page 505, Deep Learning, 2016. Sparsity is most commonly sought when a larger-than-required hidden layer (e.g. over-complete) is used to learn features that may encourage over-fitting. The introduction of a sparsity penalty counters this problem and encourages better generalization. A sparse overcomplete learned feature has been shown to be more effective than other types of learned features offering better robustness to noise and even transforms in the input, e.g. learned features of images may have improved invariance to the position of objects in the image. Sparse-overcomplete representations have a number of theoretical and practical advantages, as demonstrated in a number of recent studies. In particular, they have good robustness to noise, and provide a good tiling of the joint space of location and frequency. In addition, they are advantageous for classifiers because classification is more likely to be easier in higher dimensional spaces. <U+2014> Sparse Feature Learning for Deep Belief Networks, 2007. There is a general focus on sparsity of the representations rather than small vector magnitudes. A study of these representations that is more general than the use of neural networks is known as ¡®sparse coding.¡¯ Sparse coding provides a class of algorithms for finding succinct representations of stimuli; given only unlabeled input data, it learns basis functions that capture higher-level features in the data. <U+2014> Efficient sparse coding algorithms, 2007. An activation penalty can be applied per-layer, perhaps only at one layer that is the focus of the learned representation, such as the output of the encoder model or the middle (bottleneck) of an autoencoder model. A constraint can be applied that adds a penalty proportional to the magnitude of the vector output of the layer. The activation values may be positive or negative, so we cannot simply sum the values. Two common methods for calculating the magnitude of the activation are: The L1 norm encourages sparsity, e.g. allows some activations to become zero, whereas the l2 norm encourages small activations values in general. Use of the L1 norm may be a more commonly used penalty for activation regularization. A hyperparameter must be specified that indicates the amount or degree that the loss function will weight or pay attention to the penalty. Common values are on a logarithmic scale between 0 and 0.1, such as 0.1, 0.001, 0.0001, etc. Activity regularization can be used in conjunction with other regularization techniques, such as weight regularization. This section provides some examples of activation regularization in order to provide some context for how the technique may be used in practice. Regularized or sparse activations were originally sought as an approach to support the development of much deeper neural networks, early in the history of deep learning. As such, many examples may make use of architectures like restricted Boltzmann machines (RBMs) that have been replaced by more modern methods. Another big application of weight regularization is in autoencoders with semi-labeled or unlabeled data, so-called sparse autoencoders. Xavier Glorot, et al. at the University of Montreal introduced the use of the rectified linear activation function to encourage sparsity of representation. They used an L1 penalty and evaluate deep supervised MLPs on a range of classical computer vision classification tasks such as MNIST and CIFAR10. Additionally, an L1 penalty on the activations with a coefficient of 0.001 was added to the cost function during pre-training and fine-tuning in order to increase the amount of sparsity in the learned representations <U+2014> Deep Sparse Rectifier Neural Networks, 2011. Stephen Merity, et al. from Salesforce Research used L2 activation regularization with LSTMs on outputs and recurrent outputs for natural language process in conjunction with dropout regularization. They tested a suite of different activation regularization coefficient values on a range of language modeling problems. While simple to implement, activity regularization and temporal activity regularization are competitive with other far more complex regularization techniques and offer equivalent or better results. <U+2014> Revisiting Activation Regularization for Language RNNs, 2017. This section provides some tips for using activation regularization with your neural network. Activation regularization is a generic approach. It can be used with most, perhaps all, types of neural network models, not least the most common network types of Multilayer Perceptrons, Convolutional Neural Networks, and Long Short-Term Memory Recurrent Neural Networks. Activity regularization may be best suited to those model types that explicitly seek an efficient learned representation. These include models such as autoencoders (i.e. sparse autoencoders) and encoder-decoder models, such as encoder-decoder LSTMs used for sequence-to-sequence prediction problems. The most common activation regularization is the L1 norm as it encourages sparsity. Experiment with other types of regularization such as the L2 norm or using both the L1 and L2 norms at the same time, e.g. like the Elastic Net linear regression algorithm. The rectified linear activation function, also called relu, is an activation function that is now widely used in the hidden layer of deep neural networks. Unlike classical activation functions such as tanh (hyperbolic tangent function) and sigmoid (logistic function), the relu function allows exact zero values easily. This makes it a good candidate when learning sparse representations, such as with the l1 vector norm activation regularization. It is common to use small values for the regularization hyperparameter that controls the contribution of each activation to the penalty. Perhaps start by testing values on a log scale, such as 0.1, 0.001, and 0.0001. Then use a grid search at the order of magnitude that shows the most promise. It is a generally good practice to rescale input variables to have the same scale. When input variables have different scales, the scale of the weights of the network will, in turn, vary accordingly. Large weights can saturate the nonlinear transfer function and reduce the variance in the output from the layer. This may introduce a problem when using activation regularization. This problem can be addressed by either normalizing or standardizing input variables. Configure the layer chosen to be the learned features, e.g. the output of the encoder or the bottleneck in the autoencoder, to have more nodes that may be required. This is called an overcomplete representation that will encourage the network to overfit the training examples. This can be countered with a strong activation regularization in order to encourage a rich learned representation that is also sparse. This section provides more resources on the topic if you are looking to go deeper. In this post, you discovered activation regularization as a technique to improve the generalization of learned features. Specifically, you learned: Do you have any questions?
Ask your questions in the comments below and I will do my best to answer. Comment  Name (required)  Email (will not be published) (required)  Website"
"mastery",2018-11-26,"How to Reduce Overfitting in Deep Neural Networks Using Weight Constraints in Keras","https://machinelearningmastery.com/how-to-reduce-overfitting-in-deep-neural-networks-with-weight-constraints-in-keras/","Weight constraints provide an approach to reduce the overfitting of a deep learning neural network model on the training data and improve the performance of the model on new data, such as the holdout test set. There are multiple types of weight constraints, such as maximum and unit vector norms, and some require a hyperparameter that must be configured. In this tutorial, you will discover the Keras API for adding weight constraints to deep learning neural network models to reduce overfitting. After completing this tutorial, you will know: Let¡¯s get started. How to Reduce Overfitting in Deep Neural Networks With Weight Constraints in KerasPhoto by Ian Sane, some rights reserved. This tutorial is divided into three parts; they are: The Keras API supports weight constraints. The constraints are specified per-layer, but applied and enforced per-node within the layer. Using a constraint generally involves setting the kernel_constraint argument on the layer for the input weights and the bias_constraint for the bias weights. Generally, weight constraints are not used on the bias weights. A suite of different vector norms can be used as constraints, provided as classes in the keras.constraints module. They are: For example, a constraint can imported and instantiated: The weight norms can be used with most layers in Keras. In this section, we will look at some common examples. The example below sets a maximum norm weight constraint on a Dense fully connected layer. The example below sets a maximum norm weight constraint on a convolutional layer. Unlike other layer types, recurrent neural networks allow you to set a weight constraint on both the input weights and bias, as well as the recurrent input weights. The constraint for the recurrent weights is set via the recurrent_constraint argument to the layer. The example below sets a maximum norm weight constraint on an LSTM layer. Now that we know how to use the weight constraint API, let¡¯s look at a worked example. In this section, we will demonstrate how to use weight constraints to reduce overfitting of an MLP on a simple binary classification problem. This example provides a template for applying weight constraints to your own neural network for classification and regression problems. We will use a standard binary classification problem that defines two semi-circles of observations, one semi-circle for each class. Each observation has two input variables with the same scale and a class output value of either 0 or 1. This dataset is called the ¡°moons¡± dataset because of the shape of the observations in each class when plotted. We can use the make_moons() function to generate observations from this problem. We will add noise to the data and seed the random number generator so that the same samples are generated each time the code is run. We can plot the dataset where the two variables are taken as x and y coordinates on a graph and the class value is taken as the color of the observation. The complete example of generating the dataset and plotting it is listed below. Running the example creates a scatter plot showing the semi-circle or moon shape of the observations in each class. We can see the noise in the dispersal of the points making the moons less obvious. Scatter Plot of Moons Dataset With Color Showing the Class Value of Each Sample This is a good test problem because the classes cannot be separated by a line, e.g. are not linearly separable, requiring a nonlinear method such as a neural network to address. We have only generated 100 samples, which is small for a neural network, providing the opportunity to overfit the training dataset and have higher error on the test dataset: a good case for using regularization. Further, the samples have noise, giving the model an opportunity to learn aspects of the samples that don¡¯t generalize. We can develop an MLP model to address this binary classification problem. The model will have one hidden layer with more nodes than may be required to solve this problem, providing an opportunity to overfit. We will also train the model for longer than is required to ensure the model overfits. Before we define the model, we will split the dataset into train and test sets, using 30 examples to train the model and 70 to evaluate the fit model¡¯s performance. Next, we can define the model. The hidden layer uses 500 nodes in the hidden layer and the rectified linear activation function. A sigmoid activation function is used in the output layer in order to predict class values of 0 or 1. The model is optimized using the binary cross entropy loss function, suitable for binary classification problems and the efficient Adam version of gradient descent. The defined model is then fit on the training data for 4,000 epochs and the default batch size of 32. We will also use the test dataset as a validation dataset. We can evaluate the performance of the model on the test dataset and report the result. Finally, we will plot the performance of the model on both the train and test set each epoch. If the model does indeed overfit the training dataset, we would expect the line plot of accuracy on the training set to continue to increase and the test set to rise and then fall again as the model learns statistical noise in the training dataset. We can tie all of these pieces together; the complete example is listed below. Running the example reports the model performance on the train and test datasets. We can see that the model has better performance on the training dataset than the test dataset, one possible sign of overfitting. Your specific results may vary given the stochastic nature of the neural network and the training algorithm. Because the model is overfit, we generally would not expect much, if any, variance in the accuracy across repeated runs of the model on the same dataset. A figure is created showing line plots of the model accuracy on the train and test sets. We can see that expected shape of an overfit model where test accuracy increases to a point and then begins to decrease again. Line Plots of Accuracy on Train and Test Datasets While Training Showing an Overfit We can update the example to use a weight constraint. There are a few different weight constraints to choose from. A good simple constraint for this model is to simply normalize the weights so that the norm is equal to 1.0. This constraint has the effect of forcing all incoming weights to be small. We can do this by using the unit_norm in Keras. This constraint can be added to the first hidden layer as follows: We can also achieve the same result by using the min_max_norm and setting the min and maximum to 1.0, for example: We cannot achieve the same result with the maximum norm constraint as it will allow norms at or below the specified limit; for example: The complete updated example with the unit norm constraint is listed below: Running the example reports the model performance on the train and test datasets. We can see that indeed the strict constraint on the size of the weights has improved the performance of the model on the holdout set without impacting performance on the training set. Reviewing the line plot of train and test accuracy, we can see that it no longer appears that the model has overfit the training dataset. Model accuracy on both the train and test sets continues to increase to a plateau. Line Plots of Accuracy on Train and Test Datasets While Training With Weight Constraints This section lists some ideas for extending the tutorial that you may wish to explore. If you explore any of these extensions, I¡¯d love to know. This section provides more resources on the topic if you are looking to go deeper. In this tutorial, you discovered the Keras API for adding weight constraints to deep learning neural network models. Specifically, you learned: Do you have any questions?
Ask your questions in the comments below and I will do my best to answer. Is gradient clipping similar to a weight constraint? Great question!  Not quite. Weight constraints are applied to the weights and is a regularization technique. Gradient clipping is applied to the error gradient used to update the weights and is used to avoid exploding gradients. Awesome article. This helps to impove theprediction  in the kaggle competition, ¡°Don¡¯t call me turkey!¡±. Wishes, I¡¯m happy to hear that, well done! Does containing the weights in each layer say to sum up to one make the model easier to interpret? Maybe on the input layer, but perhaps not on hidden layers. Say if  kernel_constraint=max_norm(A). On what basis should I set up the value of ¡®A¡¯ ? Experiment with a range of small integer values, often in [1,4] On which layer this should be applied ? As most of the networks in CNN are too deeper. Is there a way to figure that out ? Use on all layers. Comment  Name (required)  Email (will not be published) (required)  Website"
