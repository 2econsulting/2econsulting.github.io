"date","headline","url_address","text"
2018-07-09,"How to Calculate Nonparametric Rank Correlation in Python","https://machinelearningmastery.com/how-to-calculate-nonparametric-rank-correlation-in-python/","Correlation is a measure of the association between two variables. It is easy to calculate and interpret when both variables have a well understood Gaussian distribution. When we do not know the distribution of the variables, we must use nonparametric rank correlation methods. In this tutorial, you will discover rank correlation methods for quantifying the association between variables with a non-Gaussian distribution. After completing this tutorial, you will know: Let¡¯s get started. This tutorial is divided into 4 parts; they are: Take my free 7-day email crash course now (with sample code). Click to sign-up and also get a free PDF Ebook version of the course. Download Your FREE Mini-Course Correlation refers to the association between the observed values of two variables. The variables may have a positive association, meaning that as the values for one variable increase, so do the values of the other variable. The association may also be negative, meaning that as the values of one variable increase, the values of the others decrease. Finally, the association may be neutral, meaning that the variables are not associated. Correlation quantifies this association, often as a measure between the values -1 to 1 for perfectly negatively correlated and perfectly positively correlated. The calculated correlation is referred to as the ¡°correlation coefficient.¡± This correlation coefficient can then be interpreted to describe the measures. See the table below to help with interpretation the correlation coefficient. Table of Correlation Coefficient Values and Their InterpretationTaken from ¡°Nonparametric Statistics for Non-Statisticians: A Step-by-Step Approach¡±. The correlation between two variables that each have a Gaussian distribution can be calculated using standard methods such as the Pearson¡¯s correlation. This procedure cannot be used for data that does not have a Gaussian distribution. Instead, rank correlation methods must be used. Rank correlation refers to methods that quantify the association between variables using the ordinal relationship between the values rather than the specific values. Ordinal data is data that has label values and has an order or rank relationship; for example: ¡®low¡®, ¡®medium¡®, and ¡®high¡®. Rank correlation can be calculated for real-valued variables. This is done by first converting the values for each variable into rank data. This is where the values are ordered and assigned an integer rank value. Rank correlation coefficients can then be calculated in order to quantify the association between the two ranked variables. Because no distribution for the values is assumed, rank correlation methods are referred to as distribution-free correlation or nonparametric correlation. Interestingly, rank correlation measures are often used as the basis for other statistical hypothesis tests, such as determining whether two samples were likely drawn from the same (or different) population distributions. Rank correlation methods are often named after the researcher or researchers that developed the method. Four examples of rank correlation methods are as follows: In the following sections, we will take a closer look at two of the more common rank correlation methods: Spearman¡¯s and Kendall¡¯s. Before we demonstrate rank correlation methods, we must first define a test problem. In this section, we will define a simple two-variable dataset where each variable is drawn from a uniform distribution (e.g. non-Gaussian) and the values of the second variable depend on the values of the first value. Specifically, a sample of 1,000 random floating point values are drawn from a uniform distribution and scaled to the range 0 to 20. A second sample of 1,000 random floating point values are drawn from a uniform distribution between 0 and 10 and added to values in the first sample to create an association. The complete example is listed below. Running the example generates the data sample and graphs the points on a scatter plot. We can clearly see that each variable has a uniform distribution and the positive association between the variables is visible by the diagonal grouping of the points from the bottom left to the top right of the plot. Scatter Plot of Associated Variables Drawn From a Uniform Distribution Spearman¡¯s rank correlation is named for Charles Spearman. It may also be called Spearman¡¯s correlation coefficient and is denoted by the lowercase greek letter rho (p). As such, it may be referred to as Spearman¡¯s rho. This statistical method quantifies the degree to which ranked variables are associated by a monotonic function, meaning an increasing or decreasing relationship. As a statistical hypothesis test, the method assumes that the samples are uncorrelated (fail to reject H0). The Spearman rank-order correlation is a statistical procedure that is designed to measure the relationship between two variables on an ordinal scale of measurement. <U+2014> Page 124, Nonparametric Statistics for Non-Statisticians: A Step-by-Step Approach, 2009. The intuition for the Spearman¡¯s rank correlation is that it calculates a Pearson¡¯s correlation (e.g. a parametric measure of correlation) using the rank values instead of the real values. Where the Pearson¡¯s correlation is the calculation of the covariance (or expected difference of observations from the mean) between the two variables normalized by the variance or spread of both variables. Spearman¡¯s rank correlation can be calculated in Python using the spearmanr() SciPy function. The function takes two real-valued samples as arguments and returns both the correlation coefficient in the range between -1 and 1 and the p-value for interpreting the significance of the coefficient. We can demonstrate the Spearman¡¯s rank correlation on the test dataset. We know that there is a strong association between the variables in the dataset and we would expect the Spearman¡¯s test to find this association. The complete example is listed below. Running the example calculates the Spearman¡¯s correlation coefficient between the two variables in the test dataset. The statistical test reports a strong positive correlation with a value of 0.9. The p-value is close to zero, which means that the likelihood of observing the data given that the samples are uncorrelated is very unlikely (e.g. 95% confidence) and that we can reject the null hypothesis that the samples are uncorrelated. Kendall¡¯s rank correlation is named for Maurice Kendall. It is also called Kendall¡¯s correlation coefficient, and the coefficient is often referred to by the lowercase Greek letter tau (t). In turn, the test may be called Kendall¡¯s tau. The intuition for the test is that it calculates a normalized score for the number of matching or concordant rankings between the two samples. As such, the test is also referred to as Kendall¡¯s concordance test. The Kendall¡¯s rank correlation coefficient can be calculated in Python using the kendalltau() SciPy function. The test takes the two data samples as arguments and returns the correlation coefficient and the p-value. As a statistical hypothesis test, the method assumes (H0) that there is no association between the two samples. We can demonstrate the calculation on the test dataset, where we do expect a significant positive association to be reported. The complete example is listed below. Running the example calculates the Kendall¡¯s correlation coefficient as 0.7, which is highly correlated. The p-value is close to zero (and printed as zero), as with the Spearman¡¯s test, meaning that we can confidently reject the null hypothesis that the samples are uncorrelated. This section lists some ideas for extending the tutorial that you may wish to explore. If you explore any of these extensions, I¡¯d love to know. This section provides more resources on the topic if you are looking to go deeper. In this tutorial, you discovered rank correlation methods for quantifying the association between variables with a non-Gaussian distribution. Specifically, you learned: Do you have any questions?
Ask your questions in the comments below and I will do my best to answer. ¡¦by writing lines of code in python Discover how in my new Ebook:Statistical Methods for Machine Learning It provides self-study tutorials on topics like:Hypothesis Tests, Correlation, Nonparametric Stats, Resampling, and much more¡¦ Skip the Academics. Just Results. Click to learn more. Hello Jason! I¡¯m starting to make some projects using machine learning and i have a doubt. Can I use these ranking correlations to select atributes for a machine learning project?
What is the best for this use? Thanks! Your blog is helping me a lot to get improved at the machine learning area! Yes, try it.  There are many ways to select features for ML, try a few and go with the method that results in a model with the best performance.  There is no best, instead, there are many different methods to try for your problem. Comment  Name (required)  Email (will not be published) (required)  Website Hi, I'm Jason Brownlee, Ph.D.

My goal is to make developers like YOU awesome at applied machine learning."
2018-07-06,"Statistics in Plain English for Machine Learning","https://machinelearningmastery.com/statistics-in-plain-english-for-machine-learning/","There is an ocean of books on statistics; where do you start? A big problem in choosing a beginner book on statistics is that a book may suffer one of two common problems. It may be a mathematical textbook filled with derivations, special cases, and proofs for each statistical method with little idea for the intuition for the method or how to use it. Or it may be a playbook for a proprietary or ancient statistical package with little relevance to the libraries and problems you face. In this post, you will discover the book ¡°Statistics in Plain English¡± for learning about statistical methods without getting too bogged down in theory nor implementation details. After reading this post, you will know: Let¡¯s get started. Statistics in Plain English provides an introduction to statistics for students that might be taking a statistics class as part of some other degree program in social sciences. Statistics in Plain English It was written by Timothy Urdan who is a researcher and professor of Psychology. It is a popular book because of the accessibility of the writing and is currently in the fourth edition. I have the third edition, so any quotes and table of contents will reference that version. It is not a textbook nor an exercise book, but something in between. Tim modestly states the purpose of the book as follows: The purpose of this book is to make it a little easier to understand statistics. His intention is for the book to act as a compliment to a more dense textbook on statistics. Again, I think this is modest and mentioned because it does not dive into more mathematical rigor (derivation and proofs) behind the methods and focuses on the application and intuition for the methods (i.e. what you care about as a practitioner). I do think that the book is more than suitable as a first step into statistics. Each chapter introduces a statistic (sometimes more than one) using a consistent template with three parts, as follows: The book is not long at less than 200 pages. It also uses a large form factor 11 x 5.5 inches, meaning that physically holding the book gives a lot of space to the ideas and examples. If you have the time and are really new to the field of statistics, it is worth reading cover to cover. Seriously. Even if you¡¯re familiar with the topic, it¡¯s a great read. Take my free 7-day email crash course now (with sample code). Click to sign-up and also get a free PDF Ebook version of the course. Download Your FREE Mini-Course I recommend studying the table of contents. It is useful for two reasons: The full 15-chapter table of contents from the third edition of the book are as follows: The presentation provides a clear separation of the topics. It allows you to pick and choose the topics or chapters that interest you the most and dive in, without having to read prior chapters. Thee book is organized such that the more basic statistics and statistical concepts are in the earlier chapters whereas the more complex concepts appear later in the book. However, it is not necessary to read one chapter before understanding the next. Rather, each chapter in the book was written to stand on its own. A review of the table of contents highlights two things: This chosen focus will handle most of the statistical methods required when working with social science experimental data, at least in the beginning. There are a few holes though for the machine learning practitioner. For example: Nevertheless, these topics can be looked up in more targeted books. It¡¯s a great book and I do recommend it if you are new to statistics and you¡¯re looking for a clear presentation of the foundations that you really do need to know in applied machine learning. As I mentioned above, it is not a long read and well worth reading cover to cover. With that being said, not all chapters are relevant or directly useful to you as a machine learning practitioner. Below is a breakdown or suggested reading list of the book for machine learning practitioners. I think you need to have some understanding of foundational statistics no matter what. I would recommend reading the first few chapters in order to get this grounding, at least: To beef-up your skills in understanding your training data and in data preparation, I would recommend the following three chapters: For evaluating and comparing machine learning models and model parameters, you can use statistical hypothesis tests. To get started in this area, I would recommend the following two chapters: You could probably skip the other chapters. The chapter on linear regression (Chapter 13) might be of interest if you use the method and are interested in a deeper idea of how and why it works. Do you agree with this reading plan?
Let me know in the comments below. This section provides more resources on the topic if you are looking to go deeper. In this post, you discovered the book ¡°Statistics in Plain English¡± for learning about statistical methods without getting too bogged down in theory (proofs and derivations) nor implementation details (pages of code and commands for proprietary statistical packages). Specifically, you learned: Do you have this book or have you read it?
What do you think of it? Share your thoughts below. Are you thinking of getting this book?
Why or why not? ¡¦by writing lines of code in python Discover how in my new Ebook:Statistical Methods for Machine Learning It provides self-study tutorials on topics like:Hypothesis Tests, Correlation, Nonparametric Stats, Resampling, and much more¡¦ Skip the Academics. Just Results. Click to learn more. I am inclined to get this book, though according to a few of the Amazon reviews this book has a lot of errors. Did the errors affect your reading experience? Thanks. I did not suffer issues, but I used it as a reference and cross-ref everything across multiple sources. Same as the Avi i use to read reviews first before buying.
The reviews are not as expected. Still not sure to buy it or not.
<U+0001F642> Find a book that is perfect for you. Comment  Name (required)  Email (will not be published) (required)  Website Hi, I'm Jason Brownlee, Ph.D.

My goal is to make developers like YOU awesome at applied machine learning."
2018-07-04,"How to Generate Random Numbers in Python","https://machinelearningmastery.com/how-to-generate-random-numbers-in-python/","The use of randomness is an important part of the configuration and evaluation of machine learning algorithms. From the random initialization of weights in an artificial neural network, to the splitting of data into random train and test sets, to the random shuffling of a training dataset in stochastic gradient descent, generating random numbers and harnessing randomness is a required skill. In this tutorial, you will discover how to generate and work with random numbers in Python. After completing this tutorial, you will know: Let¡¯s get started. How to Generate Random Numbers in PythonPhoto by Harold Litwiler, some rights reserved. This tutorial is divided into 3 parts; they are: Take my free 7-day email crash course now (with sample code). Click to sign-up and also get a free PDF Ebook version of the course. Download Your FREE Mini-Course The source of randomness that we inject into our programs and algorithms is a mathematical trick called a pseudorandom number generator. A random number generator is a system that generates random numbers from a true source of randomness. Often something physical, such as a Geiger counter, where the results are turned into random numbers. We do not need true randomness in machine learning. Instead we can use pseudorandomness. Pseudorandomness is a sample of numbers that look close to random, but were generated using a deterministic process. Shuffling data and initializing coefficients with random values use pseudorandom number generators. These little programs are often a function that you can call that will return a random number. Called again, they will return a new random number. Wrapper functions are often also available and allow you to get your randomness as an integer, floating point, within a specific distribution, within a specific range, and so on. The numbers are generated in a sequence. The sequence is deterministic and is seeded with an initial number. If you do not explicitly seed the pseudorandom number generator, then it may use the current system time in seconds or milliseconds as the seed. The value of the seed does not matter. Choose anything you wish. What does matter is that the same seeding of the process will result in the same sequence of random numbers. Let¡¯s make this concrete with some examples. The Python standard library provides a module called random that offers a suite of functions for generating random numbers. Python uses a popular and robust pseudorandom number generator called the Mersenne Twister. In this section, we will look at a number of use cases for generating and using random numbers and randomness with the standard Python API. The pseudorandom number generator is a mathematical function that generates a sequence of nearly random numbers. It takes a parameter to start off the sequence, called the seed. The function is deterministic, meaning given the same seed, it will produce the same sequence of numbers every time. The choice of seed does not matter. The seed() function will seed the pseudorandom number generator, taking an integer value as an argument, such as 1 or 7. If the seed() function is not called prior to using randomness, the default is to use the current system time in milliseconds from epoch (1970). The example below demonstrates seeding the pseudorandom number generator, generates some random numbers, and shows that reseeding the generator will result in the same sequence of numbers being generated. Running the example seeds the pseudorandom number generator with the value 1, generates 3 random numbers, reseeds the generator, and shows that the same three random numbers are generated. It can be useful to control the randomness by setting the seed to ensure that your code produces the same result each time, such as in a production model. For running experiments where randomization is used to control for confounding variables, a different seed may be used for each experimental run. Random floating point values can be generated using the random() function. Values will be generated in the range between 0 and 1, specifically in the interval [0,1). Values are drawn from a uniform distribution, meaning each value has an equal chance of being drawn. The example below generates 10 random floating point values. Running the example generates and prints each random floating point value. The floating point values could be rescaled to a desired range by multiplying them by the size of the new range and adding the min value, as follows: Where min and max are the minimum and maximum values of the desired range respectively, and value is the randomly generated floating point value in the range between 0 and 1. Random integer values can be generated with the randint() function. This function takes two arguments: the start and the end of the range for the generated integer values. Random integers are generated within and including the start and end of range values, specifically in the interval [start, end]. Random values are drawn from a uniform distribution. The example below generates 10 random integer values between 0 and 10. Running the example generates and prints 10 random integer values. Random floating point values can be drawn from a Gaussian distribution using the gauss() function. This function takes two arguments that correspond to the parameters that control the size of the distribution, specifically the mean and the standard deviation. The example below generates 10 random values drawn from a Gaussian distribution with a mean of 0.0 and a standard deviation of 1.0. Note that these parameters are not the bounds on the values and that the spread of the values will be controlled by the bell shape of the distribution, in this case proportionately likely above and below 0.0. Running the example generates and prints 10 Gaussian random values. Random numbers can be used to randomly choose an item from a list. For example, if a list had 10 items with indexes between 0 and 9, then you could generate a random integer between 0 and 9 and use it to randomly select an item from the list. The choice() function implements this behavior for you. Selections are made with a uniform likelihood. The example below generates a list of 20 integers and gives five examples of choosing one random item from the list. Running the example first prints the list of integer values, followed by five examples of choosing and printing a random value from the list. We may be interested in repeating the random selection of items from a list to create a randomly chosen subset. Importantly, once an item is selected from the list and added to the subset, it should not be added again. This is called selection without replacement because once an item from the list is selected for the subset, it is not added back to the original list (i.e. is not made available for re-selection). This behavior is provided in the sample() function that selects a random sample from a list without replacement. The function takes both the list and the size of the subset to select as arguments. Note that items are not actually removed from the original list, only selected into a copy of the list. The example below demonstrates selecting a subset of five items from a list of 20 integers. Running the example first prints the list of integer values, then the random sample is chosen and printed for comparison. Randomness can be used to shuffle a list of items, like shuffling a deck of cards. The shuffle() function can be used to shuffle a list. The shuffle is performed in place, meaning that the list provided as an argument to the shuffle() function is shuffled rather than a shuffled copy of the list being made and returned. The example below demonstrates randomly shuffling a list of integer values. Running the example first prints the list of integers, then the same list after it has been randomly shuffled. In machine learning, you are likely using libraries such as scikit-learn and Keras. These libraries make use of NumPy under the covers, a library that makes working with vectors and matrices of numbers very efficient. NumPy also has its own implementation of a pseudorandom number generator and convenience wrapper functions. NumPy also implements the Mersenne Twister pseudorandom number generator. Let¡¯s look at a few examples of generating random numbers and using randomness with NumPy arrays. The NumPy pseudorandom number generator is different from the Python standard library pseudorandom number generator. Importantly, seeding the Python pseudorandom number generator does not impact the NumPy pseudorandom number generator. It must be seeded and used separately. The seed() function can be used to seed the NumPy pseudorandom number generator, taking an integer as the seed value. The example below demonstrates how to seed the generator and how reseeding the generator will result in the same sequence of random numbers being generated. Running the example seeds the pseudorandom number generator, prints a sequence of random numbers, then reseeds the generator showing that the exact same sequence of random numbers is generated. An array of random floating point values can be generated with the rand() NumPy function. If no argument is provided, then a single random value is created, otherwise the size of the array can be specified. The example below creates an array of 10 random floating point values drawn from a uniform distribution. Running the example generates and prints the NumPy array of random floating point values. An array of random integers can be generated using the randint() NumPy function. This function takes three arguments, the lower end of the range, the upper end of the range, and the number of integer values to generate or the size of the array. Random integers will be drawn from a uniform distribution including the lower value and excluding the upper value, e.g. in the interval [lower, upper). The example below demonstrates generating an array of random integers. Running the example generates and prints an array of 20 random integer values between 0 and 10. An array of random Gaussian values can be generated using the randn() NumPy function. This function takes a single argument to specify the size of the resulting array. The Gaussian values are drawn from a standard Gaussian distribution; this is a distribution that has a mean of 0.0 and a standard deviation of 1.0. The example below shows how to generate an array of random Gaussian values. Running the example generates and prints an array of 10 random values from a standard Gaussian distribution. Values from a standard Gaussian distribution can be scaled by multiplying the value by the standard deviation and adding the mean from the desired scaled distribution. For example: Where mean and stdev are the mean and standard deviation for the desired scaled Gaussian distribution and value is the randomly generated value from a standard Gaussian distribution. A NumPy array can be randomly shuffled in-place using the shuffle() NumPy function. The example below demonstrates how to shuffle a NumPy array. Running the example first generates a list of 20 integer values, then shuffles and prints the shuffled array. This section provides more resources on the topic if you are looking to go deeper. In this tutorial, you discovered how to generate and work with random numbers in Python. Specifically, you learned: Do you have any questions?
Ask your questions in the comments below and I will do my best to answer. ¡¦by writing lines of code in python Discover how in my new Ebook:Statistical Methods for Machine Learning It provides self-study tutorials on topics like:Hypothesis Tests, Correlation, Nonparametric Stats, Resampling, and much more¡¦ Skip the Academics. Just Results. Click to learn more. Beautiful! Thank you so much! This was just what I needed today and I found it randomly, or should I say pseudorandomly! Haha! I¡¯m glad it helped. thanks for great article ¡¦ It helped  me to understand the different ways  to generate random numbers.. Thanks. Comment  Name (required)  Email (will not be published) (required)  Website Hi, I'm Jason Brownlee, Ph.D.

My goal is to make developers like YOU awesome at applied machine learning."
2018-07-02,"Statistics for Evaluating Machine Learning Models","https://machinelearningmastery.com/statistics-for-evaluating-machine-learning-models/","Tom Mitchell¡¯s classic 1997 book ¡°Machine Learning¡± provides a chapter dedicated to statistical methods for evaluating machine learning models. Statistics provides an important set of tools used at each step of a machine learning project. A practitioner cannot effectively evaluate the skill of a machine learning model without using statistical methods. Unfortunately, statistics is an area that is foreign to most developers and computer science graduates. This makes the chapter in Mitchell¡¯s seminal machine learning text an important, if not required, reading by practitioners. In this post, you will discover statistical methods recommended by Mitchel to evaluate and compare machine learning models. After reading this post, you will know: Let¡¯s get started. Statistics for Evaluating Machine Learning ModelsPhoto by Pierre (Rennes), some rights reserved. Tom Mitchell wrote what might be the classic textbook on applied machine learning, titled ¡°Machine Learning¡± and released in 1997. In the book he dedicated an entire chapter to the statistical methods required to evaluate machine learning models and algorithms. Specifically, Chapter 5 titled ¡°Evaluating Hypotheses¡°. Chapter 5 presents basic concepts from statistics and estimation theory, focusing on evaluating the accuracy of hypotheses using limited samples of data. This includes the calculation of confidence intervals for estimating hypothesis accuracy and methods for comparing the accuracy of learning methods. <U+2014> Page 16, Machine Learning, 1997. In this post, we are going to take a closer look at this chapter and review the statistical methods recommended by Mitchell at that time. The fundamentals of statistical methods do not change and may be just as useful and relevant now, 20 years since the publication of the book. It is important to note that when Mitchell refers to hypotheses, he is referring to learned models, the results of running a learning algorithm on a dataset. Evaluating and comparing hypotheses means comparing learned models, which is different from evaluating and comparing machine learning algorithms, which could be trained on different samples from the same problem or different problems. Chapter 5 on evaluating hypotheses is divided into 7 parts; they are as follows: We will spend time looking at each section and summarize the statistical methods and recommendations made. Take my free 7-day email crash course now (with sample code). Click to sign-up and also get a free PDF Ebook version of the course. Download Your FREE Mini-Course The chapter starts off by stating the importance of evaluating hypotheses in machine learning. Empirically evaluating the accuracy of hypotheses is fundamental to machine learning. <U+2014> Page 128, Machine Learning, 1997. The chapter is motivated by three questions; they are: All three questions are closely related. The first question raises concerns over errors in the estimate of model skill and motivates the need for confidence intervals. The second question raises concerns about making decisions based on model skill on small samples and motivates statistical hypothesis testing. And finally, the third question considers the economical use of small samples and motivates resampling methods such as k-fold cross-validation. This chapter discusses methods for evaluating learned hypotheses, methods for comparing the accuracy of two hypotheses, and methods for comparing the accuracy of two learning algorithms when only limited data is available. <U+2014> Page 129, Machine Learning, 1997. The motivation closes with a reminder of the difficulty of estimating the skill of a hypothesis. Specifically the introduction of bias and variance in the estimate of the skill of a model: The skill or prediction error of a model must be estimated, and as an estimate, it will contain error. This is made clear by distinguishing between the true error of a model and the estimated or sample error. One is the error rate of the hypothesis over the sample of data that is available. The other is the error rate of the hypothesis over the entire unknown distribution D of examples. <U+2014> Page 130, Machine Learning, 1997. We want to know the true error, but we must work with the estimate, approximated from a data sample. This raises the question of how good is a given estimate of error? One approach is to calculate a confidence interval around the sample error that is large enough to cover the true error with a very high likelihood, such as 95%. Assuming that the error measure is a discrete proportion, such as classification error, the calculation of the confidence interval is calculated as follows: Calculation of Confidence Interval for Classification ErrorTaken from Machine Learning, 1997. Where error_s is the sample error, n is the total number of instances in the test set used to calculate the sample error and 1.96 is the critical value from the Gaussian distribution for a likelihood of 95%. The equation to calculate the confidence interval from the previous section makes many assumptions. This section works through these assumptions in order to provide a basis of understanding for the calculation. This section introduces basic notions from statistics and sampling theory, including probability distributions, expected value, variance, Binomial and Normal distributions, and two-sided and one-sided intervals. <U+2014> Page 132, Machine Learning, 1997. Usefully, a table is provided that summarizes the key concepts of this section, provided below. Summary of Key Statistical Concepts for Calculating a Confidence IntervalTaken from Machine Learning, 1997. This section provides an important statistical foundation for the confidence interval and is recommended reading. To save repeating all of this theory, the crux of the section is as follows: Given the equation to calculate the confidence intervals for proportional values and the statistical reasoning behind the equation, a general procedure is presented to calculate confidence intervals. The procedure is summarized below. General Procedure for Calculating Confidence IntervalsTaken from Machine Learning, 1997. The central limit theorem is also presented. It can be summarized by the finding that the sum (or normalized sum in the case of the mean) of independent observations will represent a sample from a Gaussian distribution. For example, the mean skill of a model on different independent data samples will be Gaussian. This is an invaluable finding as we know so much about the Gaussian and can comment on the likelihood of two samples (mean values) belonging to the same or different Gaussian distributions, such as in the case of the skill of machine learning algorithms. The Central Limit Theorem is a very useful fact because it implies that whenever we define an estimator that is the mean of some sample (e.g., errors(h) is the mean error), the distribution governing this estimator can be approximated by a Normal distribution for sufficiently large n. <U+2014> Page 143, Machine Learning, 1997. This section looks at applying the general procedure for calculating confidence intervals to the estimated difference in classification error between two models. The approach assumes that each model was trained on a different independent sample of the data. Therefore, the calculation of the confidence interval in the difference in error between the two models adds the variance from each model. Confidence Interval for the Difference in Error Between Two ModelsTaken from Machine Learning, 1997. This section also introduces the idea of statistical hypothesis testing as an alternative to calculating confidence intervals. In some cases we are interested in the probability that some specific conjecture is true, rather than in confidence intervals for some parameter. <U+2014> Page 145, Machine Learning, 1997. Interestingly, the topic is motivated by the likelihood of a one-sided confidence interval containing the true estimate of error for a model in order to determine the probability of one model being better than another. I found this explanation less clear than it should have been. This final content section of the chapter focuses on the comparison of machine learning algorithms. This is different from comparing models (hypotheses) as comparing algorithms involves training them and evaluating them potentially on multiple different samples of data from the domain. The comparison of two algorithms is motivated by estimating the expected or mean difference between the two methods. A procedure is presented that uses k-fold cross-validation where each algorithm is trained and evaluated on the same splits of the data. A final mean difference in error is calculated, from which a confidence interval can be estimated. The calculation of the confidence interval is updated to account for the reduced number of degrees of freedom as each algorithm is evaluated on the same test set. The paired Student¡¯s t-test is introduced as a statistical hypothesis test for quantifying the likelihood that two means belong to the same (or different) distributions. This test can be used with the outlined procedure, but only if each train and test set contain independent samples, a fact that is not the case with default k-fold cross-validation. In particular, in this idealized method we modify the procedure of Table 5.5 so that on each iteration through the loop it generates a new random training set Si and new random test set Ti by drawing from this underlying instance distribution instead of drawing from the fixed sample Do <U+2014> Page 148, Machine Learning, 1997. The section ends by outlining practical considerations when comparing machine learning algorithms. Mitchell reminds us that the Student¡¯s t-test does not technically apply in the case where we use resampling methods. Nevertheless, he recommends using k-fold cross-validation or random sampling in order to estimate the variance in the estimate of model error, as they are the only methods available. This is less than ideal as the expectations of the statistical test will be violated, increasing type I errors. It is wise to keep in mind that statistical models rarely fit perfectly the practical constraints in testing learning algorithms when available data is limited. Nevertheless, they do provide approximate confidence intervals that can be of great help in interpreting experimental comparisons of learning methods. <U+2014> Page 150, Machine Learning, 1997. The chapter ends with a summary of the main points hit, exercises that can be completed to confirm an understanding of the equations, and a great list of references and further reading. Briefly, the main points are: Interestingly, two technical reports by Thomas Dietterich are referenced. Dietterich went on to publish the important 1998 paper titled ¡°Approximate Statistical Tests for Comparing Supervised Classification Learning Algorithms¡± that describes the unreliability of the paired Student¡¯s t-test when comparing machine learning algorithms with random resampling and k-fold cross-validation. This section provides more resources on the topic if you are looking to go deeper. In this post, you discovered statistical methods to evaluate and compare machine learning models. Specifically, you learned: Do you have any questions?
Ask your questions in the comments below and I will do my best to answer. ¡¦by writing lines of code in python Discover how in my new Ebook:Statistical Methods for Machine Learning It provides self-study tutorials on topics like:Hypothesis Tests, Correlation, Nonparametric Stats, Resampling, and much more¡¦ Skip the Academics. Just Results. Click to learn more. Nice! I consider this a really important topic that is sometimes overlooked. A Bayesian approach to this topic would be really interesting¡¦do you know any reference about it? Thanks Peter. Not off-hand, try a search on scholar.google.com Hi Jason, Thank you for writing this nice post. Are you considering writing a blog post about statistical tests for comparing machine learning models with concrete Python examples (or a case study)? Best,
Elie Yes, I have some written and scheduled. Comment  Name (required)  Email (will not be published) (required)  Website Hi, I'm Jason Brownlee, Ph.D.

My goal is to make developers like YOU awesome at applied machine learning."
2018-06-29,"The Close Relationship Between Applied Statistics and Machine Learning","https://machinelearningmastery.com/relationship-between-applied-statistics-and-machine-learning/","The machine learning practitioner has a tradition of algorithms and a pragmatic focus on results and model skill above other concerns such as model interpretability. Statisticians work on much the same type of modeling problems under the names of applied statistics and statistical learning. Coming from a mathematical background, they have more of a focus on the behavior of models and explainability of predictions. The very close relationship between the two approaches to the same problem means that both fields have a lot to learn from each other. The statisticians need to consider algorithmic methods was called out in the classic ¡°two cultures¡± paper. Machine learning practitioners must also take heed, keep an open mind, and learn both the terminology and relevant methods from applied statistics. In this post, you will discover that machine learning and statistical learning are two closely related but different perspectives on the same problem. After reading this post, you will know: Let¡¯s get started. The Close Relationship Between Applied Statistics and Machine LearningPhoto by James Loesch, some rights reserved. Machine learning is a subfield of artificial intelligence and is related to the broader field of computer science. When it comes to developing machine learning models in order to make predictions, there is a heavy focus on algorithms, code, and results. Machine learning is a lot broader than developing models in order to make predictions, as can be seen by the definition in the classic 1997 textbook by Tom Mitchell. The field of machine learning is concerned with the question of how to construct computer programs that automatically improve with experience. <U+2014> Page xv, Machine Learning, 1997. Here, we can see that from a research perspective, machine learning is really the study of learning with computer programs. It just so happens that some of these learning programs are useful for predictive modeling problems, and some in fact have been borrowed from other fields, such as statistics. Linear regression is a perfect example. It is a more-than-a-century-old method from the (at the time: nascent) field of statistics that is used for fitting a line or plane to real-valued data. From a machine learning perspective, we look at it as a system for learning weights (coefficients) in response to examples from a domain. Many methods have been developed in the field of artificial intelligence and machine learning, sometimes by statisticians, that prove very useful for the task of predictive modeling. A good example is classification and regression trees that bears no resemblance to classical methods in statistics. Take my free 7-day email crash course now (with sample code). Click to sign-up and also get a free PDF Ebook version of the course. Download Your FREE Mini-Course The useful part of machine learning for the practitioner may be called predictive modeling. This explicitly ignores distinctions between statistics and machine learning. It also shucks off the broader objectives of statistics (understanding data) and machine learning (understanding learning in software) and only concerns itself, as its name suggests, with developing models that make predictions. The term predictive modeling may stir associations such as machine learning, pattern recognition, and data mining. Indeed, these associations are appropriate and the methods implied by these terms are an integral piece of the predictive modeling process. But predictive modeling encompasses much more than the tools and techniques for uncovering patterns within data. The practice of predictive modeling defines the process of developing a model in a way that we can understand and quantify the model¡¯s prediction accuracy on future, yet-to-be-seen data. <U+2014> Page vii, Applied Predictive Modeling, 2013 Predictive modeling provides a laser-focus on developing models with the objective of getting the best possible results with regard to some measure of model skill. This pragmatic approach often means that results in the form of maximum skill or minimum error are sought at the expense of almost everything else. It doesn¡¯t really matter what we call the process, machine learning or predictive modeling. In some sense it is marketing and group identification. Getting results and delivering value matters more to the practitioner. The process of working with a dataset and developing a predictive model is also a task in statistics. A statistician may have traditionally referred to the activity as applied statistics. Statistics is a subfield of mathematics, and this heritage gives a focus of well defined, carefully chosen methods. A need to understand not only why a specific model was chosen, but also how and why specific predictions are made. From this perspective, often model skill is important, but less important than the interpretability of the model. Nevertheless, modern statisticians have formulated a new perspective as a subfield of applied statistics called ¡°statistical learning¡°. It may be the statistics equivalent of ¡°predictive modeling¡± where model skill is important, but perhaps a stronger emphasis is given to careful selection and introduction of the learning models. Statistical learning refers to a set of tools for modeling and understanding complex datasets. It is a recently developed area in statistics and blends with parallel developments in computer science and, in particular, machine learning. <U+2014> Page vii, An Introduction to Statistical Learning with Applications in R, 2013. We can see that there is a bleeding of ideas between fields and subfields in statistics. The machine learning practitioner must be aware of both the machine learning and statistical-based approach to the problem. This is especially important given the use of different terminology in both domains. In his course on statistics, Rob Tibshirani, a statistician who also has a foot in machine learning, provides a glossary that maps terms in statistics to terms in machine learning, reproduced below. Glossary Mapping Terms in Statistics to Terms in Machine Learning This highlights the deeper need for the machine learning practitioner to focus on predictive modeling and stay open to methods, ideas, and terminology, regardless of the field of origin. This may apply to modern fields like bioinformatics and econometrics but applies more so to the tightly related and much older field of statistics. Recently, and perhaps still now, applied statisticians looked down the field of machine learning and the practice of results-at-any-cost predictive modeling. Both fields offer tremendous value, but perhaps on subtly different flavors of the same general problem of predictive modeling. Real and valuable contributions have been made to modeling from the computer science perspective of machine learning such as decision trees mentioned above and artificial neural networks, more recently relabeled deep learning, to name two well known examples. Just as the machine learning practitioner must keep an eye on applied statistics and statistical learning, the statistician must keep an eye on machine learning. This call was made clearly in the now (perhaps famous) 2001 paper titled ¡°Statistical Modeling: The Two Cultures¡± by Leo Breiman. In it, he contrasts the ¡°data modeling culture¡± of statisticians to the ¡°algorithmic modeling culture¡± of all other fields, to which machine learning belongs. He highlights these cultures as ways of thinking about the same problem of mapping inputs to outputs, where the statistical approach is to focus on goodness of fit tests and the algorithmic approach focuses on predictive accuracy. He suggests that the field of statistics will suffer both by losing relevance and in the fragility of the methods by ignoring the algorithmic approach. The classical approach he refers to as ¡°data models,¡± a subtle but important shift in focus where a practitioner chooses and focuses on the behavior of the model (e.g. logistic regression) rather than the data and processes that may have generated it. This might be characterized (perhaps unfairly) as focusing on making the data fit the model rather than choosing or adapting the model to fit the data. The statistical community has been committed to the almost exclusive use of data models. This commitment has led to irrelevant theory, questionable conclusions, and has kept statisticians from working on a large range of interesting current problems. [¡¦] If our goal as a field is to use data to solve problems, then we need to move away from exclusive dependence on data models and adopt a more diverse set of tools. It¡¯s an important paper, still relevant and a great read more than 15 years later. The emergence of subfields like ¡°statistical learning¡± by statisticians suggests that headway is being made. This section provides more resources on the topic if you are looking to go deeper. In this post, you discovered that machine learning and statistical learning are two closely related but different perspectives on the same problem. Specifically, you learned: Do you have any questions?
Ask your questions in the comments below and I will do my best to answer. ¡¦by writing lines of code in python Discover how in my new Ebook:Statistical Methods for Machine Learning It provides self-study tutorials on topics like:Hypothesis Tests, Correlation, Nonparametric Stats, Resampling, and much more¡¦ Skip the Academics. Just Results. Click to learn more. Reminds me of when I was an engineering undergrad (a long time ago). There was a similar cultural divide. The mathematicians thought engineers were ¡°crude¡± for taking formulas and applying them just because they worked, while not really knowing why. And the engineers thought the mathematicians were impractical with all their theorizing for the sake of it! Dear Ken and Dr Jason,
It reminds me of my first year mathematics lecturer who said to his students that the calculus involved in producing CT scans was developed in the 1930s. In the 1930s the technology to process images was non-existent, let alone computers. Thus the engineering and application of the calculus was not possible. It may well be that pure mathematics may be ahead of engineering and the pure mathematicians have to wait for their theories to come to reality. Regards
Anthony of Sydney It may be and there is a place for it for sure.  But today we need results and must focus on what is working. Yep. Deep learning, which is supposed to replace most of machine learning in the near future rarely makes use of statistics. I could not disagree more. Deep learning is not replacing all classical or ml methods, it is just one more method to use. You cannot choose/understand training data or evaluate/present model performance without stats, deep learning or otherwise. Perhaps skim this post for more reasons:https://machinelearningmastery.com/what-is-statistics/ Comment  Name (required)  Email (will not be published) (required)  Website Hi, I'm Jason Brownlee, Ph.D.

My goal is to make developers like YOU awesome at applied machine learning."
2018-06-27,"What is Statistics (and why is it important in machine learning)?","https://machinelearningmastery.com/what-is-statistics/","Statistics is a collection of tools that you can use to get answers to important questions about data. You can use descriptive statistical methods to transform raw observations into information that you can understand and share. You can use inferential statistical methods to reason from small samples of data to whole domains. In this post, you will discover clearly why statistics is important in general and for machine learning and generally the types of methods that are available. After reading this post, you will know: Let¡¯s get started. A Gentle Introduction to StatisticsPhoto by Mike Sutherland, some rights reserved. Machine learning and statistics are two tightly related fields of study. So much so that statisticians refer to machine learning as ¡°applied statistics¡± or ¡°statistical learning¡± rather than the computer-science-centric name. Machine learning is almost universally presented to beginners assuming that the reader has some background in statistics. We can make this concrete with a few cherry picked examples. Take a look at this quote from the beginning of a popular applied machine learning book titled ¡°Applied Predictive Modeling¡°: ¡¦ the reader should have some knowledge of basic statistics, including variance, correlation, simple linear regression, and basic hypothesis testing (e.g. p-values and test statistics). <U+2014> Page vii, Applied Predictive Modeling, 2013 Here¡¯s another example from the popular ¡°Introduction to Statistical Learning¡± book: We expect that the reader will have had at least one elementary course in statistics. <U+2014> Page 9, An Introduction to Statistical Learning with Applications in R, 2013. Even when statistics is not a prerequisite, some primitive prior knowledge is required as can be seen in this quote from the widely read ¡°Programming Collective Intelligence¡°: ¡¦ this book does not assume you have any prior knowledge of [¡¦] or statistics. [¡¦] but having some knowledge of trigonometry and basic statistics will help you understand the algorithms. <U+2014> Page xiii, Programming Collective Intelligence: Building Smart Web 2.0 Applications, 2007. In order to be able to understand machine learning, some basic understanding of statistics is required. To see why this is the case, we must first understand why we need the field of statistics in the first place. Take my free 7-day email crash course now (with sample code). Click to sign-up and also get a free PDF Ebook version of the course. Download Your FREE Mini-Course Raw observations alone are data, but they are not information or knowledge. Data raises questions, such as: Although they appear simple, these questions must be answered in order to turn raw observations into information that we can use and share. Beyond raw data, we may design experiments in order to collect observations. From these experimental results we may have more sophisticated questions, such as: Questions of this type are important. The results matter to the project, to stakeholders, and to effective decision making. Statistical methods are required to find answers to the questions that we have about data. We can see that in order to both understand the data used to train a machine learning model and to interpret the results of testing different machine learning models, that statistical methods are required. This is just the tip of the iceberg as each step in a predictive modeling project will require the use of a statistical method. Statistics is a subfield of mathematics. It refers to a collection of methods for working with data and using data to answer questions. Statistics is the art of making numerical conjectures about puzzling questions. [¡¦] The methods were developed over several hundred years by people who were looking for answers to their questions. <U+2014> Page xiii, Statistics, Fourth Edition, 2007. It is because the field is comprised of a grab bag of methods for working with data that it can seem large and amorphous to beginners. It can be hard to see the line between methods that belong to statistics and methods that belong to other fields of study. Often a technique can be both a classical method from statistics and a modern algorithm used for feature selection or modeling. Although a working knowledge of statistics does not require deep theoretical knowledge, some important and easy-to-digest theorems from the relationship between statistics and probability can provide a valuable foundation. Two examples include the law of large numbers and the central limit theorem; the first aids in understanding why bigger samples are often better and the second provides a foundation for how we can compare the expected values between samples (e.g mean values). When it comes to the statistical tools that we use in practice, it can be helpful to divide the field of statistics into two large groups of methods: descriptive statistics for summarizing data and inferential statistics for drawing conclusions from samples of data. Statistics allow researchers to collect information, or data, from a large number of people and then summarize their typical experience. [¡¦] Statistics are also used to reach conclusions about general differences between groups. [¡¦] Statistics can also be used to see if scores on two variables are related and to make predictions. Pages ix-x, Statistics in Plain English, Third Edition, 2010. Descriptive statistics refer to methods for summarizing raw observations into information that we can understand and share. Commonly, we think of descriptive statistics as the calculation of statistical values on samples of data in order to summarize properties of the sample of data, such as the common expected value (e.g. the mean or median) and the spread of the data (e.g. the variance or standard deviation). Descriptive statistics may also cover graphical methods that can be used to visualize samples of data. Charts and graphics can provide a useful qualitative understanding of both the shape or distribution of observations as well as how variables may relate to each other. Inferential statistics is a fancy name for methods that aid in quantifying properties of the domain or population from a smaller set of obtained observations called a sample. Commonly, we think of inferential statistics as the estimation of quantities from the population distribution, such as the expected value or the amount of spread. More sophisticated statistical inference tools can be used to quantify the likelihood of observing data samples given an assumption. These are often referred to as tools for statistical hypothesis testing, where the base assumption of a test is called the null hypothesis. There are many examples of inferential statistical methods given the range of hypothesises we may assume and the constraints we may impose on the data in order to increase the power or likelihood that the finding of the test is correct. This section provides more resources on the topic if you are looking to go deeper. In this post, you discovered clearly why statistics is important in general and for machine learning, and generally the types of methods that are available. Specifically, you learned: Do you have any questions?
Ask your questions in the comments below and I will do my best to answer. ¡¦by writing lines of code in python Discover how in my new Ebook:Statistical Methods for Machine Learning It provides self-study tutorials on topics like:Hypothesis Tests, Correlation, Nonparametric Stats, Resampling, and much more¡¦ Skip the Academics. Just Results. Click to learn more. Hi
If dataset is tall. Then how do we sample it? I mean what methods are used for sample selection.
Regards By tall, I guess you mean many rows. You can randomly select rows as a sub-sample. Yes i mean largw number of rows. But how may i get samples of good quality to represent data in majority. Which method to be used Often descriptive statistics can be used to confirm that a data sample is representative of the population. Hypothesis tests can confirm these findings. How can we collaborate these statistic skills with programming and apply them for solving the real world problems, most probably for machine learning and AI problems? Good question, here are 10 examples:https://machinelearningmastery.com/statistical-methods-in-an-applied-machine-learning-project/ Comment  Name (required)  Email (will not be published) (required)  Website Hi, I'm Jason Brownlee, Ph.D.

My goal is to make developers like YOU awesome at applied machine learning."
