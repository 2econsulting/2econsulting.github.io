"","site","date","headline","url_address","text","keyword"
"1","kaggle",2018-11-15,"Data Notes: Impact of Game of Thrones on US Baby Names","http://blog.kaggle.com/2018/11/15/data-notes-impact-of-game-of-thrones-on-us-baby-names/","Are Game of Thrones fans naming their babies Sansa and Tyrion? Enjoy these new, intriguing and overlooked datasets and kernels 1.<U+0001F476> Impact of Game of Thrones on US Baby Names (Link) 2. <U+0001F3E5> Skin Lesion Analyzer + Tensorflow.js Web App (Link) 3. <U+0001F393> Where do People Learn ML / DS? (Link) 4. <U+0001F4B0> What Makes a Kaggler Valuable? (Link) 5. <U+0001F4BE> What Software do Kagglers Use to Code? (Link) 6. <U+0001F40D> A Deep Dive into the Usage of R, Python, or Both (Link) 7.<U+00A0><U+0001F47D> UFO Report Analysis - MapPlots (Link) 8. <U+0001F4DD> Dataset: 2018 Kaggle ML & DS Survey (Link) 9. <U+0001F691> Dataset: CMS Estimated Uninsured People (Link) 10. <U+0001F4C8> Dataset: AMEX, NYSE, NASDAQ Stock Histories (Link) Working with image data? Try using scikit-image to process it all! Copyright ¨Ï 2018 Kaggle, All rights reserved.","Keyword(freq): throne(2), baby(1), dataset(1), fan(1), history(1), kaggler(1), kernel(1), mapplot(1), right(1), NA(NA)"
"2","datacamp",2018-11-12,"Angela Bassa discusses managing data science teams and much more.","https://www.datacamp.com/community/blog/managing-data-science-teams","Hugo Bowne-Anderson, the host of DataFramed, the DataCamp podcast, recently interviewed Angela Bassa, the Director of Data Science at iRobot. Here is the podcast link. Hugo:    Hi there Angela, and welcome to DataFramed. Angela:    Thanks, thanks for having me. Hugo:    It's a great pleasure to have you on the show, and I'm really excited to be talking about managing data science teams today, and your work at iRobot. But, before we get into this conversation, I'd love to find out a bit about you. I thought maybe you could start by telling us what you're known for in the data community. Angela:    Sure. I've been involved in data science under that moniker for, let's call it four, five years. Most of the contributions that I've made, you know I don't have a package named after me, or anything like that. But, I've spoken a lot about how to do data science within a business context in terms of corporate data science, and also how to develop the skills to succeed as a data scientist within a larger organization. I'd like to think that folks who care about what I have to say, probably care about that. Hugo:    Absolutely. I think that's really important, particularly at this stage in the way data science is developing to consider what's happening in a business context, because a lot of people I think talk about the kind of state of the art techniques, and all of the buzz terms we hear. But, we do need to remember that data science within an organization is there in order to be one set of inputs into the decision making process, right? Angela:    Yeah, exactly. There are lots of companies that have their product be data scientific or algorithmic, but a large portion of data science performed within a business context is actually done in service of the business, rather than packaged as its own product. Really understanding how that fits within the larger organization strategically really matters in terms of being successful. Hugo:    Yeah, and that's a point we're going to get to in this conversation. Before we get there though, I'd like to know a bit about your trajectory in terms of how you got into data science initially. Angela:    The short answer is I was really lucky. I can't claim to have gone to school with the ultimate goal of being a data science professional, even though I'm really, really glad that that's how things turned out. I went to undergrad, and I went to an engineering school, so obviously what you do in an engineering school is you don't do engineering. I did my undergrad in math, and they recruit really heavily on Wall Street for math professionals. It was either that or academia, and I didn't really want to join the academic environment, so off to Wall Street I went. I hated it. It was such a bad personality fit. But I did get to work with data. That was my role, was to do data analysis, and monitor data activity in the market. That part I really liked. Nothing against the financial world, I still have friends there. It just wasn't for me. Hugo:    When was that? Angela:    Oh my gosh, that was about 15 years ago. Hugo:    Okay. Angela:    After I left, I started doing strategy consulting because that's the other thing that you do if you don't do investment banking. You usually do strategy consulting. That's when I really started getting my hands dirty with data, and modeling in particular, rather than just monitoring. I did a lot of pharmaceutical strategies. There's a lot of statistics that go into how do you set up a controlled experiment, a randomized control trial so that you can test the efficacy of different treatments. We did a lot of that kind of consulting for large pharmaceutical companies, and biotechs, and med techs. I did that for about eight years. Angela:    I left that industry and joined a large marketing services organization. That's where I got introduced to big data. Truly big data. I mean, that's when we went from things that could run on a single machine. I mean, the machine might hang a little, but it would definitely all run within RAM, to computations that you really needed to understand how to run the computation as much as you needed to understand what the computation was. While that was exciting, the stakes were really low. I mean, if you mess up, somebody doesn't get a coupon, right? I actually, here in the Boston area where I'm located, participating in the community, and meetups, and what not, I ended up meeting some folks from a company that used to exist called EnerNOC. They've since been acquired. Angela:    That's where the great outcome really came, where I was doing data science under that name. The stakes were high enough, so if you messed up you could lead to a brownout, or a blackout, or something like that, and folks really depended on our analysis to be able to save money, to save electricity. I really enjoyed working in that, but then after a while the great folks at iRobot reached out to me, and as a nerd, the opportunity to do this thing that I love, data science, but, also work with robots, it was- Hugo:    That's pretty cool. Angela:    ... Yeah, it was hard to pass. It was really hard to pass. Hugo:    What do you do at iRobot now? Angela:    I am the Director of Data Science at iRobot. I think there are sort of two sides to what I do. One side is managing the team, a team of Data Scientists, and Analysts, and Interns, and Contractors who help us achieve our objectives. The other part of that is setting those objectives, and understanding how we can do the most good for the company. Hugo:    Great. Can you just tell us a bit about what iRobot does? Angela:    Sure. iRobot is the number one consumer robotics company. In the US for sure, I'm pretty sure it's the world as well. We are the makers of consumer robots that you may know and love, like the Roomba, and the Braava. Those are a robotic vacuum cleaner, and a robotic mop, respectively. I think it's really fantastic, because robotics is hard. This is a company that has figured out how to operate in this really difficult environment, making robots that are affordable, and that are able to help folks who have these tools sort of do more with their day. It's really exciting. Hugo:    Now I kind of want to delve into a bit about data science management. As we know, there are a lot of roads that lead to data science, and I'm sure there are a lot of roads that lead into becoming a data science manager as well. Maybe you could tell us how you actually got into this position, or into data science management in general? Angela:    Yeah. I think a lot of folks who get into management for technical fields, have a similar background. Which is that, you usually excel as an individual contributor, and then get sort of promoted into this completely different discipline. It's funny, because a lot of the heuristics that make you a really good individual contributor, don't necessarily translate when you go into management. As an individual contributor, you are answering questions, and posing questions. Really as a manager, you're scaling humans. It is a completely different discipline in and of itself. It takes time and effort to get really good at it, and I think the first step is understanding that it's a different job. Hugo:    And a job that you're not necessarily, will have ever been trained to do in terms of being a successful individual contributor in your field of expertise, right? Angela:    Yeah, exactly. As an individual contributor you may get your toes wet, in terms of providing mentorship, or working closely with interns, and helping them derive the most benefit from those kinds of relationships, those internships. But, going from being an individual contributor to being a manager, you have to remember that your goal is not to answer the question, your goal is to empower folks to answer their questions. Hugo:    What has your journey been like? Angela:    The way that I ended up in management, I think ... Well, it's funny. When I first was offered the opportunity to manage another person on a team, we interviewed several candidates, and the person who ultimately got the job. There was I think some miscommunication, because I don't have a PhD, I just have my undergraduate math degree, which I think served really well for how I started, which was in, as a Data Analyst. Back in the dark ages, before Hadoop existed. Angela:    The person that we hired had a PhD. He had just graduated. He starts day one, he finds out that he's working for me directly, as opposed to with me. He ended up quitting that day. Hugo:    Oh wow. That was your first engagement managing someone? Angela:    Yes, exactly. Hugo:    Wow. Angela:    That left a mark, so I didn't end up- Hugo:    Mm-hmm (affirmative). Angela:    ... I ended up, every time that I was offered a similar opportunity, I found a way to not take that on. Hugo:    Sure. Angela:    After- Hugo:    First impressions last. Angela:    ... I know. Then after a few years, it sort of became evident that, that was what needed to happen for this situation, the context that I was in. I was really cautious and worried, and I also didn't want to give up the role of individual contributor. Something that I had a lot of passion for, that I ... If I may so, I thought I was really good at, and I enjoyed. I was worried that the path for professional growth lay in switching tracks, and jumping into management. That isn't always the case, but it certainly seemed like the door that was open to me at the time. Angela:    I was cautious, and a little bit ... It felt bittersweet. But, after that, managing a single person, and having that second iteration worked much better. I think probably because I was more self aware, and the person that I was managing had a much better temperament. After that I ended up managing a whole engagement, where the two of us worked. Then from there, it just kept growing, where I managed a small team, and then ended up managing the function, the discipline of data science within an organization. It has been an evolution. Hugo:    Yeah, interesting. In terms of a data science team needing to deliver value for a business, we need to consider how data science is embedded in an organization. I'm wondering to your mind, what different models exist for data science in orgs, and which is your favorite, or which do you have, or which is working for you at the moment? Angela:    I have personally worked in data science under several different umbrellas. For instance, I've had teams that were under the operations branch of the org chart, under finance, and financial operations, under IT, under engineering, or under a dedicated R&D organization. Obviously, that's a lot of organizational structure, so there were a couple of re-orgs. I've even been part of several re-organizations, and one thing that I noticed is that, the data science team always changes hands, always changes branches of the org chart, every time there's been a re-org, that I've been a party of. I think that speaks to the value that data science can bring to an organization. That, it seems like different arms of a company all want to be able to leverage this really powerful discipline. Angela:    I think the key to ensure that the function is successful within an organization, independent of where it sits, whether it sits next to product management, usually when you're developing product features, or whether it sits within operations, so that you are delivering value back to the enterprise. I think the important thing there is to really allow the function to mature. Usually in companies, especially companies where data science is not the product. Because, otherwise in those cases, data science is part of the founding, right? You need that in order to deliver on the business proposition. Angela:    But, in other cases within a larger enterprise, within sort of legacy companies that are looking to employ the tool set, there's usually a couple of people who are delivering on that, and they really need time to mature as a discipline within the organization to become experts in the strategy, and the objective of that organization to be able to become experts in the data, and the artifacts, and bring that back. That's the one thing that I would say that, everything else really doesn't matter in an organizational context. But, what matters is the ability to let that team go through a couple of iterations, so they get to a point where they're past the exploration. Hugo:    I think this idea of allowing the team to become mature and evolve is incredibly important, and something we'll come back to. Something you mentioned just then is allowing the team also time to understand the data, and become experts. I think this is in the direction of facilitating, allowing the team to deliver as much value to the organization as possible. I'm wondering, just in general, what are the most important strategies as a manager to ensure that your team can deliver as much value as possible? Angela:    ... I think the metaphor that I like to imagine is, and you'll have to pardon me because I'm Brazilian, so I think in soccer, not football. But, in American football there is this concept of the lineman who creates space so that the quarterback can make his play. I think a lot of times we like to think of the manager as the quarterback, and I don't think that's right. I think the individual contributors, for their particular projects, for their tasks, are their own quarterbacks. The role of the manager is to really create the pocket, create space so that they can think, and create space so that they can see the whole field, and they can see the opportunities, and they can see the answer. Angela:    That's sort of my mentality. What I coach my team to be able to do is to become experts in the data. I think if you get asked to perform an analysis, or to answer a question, a lot of the times what happens is the person doing the asking doesn't necessarily have the imagination to envision what an answer might look like, or what might be able, right? They have this narrow view, because they are experts in something else. They're incredibly smart, but they're smart in a different thing than the thing we are smart in. When they ask a question, sometimes the question is too low level, or too high level. Angela:    Part of the role of a Data Scientist is to be that therapist, getting the question just so, so that you really get at what the person doing the asking wants. Sometimes they don't even know what they want, or they don't even know what's possible to get answers to. So being the lineman to create that space so that the quarterbacks can do their thing, and do the strategy, and figure out how to answer the question is really how I think of enabling the team to deliver the most value. Hugo:    There's so much in there. Two takeaways, I was thinking of when listening was, there's the aspect of managing expectations on both sides of what's possible, what's feasible. But, also this act of translation, and helping to turn business questions into data questions. Then, the reverse act of translation, turning the data answers into business answers as well. Angela:    I think that's fundamentally the job of a Data Scientist. Because, everybody ... I mean, it's the 21st century. Every discipline has data, everybody has information that they're using to inform their decision making. What makes data science unique is our ability to take a business question, and formally formulate it, formally articulate it in a way that we can use the tools of statistics, and in software development to create a solution that is reproducible, that is replicable, that is interpretable, and that is fit for purpose, that answers the question. Because, a lot of times, what can happen is Data Scientists will become so enamored with a particular approach, that they can try to use it for everything when it wouldn't be a great fit. Or, they become enamored with a data set, and they use it because they can, not because they should. That translational step, from business, to math, to the technical components, back to the business, really is where the great Data Scientists make a difference. Hugo:    A recurring theme in this conversation so far is the maturing of a data science team, and the evolution as a team. As you said, you started off managing one person. I'm wondering, what are key aspects of a Data Science Manager to think about as your team grows in size as a function of time? Angela:    I think one of the things that happens over time, so I was the first Manager of Data Science at EnerNOC, the company that I was at before iRobot. I was the first Director of Data Science at iRobot, so these are two teams that I grew sort of from the ground up. The thing that happens in the very beginning, there is so much potential, but there's also so much low hanging fruit. Having a team that has the flexibility to deliver on a couple of ... I wouldn't call them necessarily moon shots, but on a couple of high visibility, high sophistication answers, to start illustrating what's possible, right? What are the amazing things that this new function can deliver on? Angela:    But also, that low hanging fruit. The quickest way to value is knocking those out, is taking the things that are easy, and answering them better than anybody else can, with an architecture that takes care of itself so that it requires minimal monitoring. You just start adding things to that pipeline, and solving problems that themselves are tiny, but that save an aggregate number of people seconds or minutes. Then, those add up. Having that flexibility means that in the very beginning, you have sort of undifferentiated talent, right? You have the quote/unquote, ""Unicorns."" I hate that word. Hugo:    So, data science generalists of some sort? Angela:    Exactly, yeah. Folks that have the basic tool set, and that with a little bit of guidance, can sort of play in all of those roles. But there's something that folks in the medical sciences say, that I think is really relevant, is that ontogeny recapitulates phylogeny. And what I think that phrase means is that the way organisms develop, from fertilization to gestation or hatching, mimic the stages in the evolution of the animal's remote ancestors. That's a pretty random analogy, but the way I think it's relevant here is that the way a data science team develops also mimics the stages in the evolution of a company. So, much like a startup, a budding data science team has lots of undifferentiated and flexible talent, and the team goes through several ""pivots"" and they try to establish their value, who their champions are, and the ideal way to engage with the rest of their internal customers. When they're just small teams, they are rudimentary, and they are pluripotent, right? They act a little these stem cells, right? They can mature into anything. Hugo: What then happens as a data team matures?
Angela:    When you get some maturity into the team, that's when you start to have specialization, that's when you start to have differentiation. That's when you start having folks who are really great at visualization, or really natural talents in terms of data platform engineering, or reliability. Folks who are great at QA, they have that personality, and that passion for the attention to detail. When there's enough scale in the type of work that the data science team is doing, only then I think it makes sense to start having those dedicated, ancillary teams that can liberate the Data Scientist to truly focus on the science component, which is the hypothesis testing. Hugo:    Once you enter that stage, how do you think about hiring, or building a team around the different skills? As you say, you don't necessarily want data science generalists then, but you want a team of people whose skill sets, questions asking, curiosities compliment one another, right? Angela:    Yeah. I think as you start, you want to have folks who are well rounded. But, the farther along you go, I think it's important to have a team that represents your end users, whoever they may be. I think, especially in companies where the product is data science, you want to make sure that your data science team looks like the folks who use your product, so that you have different perspectives, and you can ask different questions. And, everybody doesn't look the same way, use the same tools, ask the same questions. I think it's important to have that diversity in all dimensions. I think folks who are senior, and folks who are junior, there's something I like to think about in terms of the luxury of ignorance. Which, is when junior folks in a team get to ask ¡°dumb¡± questions, right? And dumb in quotation marks, because they're not dumb. What they are is unencumbered. They're unencumbered by the assumptions that we forget we make. They're unencumbered by the heuristics that we've developed, that may not be applicable everywhere. Angela:    They have this luxury of being able to challenge the assumptions that folks with more seniority are perfectly capable of, but you start forgetting. You hear hooves, and you think horses, not zebras. Well, the more younger folks are like, ""Well what if it's a zebra?"" And they challenge that, and they force you to think about why you're making certain decisions. Hugo:    I love that, and I love that you describe it in terms of heuristics that we develop over time, because we know that when we start using heuristics a lot, they're coupled with certain biases as well. So, having a new point of view, which is unencumbered by heuristics will also make us recognize our own biases hopefully also. Angela:    Absolutely. Not to knock on heuristics, they're great, they exist for a reason. Hugo:    Mm-hmm (affirmative) and necessary. Angela:    We build them because they create shortcuts, and they make us efficient, right? It's the whole thing about thinking fast and slow, and how our brains operate, and how we create our own Bayesian priors, and sort of go from them. But, I think having folks with different priors participate in the conversation, really enriches it. Hugo:    You mentioned earlier the types of questions that a data science team can think about, and perhaps should think about. You actually ... We may get to this later, recently you sent me a draft of an article you're writing for Harvard Business Review, and you make a nice distinction there between the space of questions a team might be able to answer, and the space of questions a team can and should answer. I thought maybe you could speak to that a bit, in light of this. Angela:    Yeah. I think that this is a perfect fit for that. In terms of what usually can happen, and very easily. I've been guilty of this as well is, you have access to data, and so you start correlating. You start exploring, and you start figuring out what could happen. I think while there's certainly value in directionless exploration as you're starting to build your own heuristics about these data artifacts. I think if possible, whenever possible, it's much more important to think about first what the objective might be, and to have that north star as you start quote/unquote, ""Spelunking,"" through data. When you think about what the question that is posed to you is, a lot of the times it can be easy to think, ""Oh, well I don't have a perfect fit for that question, but I have this other data set that I bet is correlated."" And so, you start going there. Angela:    I think one of the things that makes a really good Data Scientist is also humility. Humility to know that maybe that's not what it means. I mean, sometimes the answer is in an email thread somewhere that you don't have access to, that you weren't involved in, that you weren't privy to. But, the answer exists elsewhere. I think it's really important to have the self awareness to go and ask, and become an expert not just through spelunking in data, but spelunking through the organization, right? Making connections with other folks around the organization, and truly gaining insight into how the data is generated, what context is it used for, can it be repurposed, what are the issues that potentially arise with that repurposing? Angela:    And so, really figuring out what kinds of questions can be answered is great, but what kind of questions should be answered I think is something that the data scientists within an organization is well positioned to be able to ask, and perhaps a better position than anybody else. Hugo:    Now, this speaks to a certain trade off I think. I'm wondering, in your role as a Data Science Manager, what are the types of trade offs you need to make, and how do you think about making the right ones? Angela:    Oh, I think being a manager in any discipline, but especially in data science, I think those trade offs are everything. Data science is a little bit different than other types of work, because you're not just answering questions. A lot of times you are figuring out if a question is even answerable, right? It's not just the how or the what, but it's also the if. Figuring out those trade offs, a lot of other disciplines have different trade offs. But, a lot of the trade offs are also very similar in terms of how much time do you spend catching up on what the latest findings of a discipline, the latest applications, the latest methodologies versus, selling a discipline, selling it internally, letting folks in legal, and in sales, and in operations. Letting them know that this resource is available to them if they have questions, that they would love to have more information, more data to help with their decision making. Angela:    How much do you spend doing? Usually I'm making slides, or writing memos, or thinking through what everybody needs, and articulating that, and setting it in writing. Versus coaching, versus growing your team, and making sure they have what they need, and making sure that they are getting exposed to strategy so that they can make the best play when it's their turn. As well as planning, and strategizing, and figuring out who do we need to talk to, when do we need to deliver something by, when do we need to do road shows, and present some of our findings so folks know that we're a credible part of the organization that can be leveraged, and can bring value? Angela:    I think all of that are the things that you are constantly trying to juggle and optimize as a manager. Also, there's loads of additional questions. Who do you bring into your team, and how do you make sure that everybody who comes and joins the team allows you to get network effects out of that expansion, so that you're not just having a plus one, but you're having plus N because of all of the ways in which that person improves a team, and covers blind spots? Hugo:    How do you think about the trade off between ... I mean, when hiring for a data science position you can hire someone with incredibly strong quantitative and data science skills. But, you can also go about it, I presume, in terms of someone who maybe has some other expertise, and can pick up a bunch of the data science in the process as well, right? Angela:    Yeah. I'm a big fan of the data science boot camps. Not all of them, but I think there are several that have been fantastic for preparing folks who have that ambition, and that ability to learn the skills, right? I think there are parts to data science which is, that you can't teach, right? You can't teach somebody to want to answer a question correctly. But, the how I think is teachable. I think there are a lot of folks out there who are breaking into data science. I mean, the different institutes and universities are only starting to have quote/unquote, ""Data science programs."" I mean, pretty much everybody who came into data science over the last five years did something else as their training. Angela:    Here's a perfect example. On the team at iRobot we have one of our Data Scientists who's originally trained as a Marine Biologist. You would think, ""What does a Marine Biologist do in a robotics consumer company?"" Well, you'd be surprised, because it turns out that there's a lot of research in her field. What she did, she did a lot of studies with pods of dolphin in the wild. She actually traveled all over, and I'm sort of jealous. It turns out that that kind of modeling expertise is really useful when you're thinking about a fleet of robots, and how those robots behave- Hugo:    Oh wow. Angela:    ... Independently, and dependently. You can think of a fleet of robots as a pod of dolphin in certain scenarios. Obviously it's not a perfect analog, but a lot of the modeling becomes extremely handy. That knowledge exists in the world, and it's just a question of how do you know to look for it there? Hugo:    Yes. Angela:    She brings that level of expertise to us. She's an amazing Data Scientist. She has all of the qualifications to be a fantastic Data Scientist, technically. But, she also brings this added dimension that helps us solve problems differently, and I think better. Hugo:    Yeah, and of course being from academic research, or scientific research, knowing how to ask the right questions. But also, if she did a lot of travel, data collection, that type of stuff, thinking about the data generating process, how the data was generated, and how then you can model it is such a key part of what it is to do this type of work also. Angela:    Exactly, yeah. That's one of the reasons that I'm a big fan of internship programs as well, because it can seem like grunt work, but it's incredibly important grunt work, and I think we all did it. I mean, I did it when I was on Wall Street as well. As I was building my data sets, and I was building these databases that got monitored, I understood very intimately what I meant when I made design choices, and how my design choices propagated downstream so that what kinds of questions were easier to answer, and harder to answer, and why? What was my governance model, right? I didn't have words for those things when I was starting out, but that's what those are. Angela:    In our internship program we have folks become intimately familiar with data gathering, and data ingestion, and data management which, I think down the line helps them tremendously, because they are better able to understand context, and to understand how important it is to be respectful of those design decisions, and not use data sets for one thing, when they are really intended for another, and accounting for that. Hugo:    Yeah. Just quickly, for any of our listeners who are really enjoying this conversation and your work at iRobot, can they check out internship programs online or something along those lines? Angela:    Oh yeah, absolutely. If you go to our careers page and search for the data science internship, yes, if you're interested, please apply. Hugo:    Fantastic. If you do apply, make sure to mention that you heard about it on the podcast. Angela:    Absolutely, yes. Hugo:    Something you mentioned Angela, is this idea of it being a requirement in some ways to sell data science internally in an organization. Something I'm really interested in is how we're going to see our data literacy spread across orgs, not only in data science teams. I'm wondering for you to have the best conversation with stakeholders, how much data do they need to be able to speak, or do you see a future in which C-suite and other stakeholders speak more data, and become more data literate? Angela:    Oh, I think the latter. I think it's going to start becoming even harder to not be able to credibly discuss your product, or your strategy in a data literate way. I think the market has that expectation, I think it's becoming table stakes. And, to be able to ensure that your strategic decisions are based on information that you have had the foresight to gather so that you can make the right decisions. Hugo:    What are some common pitfalls or warnings you have for Data Science Managers? Angela:    One of my pet peeves is when a data team doesn't know what data is available, and what it means, and how it can be used. I think the first thing that you need to do is have a big exploratory data analysis party, you know? Hugo:    Awesome. Data party, I love it. Angela:    ... Yes. Dedicate some time, once a week, maybe 10% of everybody's time dedicated to getting lost in the data, and truly understanding it, and setting up coffees with other folks in the organization so that you can ask questions about how that data is designed, and created, and collected, and stored, and labeled. I think that's hugely important. I get really aggravated when folks think that's a waste of time, because it's undirected, and I think it's hugely valuable if you're going to be the expert on your company's data, that you be the expert on your company's data. Angela:    The other thing I think is to not over promise. One of the things that tends to happen is, folks know what's possible, and so they paint a picture, but they forget to be pragmatic about how they're going to execute. And so, not over promising is huge, but not under promising either. I think sandbagging backfires, I think you need to be able to accurately promise. Then, to deliver on it. That's not just because it keeps you from that over/under promising situation, but also because it builds credibility. If you can accurately assess what your outcome is going to be, I think that lends credibility to the actual outcome as well. Angela:    I think one way to get to that point where you can promise and then deliver is to be honest, and to be transparent. Perhaps a little bit more transparent than with other disciplines, because the Data Scientist is trained to interrogate data, to interrogate situations. They're going to be able to tell when you're over promising, or when you're under promising, or when you're not sure of what the objective is. It's really important to have that clarity, and to communicate that within the team, and within the organization. Hugo:    Great. I think this has been a wonderful conversation about the state of data science management today, and your practice in particular. I'm wondering what the future of data science in organizations, particularly relative to the decision function, what this looks like to you. Angela:    It's rosy. I think there's job security in data science. It is definitely something that's becoming more and more ingrained in the fabric of different organizations. I think that's why it depends. The future is going to look different for companies that have their product be data scientific or algorithmic, versus companies that use data science in service of something else. I also think that the future looks different, whether the team is part of a public organization, a startup, or a large organization. And also, the time horizon. Is this a team that is exclusively research, and they're working on moon shots? Versus, a team that is more operational, and is enterprise facing, and helping the company optimize its own functioning. Angela:    I think all of those have different curves that they're on, but I think, in any respect, I can't see a future where we're not relying more and more on the expertise of folks who understand how to manipulate data. Hugo:    For all our listeners out there who are either Data Scientists, aspiring Data Scientists, or even have aspirations to get into data science management, do you have a call to action for them? Angela:    Well, I'm so glad you mentioned it, and actually you also mentioned it earlier during our conversation. I'm really excited, I just penned an article for HBR, and it's actually part of a series that they're putting together called, ""Managing Data Science."" It's an eight week newsletter that they're putting together, that focuses on making analytics and AI work for everybody's organizations. I have an article coming up, so by the time this podcast hits the wires, I think it's going to be two or three weeks old. I encourage you and your listeners to check it out. Hugo:    Fantastic, and we'll include a link in the show notes as well. Angela:    Awesome, thank you. Hugo:    Angela, it's been such a pleasure having you on the show. Angela:    Oh, it has been my pleasure. Thank you for letting me nerd out.","Keyword(freq): folk(29), question(20), term(13), company(8), heuristic(7), scientist(7), robot(6), team(6), answer(5), expert(5)"
"3","mastery",2018-11-16,"How to Grid Search Deep Learning Models for Time Series Forecasting","https://machinelearningmastery.com/how-to-grid-search-deep-learning-models-for-time-series-forecasting/","Grid searching is generally not an operation that we can perform with deep learning methods. This is because deep learning methods often require large amounts of data and large models, together resulting in models that take hours, days, or weeks to train. In those cases where the datasets are smaller, such as univariate time series, it may be possible to use a grid search to tune the hyperparameters of a deep learning model. In this tutorial, you will discover how to develop a framework to grid search hyperparameters for deep learning models. After completing this tutorial, you will know: Let¡¯s get started. How to Grid Search Deep Learning Models for Time Series ForecastingPhoto by Hannes Flo, some rights reserved. This tutorial is divided into five parts; they are: The ¡®monthly airline passenger¡® dataset summarizes the monthly total number of international passengers in thousands on for an airline from 1949 to 1960. Download the dataset directly from here: Save the file with the filename ¡®monthly-airline-passengers.csv¡® in your current working directory. We can load this dataset as a Pandas series using the function read_csv(). Once loaded, we can summarize the shape of the dataset in order to determine the number of observations. We can then create a line plot of the series to get an idea of the structure of the series. We can tie all of this together; the complete example is listed below. Running the example first prints the shape of the dataset. The dataset is monthly and has 12 years, or 144 observations. In our testing, we will use the last year, or 12 observations, as the test set. A line plot is created. The dataset has an obvious trend and seasonal component. The period of the seasonal component is 12 months. Line Plot of Monthly International Airline Passengers In this tutorial, we will introduce the tools for grid searching, but we will not optimize the model hyperparameters for this problem. Instead, we will demonstrate how to grid search the deep learning model hyperparameters generally and find models with some skill compared to a naive model. From prior experiments, a naive model can achieve a root mean squared error, or RMSE, of 50.70 (remember the units are thousands of passengers) by persisting the value from 12 months ago (relative index -12). The performance of this naive model provides a bound on a model that is considered skillful for this problem. Any model that achieves a predictive performance of lower than 50.70 on the last 12 months has skill. It should be noted that a tuned ETS model can achieve an RMSE of 17.09 and a tuned SARIMA can achieve an RMSE of 13.89. These provide a lower bound on the expectations of a well-tuned deep learning model for this problem. Now that we have defined our problem and expectations of model skill, we can look at defining the grid search test harness. In this section, we will develop a grid search test harness that can be used to evaluate a range of hyperparameters for different neural network models, such as MLPs, CNNs, and LSTMs. This section is divided into the following parts: The first step is to split the loaded series into train and test sets. We will use the first 11 years (132 observations) for training and the last 12 for the test set. The train_test_split() function below will split the series taking the raw observations and the number of observations to use in the test set as arguments. Next, we need to be able to frame the univariate series of observations as a supervised learning problem so that we can train neural network models. A supervised learning framing of a series means that the data needs to be split into multiple examples that the model learns from and generalizes across. Each sample must have both an input component and an output component. The input component will be some number of prior observations, such as three years, or 36 time steps. The output component will be the total sales in the next month because we are interested in developing a model to make one-step forecasts. We can implement this using the shift() function on the pandas DataFrame. It allows us to shift a column down (forward in time) or back (backward in time). We can take the series as a column of data, then create multiple copies of the column, shifted forward or backward in time in order to create the samples with the input and output elements we require. When a series is shifted down, NaN values are introduced because we don¡¯t have values beyond the start of the series. For example, the series defined as a column: This column can be shifted and inserted as a column beforehand: We can see that on the second row, the value 1 is provided as input as an observation at the prior time step, and 2 is the next value in the series that can be predicted, or learned by the model to be predicted when 1 is presented as input. Rows with NaN values can be removed. The series_to_supervised() function below implements this behavior, allowing you to specify the number of lag observations to use in the input and the number to use in the output for each sample. It will also remove rows that have NaN values as they cannot be used to train or test a model. Time series forecasting models can be evaluated on a test set using walk-forward validation. Walk-forward validation is an approach where the model makes a forecast for each observation in the test dataset one at a time. After each forecast is made for a time step in the test dataset, the true observation for the forecast is added to the test dataset and made available to the model. Simpler models can be refit with the observation prior to making the subsequent prediction. More complex models, such as neural networks, are not refit given the much greater computational cost. Nevertheless, the true observation for the time step can then be used as part of the input for making the prediction on the next time step. First, the dataset is split into train and test sets. We will call the train_test_split() function to perform this split and pass in the pre-specified number of observations to use as the test data. A model will be fit once on the training dataset for a given configuration. We will define a generic model_fit() function to perform this operation that can be filled in for the given type of neural network that we may be interested in later. The function takes the training dataset and the model configuration and returns the fit model ready for making predictions. Each time step of the test dataset is enumerated. A prediction is made using the fit model. Again, we will define a generic function named model_predict() that takes the fit model, the history, and the model configuration and makes a single one-step prediction. The prediction is added to a list of predictions and the true observation from the test set is added to a list of observations that was seeded with all observations from the training dataset. This list is built up during each step in the walk-forward validation, allowing the model to make a one-step prediction using the most recent history. All of the predictions can then be compared to the true values in the test set and an error measure calculated. We will calculate the root mean squared error, or RMSE, between predictions and the true values. RMSE is calculated as the square root of the average of the squared differences between the forecasts and the actual values. The measure_rmse() implements this below using the mean_squared_error() scikit-learn function to first calculate the mean squared error, or MSE, before calculating the square root. The complete walk_forward_validation() function that ties all of this together is listed below. It takes the dataset, the number of observations to use as the test set, and the configuration for the model, and returns the RMSE for the model performance on the test set. Neural network models are stochastic. This means that, given the same model configuration and the same training dataset, a different internal set of weights will result each time the model is trained that will, in turn, have a different performance. This is a benefit, allowing the model to be adaptive and find high performing configurations to complex problems. It is also a problem when evaluating the performance of a model and in choosing a final model to use to make predictions. To address model evaluation, we will evaluate a model configuration multiple times via walk-forward validation and report the error as the average error across each evaluation. This is not always possible for large neural networks and may only make sense for small networks that can be fit in minutes or hours. The repeat_evaluate() function below implements this and allows the number of repeats to be specified as an optional parameter that defaults to 10 and returns the mean RMSE score from all repeats. We now have all the pieces of the framework. All that is left is a function to drive the search. We can define a grid_search() function that takes the dataset, a list of configurations to search, and the number of observations to use as the test set and perform the search. Once mean scores are calculated for each config, the list of configurations is sorted in ascending order so that the best scores are listed first. The complete function is listed below. Now that we have defined the elements of the test harness, we can tie them all together and define a simple persistence model. We do not need to fit a model so the model_fit() function will be implemented to simply return None. We will use the config to define a list of index offsets in the prior observations relative to the time to be forecasted that will be used as the prediction. For example, 12 will use the observation 12 months ago (-12) relative to the time to be forecasted. The model_predict() function can be implemented to use this configuration to persist the value at the negative relative offset. The complete example of using the framework with a simple persistence model is listed below. Running the example prints the RMSE of the model evaluated using walk-forward validation on the final 12 months of data. Each model configuration is evaluated 10 times, although, because the model has no stochastic element, the score is the same each time. At the end of the run, the configurations and RMSE for the top three performing model configurations are reported. We can see, as we might have expected, that persisting the value from one year ago (relative offset -12) resulted in the best performance for the persistence model. Now that we have a robust test harness for grid searching model hyperparameters, we can use it to evaluate a suite of neural network models. Take my free 7-day email crash course now (with sample code). Click to sign-up and also get a free PDF Ebook version of the course. Download Your FREE Mini-Course There are many aspects of the MLP that we may wish to tune. We will define a very simple model with one hidden layer and define five hyperparameters to tune. They are: Modern neural networks can handle raw data with little pre-processing, such as scaling and differencing. Nevertheless, when it comes to time series data, sometimes differencing the series can make a problem easier to model. Recall that differencing is the transform of the data such that a value of a prior observation is subtracted from the current observation, removing trend or seasonality structure. We will add support for differencing to the grid search test harness, just in case it adds value to your specific problem. It does add value for the internal airline passengers dataset. The difference() function below will calculate the difference of a given order for the dataset. Differencing will be optional, where an order of 0 suggests no differencing, whereas an order 1 or order 12 will require that the data be differenced prior to fitting the model and that the predictions of the model will need the differencing reversed prior to returning the forecast. We can now define the elements required to fit the MLP model in the test harness. First, we must unpack the list of hyperparameters. Next, we must prepare the data, including the differencing, transforming the data to a supervised format and separating out the input and output aspects of the data samples. We can now define and fit the model with the provided configuration. The complete implementation of the model_fit() function is listed below. The five chosen hyperparameters are by no means the only or best hyperparameters of the model to tune. You may modify the function to tune other parameters, such as the addition and size of more hidden layers and much more. Once the model is fit, we can use it to make forecasts. If the data was differenced, the difference must be inverted for the prediction of the model. This involves adding the value at the relative offset from the history back to the value predicted by the model. It also means that the history must be differenced so that the input data used to make the prediction has the expected form. Once prepared, we can use the history data to create a single sample as input to the model for making a one-step prediction. The shape of one sample must be [1, n_input] where n_input is the chosen number of lag observations to use. Finally, a prediction can be made. The complete implementation of the model_predict() function is listed below. Next, we must define the range of values to try for each hyperparameter. We can define a model_configs() function that creates a list of the different combinations of parameters to try. We will define a small subset of configurations to try as an example, including a differencing of 12 months, which we expect will be required. You are encouraged to experiment with standalone models, review learning curve diagnostic plots, and use information about the domain to set ranges of values of the hyperparameters to grid search. You are also encouraged to repeat the grid search to narrow in on ranges of values that appear to show better performance. An implementation of the model_configs() function is listed below. We now have all of the pieces needed to grid search MLP models for a univariate time series forecasting problem. The complete example is listed below. Running the example, we can see that there are a total of eight configurations to be evaluated by the framework. Each config will be evaluated 10 times; that means 10 models will be created and evaluated using walk-forward validation to calculate an RMSE score before an average of those 10 scores is reported and used to score the configuration. The scores are then sorted and the top 3 configurations with the lowest RMSE are reported at the end. A skillful model configuration was found as compared to a naive model that reported an RMSE of 50.70. We can see that the best RMSE of 18.98 was achieved with a configuration of [12, 100, 100, 1, 12], which we know can be interpreted as: A truncated example output of the grid search is listed below. Your specific scores may vary given the stochastic nature of the algorithm. We can now adapt the framework to grid search CNN models. Much the same set of hyperparameters can be searched as with the MLP model, except the number of nodes in the hidden layer can be replaced by the number of filter maps and kernel size in the convolutional layers. The chosen set of hyperparameters to grid search in the CNN model are as follows: Some additional hyperparameters that you may wish to investigate are the use of two convolutional layers before a pooling layer, the repetition of the convolutional and pooling layer pattern, the use of dropout, and more. We will define a very simple CNN model with one convolutional layer and one max pooling layer. The data must be prepared in much the same way as for the MLP. Unlike the MLP that expects the input data to have the shape [samples, features], the 1D CNN model expects the data to have the shape [samples, timesteps, features] where features maps onto channels and in this case 1 for the one variable we measure each month. The complete implementation of the model_fit() function is listed below. Making a prediction with a fit CNN model is very much like making a prediction with a fit MLP. Again, the only difference is that the one sample worth of input data must have a three-dimensional shape. The complete implementation of the model_predict() function is listed below. Finally, we can define a list of configurations for the model to evaluate. As before, we can do this by defining lists of hyperparameter values to try that are combined into a list. We will try a small number of configurations to ensure the example executes in a reasonable amount of time. The complete model_configs() function is listed below. We now have all of the elements needed to grid search the hyperparameters of a convolutional neural network for univariate time series forecasting. The complete example is listed below. Running the example, we can see that only eight distinct configurations are evaluated. We can see that a configuration of [12, 64, 5, 100, 1, 12] achieved an RMSE of 18.89, which is skillful as compared to a naive forecast model that achieved 50.70. We can unpack this configuration as: A truncated example output of the grid search is listed below. Your specific scores may vary given the stochastic nature of the algorithm. We can now adopt the framework for grid searching the hyperparameters of an LSTM model. The hyperparameters for the LSTM model will be the same five as the MLP; they are: We will define a simple LSTM model with a single hidden LSTM layer and the number of nodes specifying the number of units in this layer. It may be interesting to explore tuning additional configurations such as the use of a bidirectional input layer, stacked LSTM layers, and even hybrid models with CNN or ConvLSTM input models. As with the CNN model, the LSTM model expects input data to have a three-dimensional shape for the samples, time steps, and features. The complete implementation of the model_fit() function is listed below. Also like the CNN, the single input sample used to make a prediction must also be reshaped into the expected three-dimensional structure. The complete model_predict() function is listed below. We can now define the function used to create the list of model configurations to evaluate. The LSTM model is quite a bit slower to train than MLP and CNN models; as such, you may want to evaluate fewer configurations per run. We will define a very simple set of two configurations to explore: stochastic and batch gradient descent. We now have everything we need to grid search hyperparameters for the LSTM model for univariate time series forecasting. The complete example is listed below. Running the example, we can see that only two distinct configurations are evaluated. We can see that a configuration of [12, 100, 50, 1, 12] achieved an RMSE of 21.24, which is skillful as compared to a naive forecast model that achieved 50.70. The model requires a lot more tuning and may do much better with a hybrid configuration, such as having a CNN model as input. We can unpack this configuration as: A truncated example output of the grid search is listed below. Your specific scores may vary given the stochastic nature of the algorithm. This section lists some ideas for extending the tutorial that you may wish to explore. If you explore any of these extensions, I¡¯d love to know. This section provides more resources on the topic if you are looking to go deeper. In this tutorial, you discovered how to develop a framework to grid search hyperparameters for deep learning models. Specifically, you learned: Do you have any questions?
Ask your questions in the comments below and I will do my best to answer. ¡¦with just a few lines of python code Discover how in my new Ebook:Deep Learning for Time Series Forecasting It provides self-study tutorials on topics like: CNNs, LSTMs,Multivariate Forecasting, Multi-Step Forecasting and much more¡¦ Skip the Academics. Just Results. Click to learn more. Thank you for providing such wonderful information. I¡¯m glad it helped. Just wanted to say thank you for your most excellent tutorials. They have helped me tremendously. Comment  Name (required)  Email (will not be published) (required)  Website","Keyword(freq): model(20), hyperparameter(19), configuration(16), observation(16), value(11), score(7), prediction(6), sample(5), element(4), layer(4)"
"4","mastery",2018-11-14,"How to Develop LSTM Models for Time Series Forecasting","https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/","Long Short-Term Memory networks, or LSTMs for short, can be applied to time series forecasting. There are many types of LSTM models that can be used for each specific type of time series forecasting problem. In this tutorial, you will discover how to develop a suite of LSTM models for a range of standard time series forecasting problems. The objective of this tutorial is to provide standalone examples of each model on each type of time series problem as a template that you can copy and adapt for your specific time series forecasting problem. After completing this tutorial, you will know: This is a large and important post; you may want to bookmark it for future reference. Let¡¯s get started. How to Develop LSTM Models for Time Series ForecastingPhoto by N i c o l a, some rights reserved. In this tutorial, we will explore how to develop a suite of different types of LSTM models for time series forecasting. The models are demonstrated on small contrived time series problems intended to give the flavor of the type of time series problem being addressed. The chosen configuration of the models is arbitrary and not optimized for each problem; that was not the goal. This tutorial is divided into four parts; they are: LSTMs can be used to model univariate time series forecasting problems. These are problems comprised of a single series of observations and a model is required to learn from the series of past observations to predict the next value in the sequence. We will demonstrate a number of variations of the LSTM model for univariate time series forecasting. This section is divided into six parts; they are: Each of these models are demonstrated for one-step univariate time series forecasting, but can easily be adapted and used as the input part of a model for other types of time series forecasting problems. Before a univariate series can be modeled, it must be prepared. The LSTM model will learn a function that maps a sequence of past observations as input to an output observation. As such, the sequence of observations must be transformed into multiple examples from which the LSTM can learn. Consider a given univariate sequence: We can divide the sequence into multiple input/output patterns called samples, where three time steps are used as input and one time step is used as output for the one-step prediction that is being learned. The split_sequence() function below implements this behavior and will split a given univariate sequence into multiple samples where each sample has a specified number of time steps and the output is a single time step. We can demonstrate this function on our small contrived dataset above. The complete example is listed below. Running the example splits the univariate series into six samples where each sample has three input time steps and one output time step. Now that we know how to prepare a univariate series for modeling, let¡¯s look at developing LSTM models that can learn the mapping of inputs to outputs, starting with a Vanilla LSTM. Take my free 7-day email crash course now (with sample code). Click to sign-up and also get a free PDF Ebook version of the course. Download Your FREE Mini-Course A Vanilla LSTM is an LSTM model that has a single hidden layer of LSTM units, and an output layer used to make a prediction. We can define a Vanilla LSTM for univariate time series forecasting as follows. Key in the definition is the shape of the input; that is what the model expects as input for each sample in terms of the number of time steps and the number of features. We are working with a univariate series, so the number of features is one, for one variable. The number of time steps as input is the number we chose when preparing our dataset as an argument to the split_sequence() function. The shape of the input for each sample is specified in the input_shape argument on the definition of first hidden layer. We almost always have multiple samples, therefore, the model will expect the input component of training data to have the dimensions or shape: Our split_sequence() function in the previous section outputs the X with the shape [samples, timesteps], so we easily reshape it to have an additional dimension for the one feature. In this case, we define a model with 50 LSTM units in the hidden layer and an output layer that predicts a single numerical value. The model is fit using the efficient Adam version of stochastic gradient descent and optimized using the mean squared error, or ¡®mse¡® loss function. Once the model is defined, we can fit it on the training dataset. After the model is fit, we can use it to make a prediction. We can predict the next value in the sequence by providing the input: And expecting the model to predict something like: The model expects the input shape to be three-dimensional with [samples, timesteps, features], therefore, we must reshape the single input sample before making the prediction. We can tie all of this together and demonstrate how to develop a Vanilla LSTM for univariate time series forecasting and make a single prediction. Running the example prepares the data, fits the model, and makes a prediction. Your results may vary given the stochastic nature of the algorithm; try running the example a few times. We can see that the model predicts the next value in the sequence. Multiple hidden LSTM layers can be stacked one on top of another in what is referred to as a Stacked LSTM model. An LSTM layer requires a three-dimensional input and LSTMs by default will produce a two-dimensional output as an interpretation from the end of the sequence. We can address this by having the LSTM output a value for each time step in the input data by setting the return_sequences=True argument on the layer. This allows us to have 3D output from hidden LSTM layer as input to the next. We can therefore define a Stacked LSTM as follows. We can tie this together; the complete code example is listed below. Running the example predicts the next value in the sequence, which we expect would be 100. On some sequence prediction problems, it can be beneficial to allow the LSTM model to learn the input sequence both forward and backwards and concatenate both interpretations. This is called a Bidirectional LSTM. We can implement a Bidirectional LSTM for univariate time series forecasting by wrapping the first hidden layer in a wrapper layer called Bidirectional. An example of defining a Bidirectional LSTM to read input both forward and backward is as follows. The complete example of the Bidirectional LSTM for univariate time series forecasting is listed below. Running the example predicts the next value in the sequence, which we expect would be 100. A convolutional neural network, or CNN for short, is a type of neural network developed for working with two-dimensional image data. The CNN can be very effective at automatically extracting and learning features from one-dimensional sequence data such as univariate time series data. A CNN model can be used in a hybrid model with an LSTM backend where the CNN is used to interpret subsequences of input that together are provided as a sequence to an LSTM model to interpret. This hybrid model is called a CNN-LSTM. The first step is to split the input sequences into subsequences that can be processed by the CNN model. For example, we can first split our univariate time series data into input/output samples with four steps as input and one as output. Each sample can then be split into two sub-samples, each with two time steps. The CNN can interpret each subsequence of two time steps and provide a time series of interpretations of the subsequences to the LSTM model to process as input. We can parameterize this and define the number of subsequences as n_seq and the number of time steps per subsequence as n_steps. The input data can then be reshaped to have the required structure: For example: We want to reuse the same CNN model when reading in each sub-sequence of data separately. This can be achieved by wrapping the entire CNN model in a TimeDistributed wrapper that will apply the entire model once per input, in this case, once per input subsequence. The CNN model first has a convolutional layer for reading across the subsequence that requires a number of filters and a kernel size to be specified. The number of filters is the number of reads or interpretations of the input sequence. The kernel size is the number of time steps included of each ¡®read¡¯ operation of the input sequence. The convolution layer is followed by a max pooling layer that distills the filter maps down to 1/4 of their size that includes the most salient features. These structures are then flattened down to a single one-dimensional vector to be used as a single input time step to the LSTM layer. Next, we can define the LSTM part of the model that interprets the CNN model¡¯s read of the input sequence and makes a prediction. We can tie all of this together; the complete example of a CNN-LSTM model for univariate time series forecasting is listed below. Running the example predicts the next value in the sequence, which we expect would be 100. A type of LSTM related to the CNN-LSTM is the ConvLSTM, where the convolutional reading of input is built directly into each LSTM unit. The ConvLSTM was developed for reading two-dimensional spatial-temporal data, but can be adapted for use with univariate time series forecasting. The layer expects input as a sequence of two-dimensional images, therefore the shape of input data must be: For our purposes, we can split each sample into subsequences where timesteps will become the number of subsequences, or n_seq, and columns will be the number of time steps for each subsequence, or n_steps. The number of rows is fixed at 1 as we are working with one-dimensional data. We can now reshape the prepared samples into the required structure. We can define the ConvLSTM as a single layer in terms of the number of filters and a two-dimensional kernel size in terms of (rows, columns). As we are working with a one-dimensional series, the number of rows is always fixed to 1 in the kernel. The output of the model must then be flattened before it can be interpreted and a prediction made. The complete example of a ConvLSTM for one-step univariate time series forecasting is listed below. Running the example predicts the next value in the sequence, which we expect would be 100. Now that we have looked at LSTM models for univariate data, let¡¯s turn our attention to multivariate data. Multivariate time series data means data where there is more than one observation for each time step. There are two main models that we may require with multivariate time series data; they are: Let¡¯s take a look at each in turn. A problem may have two or more parallel input time series and an output time series that is dependent on the input time series. The input time series are parallel because each series has an observation at the same time steps. We can demonstrate this with a simple example of two parallel input time series where the output series is the simple addition of the input series. We can reshape these three arrays of data as a single dataset where each row is a time step, and each column is a separate time series. This is a standard way of storing parallel time series in a CSV file. The complete example is listed below. Running the example prints the dataset with one row per time step and one column for each of the two input and one output parallel time series. As with the univariate time series, we must structure these data into samples with input and output elements. An LSTM model needs sufficient context to learn a mapping from an input sequence to an output value. LSTMs can support parallel input time series as separate variables or features. Therefore, we need to split the data into samples maintaining the order of observations across the two input sequences. If we chose three input time steps, then the first sample would look as follows: Input: Output: That is, the first three time steps of each parallel series are provided as input to the model and the model associates this with the value in the output series at the third time step, in this case, 65. We can see that, in transforming the time series into input/output samples to train the model, that we will have to discard some values from the output time series where we do not have values in the input time series at prior time steps. In turn, the choice of the size of the number of input time steps will have an important effect on how much of the training data is used. We can define a function named split_sequences() that will take a dataset as we have defined it with rows for time steps and columns for parallel series and return input/output samples. We can test this function on our dataset using three time steps for each input time series as input. The complete example is listed below. Running the example first prints the shape of the X and y components. We can see that the X component has a three-dimensional structure. The first dimension is the number of samples, in this case 7. The second dimension is the number of time steps per sample, in this case 3, the value specified to the function. Finally, the last dimension specifies the number of parallel time series or the number of variables, in this case 2 for the two parallel series. This is the exact three-dimensional structure expected by an LSTM as input. The data is ready to use without further reshaping. We can then see that the input and output for each sample is printed, showing the three time steps for each of the two input series and the associated output for each sample. We are now ready to fit an LSTM model on this data. Any of the varieties of LSTMs in the previous section can be used, such as a Vanilla, Stacked, Bidirectional, CNN, or ConvLSTM model. We will use a Vanilla LSTM where the number of time steps and parallel series (features) are specified for the input layer via the input_shape argument. When making a prediction, the model expects three time steps for two input time series. We can predict the next value in the output series providing the input values of: The shape of the one sample with three time steps and two variables must be [1, 3, 2]. We would expect the next value in the sequence to be 100 + 105, or 205. The complete example is listed below. Running the example prepares the data, fits the model, and makes a prediction. An alternate time series problem is the case where there are multiple parallel time series and a value must be predicted for each. For example, given the data from the previous section: We may want to predict the value for each of the three time series for the next time step. This might be referred to as multivariate forecasting. Again, the data must be split into input/output samples in order to train a model. The first sample of this dataset would be: Input: Output: The split_sequences() function below will split multiple parallel time series with rows for time steps and one series per column into the required input/output shape. We can demonstrate this on the contrived problem; the complete example is listed below. Running the example first prints the shape of the prepared X and y components. The shape of X is three-dimensional, including the number of samples (6), the number of time steps chosen per sample (3), and the number of parallel time series or features (3). The shape of y is two-dimensional as we might expect for the number of samples (6) and the number of time variables per sample to be predicted (3). The data is ready to use in an LSTM model that expects three-dimensional input and two-dimensional output shapes for the X and y components of each sample. Then, each of the samples is printed showing the input and output components of each sample. We are now ready to fit an LSTM model on this data. Any of the varieties of LSTMs in the previous section can be used, such as a Vanilla, Stacked, Bidirectional, CNN, or ConvLSTM model. We will use a Stacked LSTM where the number of time steps and parallel series (features) are specified for the input layer via the input_shape argument. The number of parallel series is also used in the specification of the number of values to predict by the model in the output layer; again, this is three. We can predict the next value in each of the three parallel series by providing an input of three time steps for each series. The shape of the input for making a single prediction must be 1 sample, 3 time steps, and 3 features, or [1, 3, 3] We would expect the vector output to be: We can tie all of this together and demonstrate a Stacked LSTM for multivariate output time series forecasting below. Running the example prepares the data, fits the model, and makes a prediction. A time series forecasting problem that requires a prediction of multiple time steps into the future can be referred to as multi-step time series forecasting. Specifically, these are problems where the forecast horizon or interval is more than one time step. There are two main types of LSTM models that can be used for multi-step forecasting; they are: Before we look at these models, let¡¯s first look at the preparation of data for multi-step forecasting. As with one-step forecasting, a time series used for multi-step time series forecasting must be split into samples with input and output components. Both the input and output components will be comprised of multiple time steps and may or may not have the same number of steps. For example, given the univariate time series: We could use the last three time steps as input and forecast the next two time steps. The first sample would look as follows: Input: Output: The split_sequence() function below implements this behavior and will split a given univariate time series into samples with a specified number of input and output time steps. We can demonstrate this function on the small contrived dataset. The complete example is listed below. Running the example splits the univariate series into input and output time steps and prints the input and output components of each. Now that we know how to prepare data for multi-step forecasting, let¡¯s look at some LSTM models that can learn this mapping. Like other types of neural network models, the LSTM can output a vector directly that can be interpreted as a multi-step forecast. This approach was seen in the previous section were one time step of each output time series was forecasted as a vector. As with the LSTMs for univariate data in a prior section, the prepared samples must first be reshaped. The LSTM expects data to have a three-dimensional structure of [samples, timesteps, features], and in this case, we only have one feature so the reshape is straightforward. With the number of input and output steps specified in the n_steps_in and n_steps_out variables, we can define a multi-step time-series forecasting model. Any of the presented LSTM model types could be used, such as Vanilla, Stacked, Bidirectional, CNN-LSTM, or ConvLSTM. Below defines a Stacked LSTM for multi-step forecasting. The model can make a prediction for a single sample. We can predict the next two steps beyond the end of the dataset by providing the input: We would expect the predicted output to be: As expected by the model, the shape of the single sample of input data when making the prediction must be [1, 3, 1] for the 1 sample, 3 time steps of the input, and the single feature. Tying all of this together, the Stacked LSTM for multi-step forecasting with a univariate time series is listed below. Running the example forecasts and prints the next two time steps in the sequence. A model specifically developed for forecasting variable length output sequences is called the Encoder-Decoder LSTM. The model was designed for prediction problems where there are both input and output sequences, so-called sequence-to-sequence, or seq2seq problems, such as translating text from one language to another. This model can be used for multi-step time series forecasting. As its name suggests, the model is comprised of two sub-models: the encoder and the decoder. The encoder is a model responsible for reading and interpreting the input sequence. The output of the encoder is a fixed length vector that represents the model¡¯s interpretation of the sequence. The encoder is traditionally a Vanilla LSTM model, although other encoder models can be used such as Stacked, Bidirectional, and CNN models. The decoder uses the output of the encoder as an input. First, the fixed-length output of the encoder is repeated, once for each required time step in the output sequence. This sequence is then provided to an LSTM decoder model. The model must output a value for each value in the output time step, which can be interpreted by a single output model. We can use the same output layer or layers to make each one-step prediction in the output sequence. This can be achieved by wrapping the output part of the model in a TimeDistributed wrapper. The full definition for an Encoder-Decoder model for multi-step time series forecasting is listed below. As with other LSTM models, the input data must be reshaped into the expected three-dimensional shape of [samples, timesteps, features]. In the case of the Encoder-Decoder model, the output, or y part, of the training dataset must also have this shape. This is because the model will predict a given number of time steps with a given number of features for each input sample. The complete example of an Encoder-Decoder LSTM for multi-step time series forecasting is listed below. Running the example forecasts and prints the next two time steps in the sequence. In the previous sections, we have looked at univariate, multivariate, and multi-step time series forecasting. It is possible to mix and match the different types of LSTM models presented so far for the different problems. This too applies to time series forecasting problems that involve multivariate and multi-step forecasting, but it may be a little more challenging. In this section, we will provide short examples of data preparation and modeling for multivariate multi-step time series forecasting as a template to ease this challenge, specifically: Perhaps the biggest stumbling block is in the preparation of data, so this is where we will focus our attention. There are those multivariate time series forecasting problems where the output series is separate but dependent upon the input time series, and multiple time steps are required for the output series. For example, consider our multivariate time series from a prior section: We may use three prior time steps of each of the two input time series to predict two time steps of the output time series. Input: Output: The split_sequences() function below implements this behavior. We can demonstrate this on our contrived dataset. The complete example is listed below. Running the example first prints the shape of the prepared training data. We can see that the shape of the input portion of the samples is three-dimensional, comprised of six samples, with three time steps, and two variables for the 2 input time series. The output portion of the samples is two-dimensional for the six samples and the two time steps for each sample to be predicted. The prepared samples are then printed to confirm that the data was prepared as we specified. We can now develop an LSTM model for multi-step predictions. A vector output or an encoder-decoder model could be used. In this case, we will demonstrate a vector output with a Stacked LSTM. The complete example is listed below. Running the example fits the model and predicts the next two time steps of the output sequence beyond the dataset. We would expect the next two steps to be: [185, 205] It is a challenging framing of the problem with very little data, and the arbitrarily configured version of the model gets close. A problem with parallel time series may require the prediction of multiple time steps of each time series. For example, consider our multivariate time series from a prior section: We may use the last three time steps from each of the three time series as input to the model and predict the next time steps of each of the three time series as output. The first sample in the training dataset would be the following. Input: Output: The split_sequences() function below implements this behavior. We can demonstrate this function on the small contrived dataset. The complete example is listed below. Running the example first prints the shape of the prepared training dataset. We can see that both the input (X) and output (Y) elements of the dataset are three dimensional for the number of samples, time steps, and variables or parallel time series respectively. The input and output elements of each series are then printed side by side so that we can confirm that the data was prepared as we expected. We can use either the Vector Output or Encoder-Decoder LSTM to model this problem. In this case, we will use the Encoder-Decoder model. The complete example is listed below. Running the example fits the model and predicts the values for each of the three time steps for the next two time steps beyond the end of the dataset. We would expect the values for these series and time steps to be as follows: We can see that the model forecast gets reasonably close to the expected values. In this tutorial, you discovered how to develop a suite of LSTM models for a range of standard time series forecasting problems. Specifically, you learned: Do you have any questions?
Ask your questions in the comments below and I will do my best to answer. ¡¦with just a few lines of python code Discover how in my new Ebook:Deep Learning for Time Series Forecasting It provides self-study tutorials on topics like: CNNs, LSTMs,Multivariate Forecasting, Multi-Step Forecasting and much more¡¦ Skip the Academics. Just Results. Click to learn more. This tutorial is so helpful to me. Thank you very much!
It will be more helpful in the real projects if the dataset is split into batches. Hope you will mention this in the future. Keras will split the dataset into batches. I think this blog ( https://machinelearningmastery.com/use-different-batch-sizes-training-predicting-python-keras/) may answer my question. I will do more research. Thanks a lot. Great! Thanks Jason for this good tutorial. I have a question. When we have two different time series, 1 and 2. Time series 1 will influence time series 2 and our goal is to predict the future value of time series 2. How can we use LSTM for this case? I call this a dependent time series problem. I given an example of how to model it on this post:https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/ The link is the link of the current page, Do you mean that? Yes, I give an example above. Comment  Name (required)  Email (will not be published) (required)  Website","Keyword(freq): step(55), sample(29), model(22), problem(13), feature(11), lstm(8), component(7), type(7), value(7), variable(7)"
"5","mastery",2018-11-12,"How to Develop Convolutional Neural Network Models for Time Series Forecasting","https://machinelearningmastery.com/how-to-develop-convolutional-neural-network-models-for-time-series-forecasting/","Convolutional Neural Network models, or CNNs for short, can be applied to time series forecasting. There are many types of CNN models that can be used for each specific type of time series forecasting problem. In this tutorial, you will discover how to develop a suite of CNN models for a range of standard time series forecasting problems. The objective of this tutorial is to provide standalone examples of each model on each type of time series problem as a template that you can copy and adapt for your specific time series forecasting problem. After completing this tutorial, you will know: This is a large and important post; you may want to bookmark it for future reference. Let¡¯s get started. How to Develop Convolutional Neural Network Models for Time Series ForecastingPhoto by Bureau of Land Management, some rights reserved. In this tutorial, we will explore how to develop a suite of different types of CNN models for time series forecasting. The models are demonstrated on small contrived time series problems intended to give the flavor of the type of time series problem being addressed. The chosen configuration of the models is arbitrary and not optimized for each problem; that was not the goal. This tutorial is divided into four parts; they are: Although traditionally developed for two-dimensional image data, CNNs can be used to model univariate time series forecasting problems. Univariate time series are datasets comprised of a single series of observations with a temporal ordering and a model is required to learn from the series of past observations to predict the next value in the sequence. This section is divided into two parts; they are: Before a univariate series can be modeled, it must be prepared. The CNN model will learn a function that maps a sequence of past observations as input to an output observation. As such, the sequence of observations must be transformed into multiple examples from which the model can learn. Consider a given univariate sequence: We can divide the sequence into multiple input/output patterns called samples, where three time steps are used as input and one time step is used as output for the one-step prediction that is being learned. The split_sequence() function below implements this behavior and will split a given univariate sequence into multiple samples where each sample has a specified number of time steps and the output is a single time step. We can demonstrate this function on our small contrived dataset above. The complete example is listed below. Running the example splits the univariate series into six samples where each sample has three input time steps and one output time step. Now that we know how to prepare a univariate series for modeling, let¡¯s look at developing a CNN model that can learn the mapping of inputs to outputs. Take my free 7-day email crash course now (with sample code). Click to sign-up and also get a free PDF Ebook version of the course. Download Your FREE Mini-Course A one-dimensional CNN is a CNN model that has a convolutional hidden layer that operates over a 1D sequence. This is followed by perhaps a second convolutional layer in some cases, such as very long input sequences, and then a pooling layer whose job it is to distill the output of the convolutional layer to the most salient elements. The convolutional and pooling layers are followed by a dense fully connected layer that interprets the features extracted by the convolutional part of the model. A flatten layer is used between the convolutional layers and the dense layer to reduce the feature maps to a single one-dimensional vector. We can define a 1D CNN Model for univariate time series forecasting as follows. Key in the definition is the shape of the input; that is what the model expects as input for each sample in terms of the number of time steps and the number of features. We are working with a univariate series, so the number of features is one, for one variable. The number of time steps as input is the number we chose when preparing our dataset as an argument to the split_sequence() function. The input shape for each sample is specified in the input_shape argument on the definition of the first hidden layer. We almost always have multiple samples, therefore, the model will expect the input component of training data to have the dimensions or shape: Our split_sequence() function in the previous section outputs the X with the shape [samples, timesteps], so we can easily reshape it to have an additional dimension for the one feature. The CNN does not actually view the data as having time steps, instead, it is treated as a sequence over which convolutional read operations can be performed, like a one-dimensional image. In this example, we define a convolutional layer with 64 filter maps and a kernel size of 2. This is followed by a max pooling layer and a dense layer to interpret the input feature. An output layer is specified that predicts a single numerical value. The model is fit using the efficient Adam version of stochastic gradient descent and optimized using the mean squared error, or ¡®mse¡®, loss function. Once the model is defined, we can fit it on the training dataset. After the model is fit, we can use it to make a prediction. We can predict the next value in the sequence by providing the input: And expecting the model to predict something like: The model expects the input shape to be three-dimensional with [samples, timesteps, features], therefore, we must reshape the single input sample before making the prediction. We can tie all of this together and demonstrate how to develop a 1D CNN model for univariate time series forecasting and make a single prediction. Running the example prepares the data, fits the model, and makes a prediction. Your results may vary given the stochastic nature of the algorithm; try running the example a few times. We can see that the model predicts the next value in the sequence. Multivariate time series data means data where there is more than one observation for each time step. There are two main models that we may require with multivariate time series data; they are: Let¡¯s take a look at each in turn. A problem may have two or more parallel input time series and an output time series that is dependent on the input time series. The input time series are parallel because each series has observations at the same time steps. We can demonstrate this with a simple example of two parallel input time series where the output series is the simple addition of the input series. We can reshape these three arrays of data as a single dataset where each row is a time step and each column is a separate time series. This is a standard way of storing parallel time series in a CSV file. The complete example is listed below. Running the example prints the dataset with one row per time step and one column for each of the two input and one output parallel time series. As with the univariate time series, we must structure these data into samples with input and output samples. A 1D CNN model needs sufficient context to learn a mapping from an input sequence to an output value. CNNs can support parallel input time series as separate channels, like red, green, and blue components of an image. Therefore, we need to split the data into samples maintaining the order of observations across the two input sequences. If we chose three input time steps, then the first sample would look as follows: Input: Output: That is, the first three time steps of each parallel series are provided as input to the model and the model associates this with the value in the output series at the third time step, in this case, 65. We can see that, in transforming the time series into input/output samples to train the model, that we will have to discard some values from the output time series where we do not have values in the input time series at prior time steps. In turn, the choice of the size of the number of input time steps will have an important effect on how much of the training data is used. We can define a function named split_sequences() that will take a dataset as we have defined it with rows for time steps and columns for parallel series and return input/output samples. We can test this function on our dataset using three time steps for each input time series as input. The complete example is listed below. Running the example first prints the shape of the X and y components. We can see that the X component has a three-dimensional structure. The first dimension is the number of samples, in this case 7. The second dimension is the number of time steps per sample, in this case 3, the value specified to the function. Finally, the last dimension specifies the number of parallel time series or the number of variables, in this case 2 for the two parallel series. This is the exact three-dimensional structure expected by a 1D CNN as input. The data is ready to use without further reshaping. We can then see that the input and output for each sample is printed, showing the three time steps for each of the two input series and the associated output for each sample. We are now ready to fit a 1D CNN model on this data, specifying the expected number of time steps and features to expect for each input sample, in this case three and two respectively. When making a prediction, the model expects three time steps for two input time series. We can predict the next value in the output series providing the input values of: The shape of the one sample with three time steps and two variables must be [1, 3, 2]. We would expect the next value in the sequence to be 100 + 105 or 205. The complete example is listed below. Running the example prepares the data, fits the model, and makes a prediction. There is another, more elaborate way to model the problem. Each input series can be handled by a separate CNN and the output of each of these submodels can be combined before a prediction is made for the output sequence. We can refer to this as a multi-headed CNN model. It may offer more flexibility or better performance depending on the specifics of the problem that is being modeled. For example, it allows you to configure each sub-model differently for each input series, such as the number of filter maps and the kernel size. This type of model can be defined in Keras using the Keras functional API. First, we can define the first input model as a 1D CNN with an input layer that expects vectors with n_steps and 1 feature. We can define the second input submodel in the same way. Now that both input submodels have been defined, we can merge the output from each model into one long vector which can be interpreted before making a prediction for the output sequence. We can then tie the inputs and outputs together. The image below provides a schematic for how this model looks, including the shape of the inputs and outputs of each layer. Plot of Multi-Headed 1D CNN for Multivariate Time Series Forecasting This model requires input to be provided as a list of two elements where each element in the list contains data for one of the submodels. In order to achieve this, we can split the 3D input data into two separate arrays of input data; that is from one array with the shape [7, 3, 2] to two 3D arrays with [7, 3, 1] These data can then be provided in order to fit the model. Similarly, we must prepare the data for a single sample as two separate two-dimensional arrays when making a single one-step prediction. We can tie all of this together; the complete example is listed below. Running the example prepares the data, fits the model, and makes a prediction. An alternate time series problem is the case where there are multiple parallel time series and a value must be predicted for each. For example, given the data from the previous section: We may want to predict the value for each of the three time series for the next time step. This might be referred to as multivariate forecasting. Again, the data must be split into input/output samples in order to train a model. The first sample of this dataset would be: Input: Output: The split_sequences() function below will split multiple parallel time series with rows for time steps and one series per column into the required input/output shape. We can demonstrate this on the contrived problem; the complete example is listed below. Running the example first prints the shape of the prepared X and y components. The shape of X is three-dimensional, including the number of samples (6), the number of time steps chosen per sample (3), and the number of parallel time series or features (3). The shape of y is two-dimensional as we might expect for the number of samples (6) and the number of time variables per sample to be predicted (3). The data is ready to use in a 1D CNN model that expects three-dimensional input and two-dimensional output shapes for the X and y components of each sample. Then, each of the samples is printed showing the input and output components of each sample. We are now ready to fit a 1D CNN model on this data. In this model, the number of time steps and parallel series (features) are specified for the input layer via the input_shape argument. The number of parallel series is also used in the specification of the number of values to predict by the model in the output layer; again, this is three. We can predict the next value in each of the three parallel series by providing an input of three time steps for each series. The shape of the input for making a single prediction must be 1 sample, 3 time steps, and 3 features, or [1, 3, 3]. We would expect the vector output to be: We can tie all of this together and demonstrate a 1D CNN for multivariate output time series forecasting below. Running the example prepares the data, fits the model and makes a prediction. As with multiple input series, there is another more elaborate way to model the problem. Each output series can be handled by a separate output CNN model. We can refer to this as a multi-output CNN model. It may offer more flexibility or better performance depending on the specifics of the problem that is being modeled. This type of model can be defined in Keras using the Keras functional API. First, we can define the first input model as a 1D CNN model. We can then define one output layer for each of the three series that we wish to forecast, where each output submodel will forecast a single time step. We can then tie the input and output layers together into a single model. To make the model architecture clear, the schematic below clearly shows the three separate output layers of the model and the input and output shapes of each layer. Plot of Multi-Output 1D CNN for Multivariate Time Series Forecasting When training the model, it will require three separate output arrays per sample. We can achieve this by converting the output training data that has the shape [7, 3] to three arrays with the shape [7, 1]. These arrays can be provided to the model during training. Tying all of this together, the complete example is listed below. Running the example prepares the data, fits the model, and makes a prediction. In practice, there is little difference to the 1D CNN model in predicting a vector output that represents different output variables (as in the previous example), or a vector output that represents multiple time steps of one variable. Nevertheless, there are subtle and important differences in the way the training data is prepared. In this section, we will demonstrate the case of developing a multi-step forecast model using a vector model. Before we look at the specifics of the model, let¡¯s first look at the preparation of data for multi-step forecasting. As with one-step forecasting, a time series used for multi-step time series forecasting must be split into samples with input and output components. Both the input and output components will be comprised of multiple time steps and may or may not have the same number of steps. For example, given the univariate time series: We could use the last three time steps as input and forecast the next two time steps. The first sample would look as follows: Input: Output: The split_sequence() function below implements this behavior and will split a given univariate time series into samples with a specified number of input and output time steps. We can demonstrate this function on the small contrived dataset. The complete example is listed below. Running the example splits the univariate series into input and output time steps and prints the input and output components of each. Now that we know how to prepare data for multi-step forecasting, let¡¯s look at a 1D CNN model that can learn this mapping. The 1D CNN can output a vector directly that can be interpreted as a multi-step forecast. This approach was seen in the previous section were one time step of each output time series was forecasted as a vector. As with the 1D CNN models for univariate data in a prior section, the prepared samples must first be reshaped. The CNN expects data to have a three-dimensional structure of [samples, timesteps, features], and in this case, we only have one feature so the reshape is straightforward. With the number of input and output steps specified in the n_steps_in and n_steps_out variables, we can define a multi-step time-series forecasting model. The model can make a prediction for a single sample. We can predict the next two steps beyond the end of the dataset by providing the input: We would expect the predicted output to be: As expected by the model, the shape of the single sample of input data when making the prediction must be [1, 3, 1] for the 1 sample, 3 time steps of the input, and the single feature. Tying all of this together, the 1D CNN for multi-step forecasting with a univariate time series is listed below. Running the example forecasts and prints the next two time steps in the sequence. In the previous sections, we have looked at univariate, multivariate, and multi-step time series forecasting. It is possible to mix and match the different types of 1D CNN models presented so far for the different problems. This too applies to time series forecasting problems that involve multivariate and multi-step forecasting, but it may be a little more challenging. In this section, we will explore short examples of data preparation and modeling for multivariate multi-step time series forecasting as a template to ease this challenge, specifically: Perhaps the biggest stumbling block is in the preparation of data, so this is where we will focus our attention. There are those multivariate time series forecasting problems where the output series is separate but dependent upon the input time series, and multiple time steps are required for the output series. For example, consider our multivariate time series from a prior section: We may use three prior time steps of each of the two input time series to predict two time steps of the output time series. Input: Output: The split_sequences() function below implements this behavior. We can demonstrate this on our contrived dataset. The complete example is listed below. Running the example first prints the shape of the prepared training data. We can see that the shape of the input portion of the samples is three-dimensional, comprised of six samples, with three time steps and two variables for the two input time series. The output portion of the samples is two-dimensional for the six samples and the two time steps for each sample to be predicted. The prepared samples are then printed to confirm that the data was prepared as we specified. We can now develop a 1D CNN model for multi-step predictions. In this case, we will demonstrate a vector output model. The complete example is listed below. Running the example fits the model and predicts the next two time steps of the output sequence beyond the dataset. We would expect the next two steps to be [185, 205]. It is a challenging framing of the problem with very little data, and the arbitrarily configured version of the model gets close. A problem with parallel time series may require the prediction of multiple time steps of each time series. For example, consider our multivariate time series from a prior section: We may use the last three time steps from each of the three time series as input to the model, and predict the next time steps of each of the three time series as output. The first sample in the training dataset would be the following. Input: Output: The split_sequences() function below implements this behavior. We can demonstrate this function on the small contrived dataset. The complete example is listed below. Running the example first prints the shape of the prepared training dataset. We can see that both the input (X) and output (Y) elements of the dataset are three dimensional for the number of samples, time steps, and variables or parallel time series respectively. The input and output elements of each series are then printed side by side so that we can confirm that the data was prepared as we expected. We can now develop a 1D CNN model for this dataset. We will use a vector-output model in this case. As such, we must flatten the three-dimensional structure of the output portion of each sample in order to train the model. This means, instead of predicting two steps for each series, the model is trained on and expected to predict a vector of six numbers directly. The complete example is listed below. Running the example fits the model and predicts the values for each of the three time steps for the next two time steps beyond the end of the dataset. We would expect the values for these series and time steps to be as follows: We can see that the model forecast gets reasonably close to the expected values. In this tutorial, you discovered how to develop a suite of CNN models for a range of standard time series forecasting problems. Specifically, you learned: Do you have any questions?
Ask your questions in the comments below and I will do my best to answer. ¡¦with just a few lines of python code Discover how in my new Ebook:Deep Learning for Time Series Forecasting It provides self-study tutorials on topics like: CNNs, LSTMs,Multivariate Forecasting, Multi-Step Forecasting and much more¡¦ Skip the Academics. Just Results. Click to learn more. Hi Jason, Good post (as always)! I got a non related question. Recently I have been developed almost exclusively in javascript (both front react and backend with node js). It has been long time i have done asny solid coding in python, hence my skillset is rusty.  Now, I wonder, how do you see the applying of programming languages for ML apps.
Tensorflow is running now both inn a browser tf.js as well on the backend with node js (just like python?). That sounds like a great thing <U+2013> one language for everything. There are also courses on the topic, getting more tractionhttps://www.udemy.com/machine-learning-with-javascript/ Is javascript enough for machine learning apps? or python should be used? Can you please elaborate? thanks and regards
JSman Hmmm, maybe for small apps. I cannot imagine being able to convince my team that a JS solution would make more sense, unless the existing system was all JS or it as a front-end demo or something. Or maybe if the model was fit using something fast and used to make predictions in JS. Really, you want to use the same tech stack as the rest of the existing system/enterprise. Hi Jason, A very high quality article for me to learn more about deep learning. It really help me a lots.Please keep sharing the knowledge. Thank you! Cheer Thanks, I¡¯m glad to hear that. Nice site. Just a comment. IMO, It¡¯s a bit pretentious and weak to put the title PhD after your name (¡± I¡¯m Jason Brownlee PhD¡¦¡±). You don¡¯t need to validate yourself through a useless degree. You have already earned the respect of all of us through your wonderful work. A mention of your credentials at a bio page would have sufficed. Just my two cents. Thanks for the feedback. Testing showed me that ¡°phd¡± splashed around helps with creditability for first time visitors. Thanks Jason for your new clear, detailed and very well explained explanation (as always)!. I¡¯m glad it helped. I index an image by a low-level feature (color) as form of a digital vector can i can exploit the current topic for an image clasifier Maybe. Thanks Jason for a very detailed explanation of CNN, and the many ways we can approach a time forecasting problem with CNNs. I¡¯m happy it helped. Hi Jason, I have become a fan, after reading this post of yours. I have been trying to use 1D CNNs for one of my network anomaly applications, but somehow couldn¡¯t get them to work effectively. This post has all that I need to get my network up and running. Thanks. I¡¯m happy to hear that! Comment  Name (required)  Email (will not be published) (required)  Website","Keyword(freq): step(49), sample(26), model(11), component(8), array(7), feature(7), problem(7), value(7), variable(7), cnn(6)"
"6","vidhya",2018-11-15,"DataHack Summit 2018 is Almost Here <U+2013> WHERE HUMANS MEET ARTIFICIAL INTELLIGENCE","https://www.analyticsvidhya.com/blog/2018/11/datahack-summit-2018-build-india-nextgen-data-science-ecosystem/","Well <U+2013> we are just a week away from<U+00A0>DataHack Summit 2018<U+00A0>(22-25 November 2018, Bengaluru) <U+2013> India¡¯s most advanced conference on AI, Machine Learning, Deep Learning and IoT. If you are a data science professional, some one who dreams about machines and algorithms unleashing a new era in human evolution <U+2013> this is the place you want to be. Here¡¯s a small video outlining the vision behind<U+00A0>DataHack Summit<U+00A0>from the man behind Analytics Vidhya himself, Founder and CEO Kunal Jain: We are bringing together world-class AI practitioners, industry thought leaders, IoT experts, chief data scientists, data officers, machine learning engineers and researchers, technology evangelists, & data hackers from around the globe at this mega conference <U+2013> from 22 <U+2013> 25 November 2018! Tickets are almost sold out so hurry and Power talks, hack sessions, workshops, startup showcase, and a whole lot more <U+2013> this is just a microcosm of what we have in store for you at DataHack Summit 2018. Come with me <U+2013> let¡¯s take a tour around the conference! DataHack Summit is a win-win situation for everyone <U+2013> let me show you how. If you¡¯re an AI/ML/DL/IoT thought leader or executive looking to understand how things function from a holistic standpoint: And many, many more! Plenty of topics and domains will be covered and trust me, you don¡¯t want to miss this. And this isn¡¯t all. There are plenty more perks of attending DHS 2018 for leaders <U+2013> here¡¯s a couple of highlights: If you¡¯re an experienced data scientist, our hack sessions and talks will feel like you¡¯ve hit the jackpot: If you¡¯re a machine/deep learning researcher, we have: If you¡¯re looking to carve a career in data science and machine learning, we have plenty in store for you as well! There really is something at DataHack Summit 2018 for everyone! Let¡¯s drill deeper into the content and hold on to your seats, because this is going to be a thrilling ride. Analytics Vidhya is known for the world-class content we publish. This is not something we take lightly <U+2013> and that is reflected in the articles we publish and the content you will see at our flagship conference. This year, we have more sessions than ever before! These sessions will be covering a plethora of diverse topics that come under the AI umbrella. You can check out the tentative schedule (subject to changes in the coming days). Let¡¯s check out some highlights. We are delighted to announce two great industry leaders and influencers as the keynote speakers at DHS 2018 <U+2013><U+00A0>Ronald van Loon and Tarry Singh! Both of these eminent personalities bring a wealth of industry experience and leadership expertise to the Summit. Ronald van Loon is a recognized expert and a popular and well respected thought leader.<U+00A0>He has a demonstrated history of helping data driven companies generate business value with best of breed solutions and a hands-on approach. He is a guest author on leading Big Data sites, speaker/chairman/panel member on (inter)national events, and runs a successful series of webinars on Digital Transformation. Tarry Singh is the CEO, Founder and AI Neuroscience Researcher of an AI startup deepkapha.ai. In his 17 years of work experience, he has guided CxOs of numerous global organizations in setting up data-driven organizations from scratch. Tarry speaks regularly at global AI leadership summits worldwide and conducts workshops on a regular basis with his TAs who are currently Ph.Ds in various disciplines such as NLP, Computer Vision and Robotics disciplines. Leading industry experts? Check. Machine Learning practitioners? Check. We have 25+ power talks by data science practitioners and thought leaders from all over the globe. These power talks will encompass various tools, techniques and applications of Artificial Intelligence, Machine Learning and Deep Learning in the industry. Below are some of the prominent speakers who will be presenting at DHS 2018: Check out the full speaker line-up<U+00A0>here. What¡¯s more exciting than coding machine learning concepts from scratch? Hack sessions are one of the biggest features than elevate DataHack Summit to a whole different level. These sessions are a one-hour code walk-through where the speaker presents a live code demonstration in an interactive manner. We received an overwhelmingly positive response on them last year, and are delighted to showcase 15 of them this year! Check out Kunal¡¯s video where he expands on what you can look forward to: A wide variety of domains will be covered <U+2013> Machine Learning, Deep Learning, Recommendation Engine, Reinforcement Learning, Natural Language Processing, Time Series, Graph Embeddings, and much, much more. Below are a few popular hack sessions that¡¯ll be covered at DHS 2018: One of the most anticipated aspects of DataHack Summit 2018 are the workshops. And we are thrilled to be hosting 9 of them this year! These workshops aim to deliver practical knowledge in an exciting and easy-to-grasp manner, and enable the participants to build their own concepts under the supervision of experienced instructors. Excited, yet? Here¡¯s Kunal with an overview of what you can expect from these workshops: Awesome! These 8-hour workshops cover a range of topics in Machine Learning and Deep Learning <U+2013> and to add the icing on the cake, leading industry practitioners will be your guide! Check out the complete workshop list below and enroll yourself TODAY: Want to see the real power of machine learning in society? A huge addition to DataHack Summit 2018 is the ¡®Startup Showcase¡¯. Leading startups from across the globe will be showcasing some of the most exciting Artificial Intelligence and Machine Learning products from a variety of domains. Here¡¯s a glimpse of the startups who will be presenting at the conference: And there are more startups coming this week!","Keyword(freq): session(7), workshop(6), leader(4), practitioner(4), talk(4), domain(3), startup(3), topic(3), analytics(2), concept(2)"
