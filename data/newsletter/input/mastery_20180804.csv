"site","date","headline","url_address","text"
"mastery",2018-08-01,"Why Initialize a Neural Network with Random Weights?","https://machinelearningmastery.com/why-initialize-a-neural-network-with-random-weights/","The weights of artificial neural networks must be initialized to small random numbers. This is because this is an expectation of the stochastic optimization algorithm used to train the model, called stochastic gradient descent. To understand this approach to problem solving, you must first understand the role of nondeterministic and randomized algorithms as well as the need for stochastic optimization algorithms to harness randomness in their search process. In this post, you will discover the full background as to why neural network weights must be randomly initialized. After reading this post, you will know: Let¡¯s get started. Why Initialize a Neural Network with Random Weights?Photo by lwtt93, some rights reserved. This post is divided into 4 parts; they are: Classical algorithms are deterministic. An example is an algorithm to sort a list. Given an unsorted list, the sorting algorithm, say bubble sort or quick sort, will systematically sort the list until you have an ordered result. Deterministic means that each time the algorithm is given the same list, it will execute in exactly the same way. It will make the same moves at each step of the procedure. Deterministic algorithms are great as they can make guarantees about best, worst, and average running time. The problem is, they are not suitable for all problems. Some problems are hard for computers. Perhaps because of the number of combinations; perhaps because of the size of data. They are so hard because a deterministic algorithm cannot be used to solve them efficiently. The algorithm may run, but will continue running until the heat death of the universe. An alternate solution is to use nondeterministic algorithms. These are algorithms that use elements of randomness when making decisions during the execution of the algorithm. This means that a different order of steps will be followed when the same algorithm is rerun on the same data. They can rapidly speed up the process of getting a solution, but the solution will be approximate, or ¡°good,¡± but often not the ¡°best.¡± Nondeterministic algorithms often cannot make strong guarantees about running time or the quality of the solution found. This is often fine as the problems are so hard that any good solution will often be satisfactory. Search problems are often very challenging and require the use of nondeterministic algorithms that make heavy use of randomness. The algorithms are not random per se; instead they make careful use of randomness. They are random within a bound and are referred to as stochastic algorithms. The incremental, or step-wise, nature of the search often means the process and the algorithms are referred to as an optimization from an initial state or position to a final state or position. For example, stochastic optimization problem or a stochastic optimization algorithm. Some examples include the genetic algorithm, simulated annealing, and stochastic gradient descent. The search process is incremental from a starting point in the space of possible solutions toward some good enough solution. They share common features in their use of randomness, such as: We know nothing about the structure of the search space. Therefore, to remove bias from the search process, we start from a randomly chosen position. As the search process unfolds, there is a risk that we are stuck in an unfavorable area of the search space. Using randomness during the search process gives some likelihood of getting unstuck and finding a better final candidate solution. The idea of getting stuck and returning a less-good solution is referred to as getting stuck in a local optima. These two elements of random initialization and randomness during the search work together. They work together better if we consider any solution found by the search as provisional, or a candidate, and that the search process can be performed multiple times. This gives the stochastic search process multiple opportunities to start and traverse the space of candidate solutions in search of a better candidate solution<U+2013>a so-called global optima. The navigation of the space of candidate solutions is often described using the analogy of a one- or two-landscape of mountains and valleys (e.g. like a fitness landscape). If we are maximizing a score during the search, we can think of small hills in the landscape as a local optima and the largest hills as the global optima. This is a fascinating area of research, an area where I have some background. For example, see my book: Artificial neural networks are trained using a stochastic optimization algorithm called stochastic gradient descent. The algorithm uses randomness in order to find a good enough set of weights for the specific mapping function from inputs to outputs in your data that is being learned. It means that your specific network on your specific training data will fit a different network with a different model skill each time the training algorithm is run. This is a feature, not a bug. I write about this issue more in the post: As described in the previous section, stochastic optimization algorithms such as stochastic gradient descent use randomness in selecting a starting point for the search and in the progression of the search. Specifically, stochastic gradient descent requires that the weights of the network are initialized to small random values (random, but close to zero, such as in [0.0, 0.1]). Randomness is also used during the search process in the shuffling of the training dataset prior to each epoch, which in turn results in differences in the gradient estimate for each batch. You can learn more about stochastic gradient descent in this post: The progression of the search or learning of a neural network is referred to as convergence. The discovering of a sub-optimal solution or local optima is referred to as premature convergence. Training algorithms for deep learning models are usually iterative in nature and thus require the user to specify some initial point from which to begin the iterations. Moreover, training deep models is a sufficiently difficult task that most algorithms are strongly affected by the choice of initialization. <U+2014> Page 301, Deep Learning, 2016. The most effective way to evaluate the skill of a neural network configuration is to repeat the search process multiple times and report the average performance of the model over those repeats. This gives the configuration the best chance to search the space from multiple different sets of initial conditions. Sometimes this is called a multiple restart or multiple-restart search. You can learn more about the effective evaluation of neural networks in this post: We can use the same set of weights each time we train the network; for example, you could use the values of 0.0 for all weights. In this case, the equations of the learning algorithm would fail to make any changes to the network weights, and the model will be stuck. It is important to note that the bias weight in each neuron is set to zero by default, not a small random value. Specifically, nodes that are side-by-side in a hidden layer connected to the same inputs must have different weights for the learning algorithm to update the weights. This is often referred to as the need to break symmetry during training. Perhaps the only property known with complete certainty is that the initial parameters need to ¡°break symmetry¡± between different units. If two hidden units with the same activation function are connected to the same inputs, then these units must have different initial parameters. If they have the same initial parameters, then a deterministic learning algorithm applied to a deterministic cost and model will constantly update both of these units in the same way. <U+2014> Page 301, Deep Learning, 2016. We could use the same set of random numbers each time the network is trained. This would not be helpful when evaluating network configurations. It may be helpful in order to train the same final set of network weights given a training dataset in the case where a model is being used in a production environment. You can learn more about fixing the random seed for neural networks developed with Keras in this post: Traditionally, the weights of a neural network were set to small random numbers. The initialization of the weights of neural networks is a whole field of study as the careful initialization of the network can speed up the learning process. Modern deep learning libraries, such as Keras, offer a host of network initialization methods, all are variations of initializing the weights with small random numbers. For example, the current methods are available in Keras at the time of writing for all network types: See the documentation for more details. Out of interest, the default initializers chosen by Keras developers for different layer types are as follows: You can learn more about ¡°glorot_uniform¡°, also called ¡°Xavier normal¡°, named for the developer of the method Xavier Glorot, in the paper: There is no single best way to initialize the weights of a neural network. Modern initialization strategies are simple and heuristic. Designing improved initialization strategies is a difficult task because neural network optimization is not yet well understood. [¡¦] Our understanding of how the initial point affects generalization is especially primitive, offering little to no guidance for how to select the initial point. <U+2014> Page 301, Deep Learning, 2016. It is one more hyperparameter for you to explore and test and experiment with on your specific predictive modeling problem. Do you have a favorite method for weight initialization?
Let me know in the comments below. This section provides more resources on the topic if you are looking to go deeper. In this post, you discovered why neural network weights must be randomly initialized. Specifically, you learned: Do you have any questions?
Ask your questions in the comments below and I will do my best to answer. ¡¦with just a few lines of Python Discover how in my new Ebook: Deep Learning With Python It covers self-study tutorials and end-to-end projects on topics like:Multilayer Perceptrons,<U+00A0>Convolutional Nets and<U+00A0>Recurrent Neural Nets, and more¡¦ Skip the Academics. Just<U+00A0>Results. Click to<U+00A0>learn more. It¡¯s probably worth mentioning pretrained initialization. E.g. if you¡¯re working with RGB images and using a standard architecture, chances are that pretrained weights for ImageNet exist, and that¡¯s often a better starting point than random. That¡¯s a great point. Even though I don¡¯t work on image processing I have seen articles where people have used transfer learning very effectively. I have started to see transfer learning in NLP and time series as well. Highly effective! Hmmmm regarding ¡®Transfer Learning in NLP¡¯. I know of only one way to do it it effectively; pre-trained word-embedding + manually adding words/vectors. Example: ¡®dollares¡¯ is not in word-embedding, but you need it. And ¡®dollares¡¯ is a synonym for ¡®dollar¡¯. So you manually add in the txt or bin the word ¡®dollares¡¯ with the same word vectors (e.g. 300) as for ¡®dollar¡¯.  To me, everything else fail in ¡°Transfer Learning in NLP¡±. Technically, there are other ways of doing it (as you posted in another blog), but in practice, they don¡¯t work when I try them. Franco Fitting LSTM language models and using them with a little re-training has worked well for me on some projects as a time saver. Nice, thanks Chris! Comment  Name (required)  Email (will not be published) (required)  Website Hi, I'm Jason Brownlee, Ph.D.

My goal is to make developers like YOU awesome at applied machine learning."
"mastery",2018-07-30,"How to Code the Student¡¯s t-Test from Scratch in Python","https://machinelearningmastery.com/how-to-code-the-students-t-test-from-scratch-in-python/","Perhaps one of the most widely used statistical hypothesis tests is the Student¡¯s t test. Because you may use this test yourself someday, it is important to have a deep understanding of how the test works. As a developer, this understanding is best achieved by implementing the hypothesis test yourself from scratch. In this tutorial, you will discover how to implement the Student¡¯s t-test statistical hypothesis test from scratch in Python. After completing this tutorial, you will know: Let¡¯s get started. How to Code the Student¡¯s t-Test from Scratch in PythonPhoto by n1d, some rights reserved. This tutorial is divided into three parts; they are: Take my free 7-day email crash course now (with sample code). Click to sign-up and also get a free PDF Ebook version of the course. Download Your FREE Mini-Course The Student¡¯s t-Test is a statistical hypothesis test for testing whether two samples are expected to have been drawn from the same population. It is named for the pseudonym ¡°Student¡± used by William Gosset, who developed the test. The test works by checking the means from two samples to see if they are significantly different from each other. It does this by calculating the standard error in the difference between means, which can be interpreted to see how likely the difference is, if the two samples have the same mean (the null hypothesis). The t statistic calculated by the test can be interpreted by comparing it to critical values from the t-distribution. The critical value can be calculated using the degrees of freedom and a significance level with the percent point function (PPF). We can interpret the statistic value in a two-tailed test, meaning that if we reject the null hypothesis, it could be because the first mean is smaller or greater than the second mean. To do this, we can calculate the absolute value of the test statistic and compare it to the positive (right tailed) critical value, as follows: We can also retrieve the cumulative probability of observing the absolute value of the t-statistic using the cumulative distribution function (CDF) of the t-distribution in order to calculate a p-value. The p-value can then be compared to a chosen significance level (alpha) such as 0.05 to determine if the null hypothesis can be rejected: In working with the means of the samples, the test assumes that both samples were drawn from a Gaussian distribution. The test also assumes that the samples have the same variance, and the same size, although there are corrections to the test if these assumptions do not hold. For example, see Welch¡¯s t-test. There are two main versions of Student¡¯s t-test: Both the independent and the dependent Student¡¯s t-tests are available in Python via the ttest_ind() and ttest_rel() SciPy functions respectively. Note: I recommend using these SciPy functions to calculate the Student¡¯s t-test for your applications, if they are suitable. The library implementations will be faster and less prone to bugs. I would only recommend implementing the test yourself for learning purposes or in the case where you require a modified version of the test. We will use the SciPy functions to confirm the results from our own version of the tests. Note, for reference, all calculations presented in this tutorial are taken directly from Chapter 9 ¡°t Tests¡± in ¡°Statistics in Plain English¡°, Third Edition, 2010. I mention this because you may see the equations with different forms, depending on the reference text that you use. We¡¯ll start with the most common form of the Student¡¯s t-test: the case where we are comparing the means of two independent samples. The calculation of the t-statistic for two independent samples is as follows: or Where X1 and X2 are the first and second data samples and sed is the standard error of the difference between the means. The standard error of the difference between the means can be calculated as follows: Where se1 and se2 are the standard errors for the first and second datasets. The standard error of a sample can be calculated as: Where se is the standard error of the sample, std is the sample standard deviation, and n is the number of observations in the sample. These calculations make the following assumptions: We can implement these equations easily using functions from the Python standard library, NumPy and SciPy. Let¡¯s assume that our two data samples are stored in the variables data1 and data2. We can start off by calculating the mean for these samples as follows: We¡¯re halfway there. Now we need to calculate the standard error. We can do this manually, first by calculating the sample standard deviations: And then the standard errors: Alternately, we can use the sem() SciPy function to calculate the standard error directly. We can use the standard errors of the samples to calculate the ¡°standard error on the difference between the samples¡°: We can now calculate the t statistic: We can also calculate some other values to help interpret and present the statistic. The number of degrees of freedom for the test is calculated as the sum of the observations in both samples, minus two. The critical value can be calculated using the percent point function (PPF) for a given significance level, such as 0.05 (95% confidence). This function is available for the t distribution in SciPy, as follows: The p-value can be calculated using the cumulative distribution function on the t-distribution, again in SciPy. Here, we assume a two-tailed distribution, where the rejection of the null hypothesis could be interpreted as the first mean is either smaller or larger than the second mean. We can tie all of these pieces together into a simple function for calculating the t-test for two independent samples: In this section we will calculate the t-test on some synthetic data samples. First, let¡¯s generate two samples of 100 Gaussian random numbers with the same variance of 5 and differing means of 50 and 51 respectively. We will expect the test to reject the null hypothesis and find a significant difference between the samples: We can calculate the t-test on these samples using the built in SciPy function ttest_ind(). This will give us a t-statistic value and a p-value to compare to, to ensure that we have implemented the test correctly. The complete example is listed below. Running the example, we can see a t-statistic value and p value. We will use these as our expected values for the test on these data. We can now apply our own implementation on the same data, using the function defined in the previous section. The function will return a t-statistic value and a critical value. We can use the critical value to interpret the t statistic to see if the finding of the test is significant and that indeed the means are different as we expected. The function also returns a p-value. We can interpret the p-value using an alpha, such as 0.05 to determine if the finding of the test is significant and that indeed the means are different as we expected. We expect that both interpretations will always match. The complete example is listed below. Running the example first calculates the test. The results of the test are printed, including the t-statistic, the degrees of freedom, the critical value, and the p-value. We can see that both the t-statistic and p-value match the outputs of the SciPy function. The test appears to be implemented correctly. The t-statistic and the p-value are then used to interpret the results of the test. We find that as we expect, there is sufficient evidence to reject the null hypothesis, finding that the sample means are likely different. We can now look at the case of calculating the Student¡¯s t-test for dependent samples. This is the case where we collect some observations on a sample from the population, then apply some treatment, and then collect observations from the same sample. The result is two samples of the same size where the observations in each sample are related or paired. The t-test for dependent samples is referred to as the paired Student¡¯s t-test. The calculation of the paired Student¡¯s t-test is similar to the case with independent samples. The main difference is in the calculation of the denominator. Where X1 and X2 are the first and second data samples and sed is the standard error of the difference between the means. Here, sed is calculated as: Where sd is the standard deviation of the difference between the dependent sample means and n is the total number of paired observations (e.g. the size of each sample). The calculation of sd first requires the calculation of the sum of the squared differences between the samples: It also requires the sum of the (non squared) differences between the samples: We can then calculate sd as: That¡¯s it. We can implement the calculation of the paired Student¡¯s t-test directly in Python. The first step is to calculate the means of each sample. Next, we will require the number of pairs (n). We will use this in a few different calculations. Next, we must calculate the sum of the squared differences between the samples, as well as the sum differences. We can now calculate the standard deviation of the difference between means. This is then used to calculate the standard error of the difference between the means. Finally, we have everything we need to calculate the t statistic. The only other key difference between this implementation and the implementation for independent samples is the calculation of the number of degrees of freedom. As before, we can tie all of this together into a reusable function. The function will take two paired samples and a significance level (alpha) and calculate the t-statistic, number of degrees of freedom, critical value, and p-value. The complete function is listed below. In this section, we will use the same dataset in the worked example as we did for the independent Student¡¯s t-test. The data samples are not paired, but we will pretend they are. We expect the test to reject the null hypothesis and find a significant difference between the samples. As before, we can evaluate the test problem with the SciPy function for calculating a paired t-test. In this case, the ttest_rel() function. The complete example is listed below. Running the example calculates and prints the t-statistic and the p-value. We will use these values to validate the calculation of our own paired t-test function. We can now test our own implementation of the paired Student¡¯s t-test. The complete example, including the developed function and interpretation of the results of the function, is listed below. Running the example calculates the paired t-test on the sample problem. The calculated t-statistic and p-value match what we expect from the SciPy library implementation. This suggests that the implementation is correct. The interpretation of the t-test statistic with the critical value, and the p-value with the significance level both find a significant result, rejecting the null hypothesis that the means are equal. This section lists some ideas for extending the tutorial that you may wish to explore. If you explore any of these extensions, I¡¯d love to know. This section provides more resources on the topic if you are looking to go deeper. In this tutorial, you discovered how to implement the Student¡¯s t-test statistical hypothesis test from scratch in Python. Specifically, you learned: Do you have any questions?
Ask your questions in the comments below and I will do my best to answer. ¡¦by writing lines of code in python Discover how in my new Ebook:Statistical Methods for Machine Learning It provides self-study tutorials on topics like:Hypothesis Tests, Correlation, Nonparametric Stats, Resampling, and much more¡¦ Skip the Academics. Just Results. Click to learn more. Jason, Great post, I enjoy them.  A source of confusion for me for a long time was that the t-test doesn¡¯t require the two populations to be normally distributed, but rather the *sampling distribution* be normal which happens with a larger number of samples thanks to the central limit theorem   So taking 200 samples each of size 30, the distribution of those means will approach normality. A large sample will just reproduce the parent population. This is why the t-test is so useful, because you could have a freaky triangular parent distribution and it still works. Great note Tim, thanks for sharing. Comment  Name (required)  Email (will not be published) (required)  Website Hi, I'm Jason Brownlee, Ph.D.

My goal is to make developers like YOU awesome at applied machine learning."
