"site","date","headline","url_address","text"
"mastery",2018-10-01,"How to Develop and Evaluate Naive Methods for Forecasting Household Electricity Consumption","https://machinelearningmastery.com/naive-methods-for-forecasting-household-electricity-consumption/","Given the rise of smart electricity meters and the wide adoption of electricity generation technology like solar panels, there is a wealth of electricity usage data available. This data represents a multivariate time series of power-related variables that in turn could be used to model and even forecast future electricity consumption. In this tutorial, you will discover how to develop a test harness for the ¡®household power consumption¡¯ dataset and evaluate three naive forecast strategies that provide a baseline for more sophisticated algorithms. After completing this tutorial, you will know: Let¡¯s get started. How to Develop and Evaluate Naive Forecast Methods for Forecasting Household Electricity ConsumptionPhoto by Philippe Put, some rights reserved. This tutorial is divided into four parts; they are: The ¡®Household Power Consumption¡® dataset is a multivariate time series dataset that describes the electricity consumption for a single household over four years. The data was collected between December 2006 and November 2010 and observations of power consumption within the household were collected every minute. It is a multivariate series comprised of seven variables (besides the date and time); they are: Active and reactive energy refer to the technical details of alternative current. A fourth sub-metering variable can be created by subtracting the sum of three defined sub-metering variables from the total active energy as follows: The dataset can be downloaded from the UCI Machine Learning repository as a single 20 megabyte .zip file: Download the dataset and unzip it into your current working directory. You will now have the file ¡°household_power_consumption.txt¡± that is about 127 megabytes in size and contains all of the observations. We can use the read_csv() function to load the data and combine the first two columns into a single date-time column that we can use as an index. Next, we can mark all missing values indicated with a ¡®?¡® character with a NaN value, which is a float. This will allow us to work with the data as one array of floating point values rather than mixed types (less efficient.) We also need to fill in the missing values now that they have been marked. A very simple approach would be to copy the observation from the same time the day before. We can implement this in a function named fill_missing() that will take the NumPy array of the data and copy values from exactly 24 hours ago. We can apply this function directly to the data within the DataFrame. Now we can create a new column that contains the remainder of the sub-metering, using the calculation from the previous section. We can now save the cleaned-up version of the dataset to a new file; in this case we will just change the file extension to .csv and save the dataset as ¡®household_power_consumption.csv¡®. Tying all of this together, the complete example of loading, cleaning-up, and saving the dataset is listed below. Running the example creates the new file ¡®household_power_consumption.csv¡® that we can use as the starting point for our modeling project. Take my free 7-day email crash course now (with sample code). Click to sign-up and also get a free PDF Ebook version of the course. Download Your FREE Mini-Course In this section, we will consider how we can develop and evaluate predictive models for the household power dataset. This section is divided into four parts; they are: There are many ways to harness and explore the household power consumption dataset. In this tutorial, we will use the data to explore a very specific question; that is: Given recent power consumption, what is the expected power consumption for the week ahead? This requires that a predictive model forecast the total active power for each day over the next seven days. Technically, this framing of the problem is referred to as a multi-step time series forecasting problem, given the multiple forecast steps. A model that makes use of multiple input variables may be referred to as a multivariate multi-step time series forecasting model. A model of this type could be helpful within the household in planning expenditures. It could also be helpful on the supply side for planning electricity demand for a specific household. This framing of the dataset also suggests that it would be useful to downsample the per-minute observations of power consumption to daily totals. This is not required, but makes sense, given that we are interested in total power per day. We can achieve this easily using the resample() function on the pandas DataFrame. Calling this function with the argument ¡®D¡® allows the loaded data indexed by date-time to be grouped by day (see all offset aliases). We can then calculate the sum of all observations for each day and create a new dataset of daily power consumption data for each of the eight variables. The complete example is listed below. Running the example creates a new daily total power consumption dataset and saves the result into a separate file named ¡®household_power_consumption_days.csv¡®. We can use this as the dataset for fitting and evaluating predictive models for the chosen framing of the problem. A forecast will be comprised of seven values, one for each day of the week ahead. It is common with multi-step forecasting problems to evaluate each forecasted time step separately. This is helpful for a few reasons: The units of the total power are kilowatts and it would be useful to have an error metric that was also in the same units. Both Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE) fit this bill, although RMSE is more commonly used and will be adopted in this tutorial. Unlike MAE, RMSE is more punishing of forecast errors. The performance metric for this problem will be the RMSE for each lead time from day 1 to day 7. As a short-cut, it may be useful to summarize the performance of a model using a single score in order to aide in model selection. One possible score that could be used would be the RMSE across all forecast days. The function evaluate_forecasts() below will implement this behavior and return the performance of a model based on multiple seven-day forecasts. Running the function will first return the overall RMSE regardless of day, then an array of RMSE scores for each day. We will use the first three years of data for training predictive models and the final year for evaluating models. The data in a given dataset will be divided into standard weeks. These are weeks that begin on a Sunday and end on a Saturday. This is a realistic and useful way for using the chosen framing of the model, where the power consumption for the week ahead can be predicted. It is also helpful with modeling, where models can be used to predict a specific day (e.g. Wednesday) or the entire sequence. We will split the data into standard weeks, working backwards from the test dataset. The final year of the data is in 2010 and the first Sunday for 2010 was January 3rd. The data ends in mid November 2010 and the closest final Saturday in the data is November 20th. This gives 46 weeks of test data. The first and last rows of daily data for the test dataset are provided below for confirmation. The daily data starts in late 2006. The first Sunday in the dataset is December 17th, which is the second row of data. Organizing the data into standard weeks gives 159 full standard weeks for training a predictive model. The function split_dataset() below splits the daily data into train and test sets and organizes each into standard weeks. Specific row offsets are used to split the data using knowledge of the dataset. The split datasets are then organized into weekly data using the NumPy split() function. We can test this function out by loading the daily dataset and printing the first and last rows of data from both the train and test sets to confirm they match the expectations above. The complete code example is listed below. Running the example shows that indeed the train dataset has 159 weeks of data, whereas the test dataset has 46 weeks. We can see that the total active power for the train and test dataset for the first and last rows match the data for the specific dates that we defined as the bounds on the standard weeks for each set. Models will be evaluated using a scheme called walk-forward validation. This is where a model is required to make a one week prediction, then the actual data for that week is made available to the model so that it can be used as the basis for making a prediction on the subsequent week. This is both realistic for how the model may be used in practice and beneficial to the models allowing them to make use of the best available data. We can demonstrate this below with separation of input data and output/predicted data. The walk-forward validation approach to evaluating predictive models on this dataset is implement below, named evaluate_model(). The name of a function is provided for the model as the argument ¡°model_func¡°. This function is responsible for defining the model, fitting the model on the training data, and making a one-week forecast. The forecasts made by the model are then evaluated against the test dataset using the previously defined evaluate_forecasts() function. Once we have the evaluation for a model, we can summarize the performance. The function below named summarize_scores() will display the performance of a model as a single line for easy comparison with other models. We now have all of the elements to begin evaluating predictive models on the dataset. It is important to test naive forecast models on any new prediction problem. The results from naive models provide a quantitative idea of how difficult the forecast problem is and provide a baseline performance by which more sophisticated forecast methods can be evaluated. In this section, we will develop and compare three naive forecast methods for the household power prediction problem; they are: The first naive forecast that we will develop is a daily persistence model. This model takes the active power from the last day prior to the forecast period (e.g. Saturday) and uses it as the value of the power for each day in the forecast period (Sunday to Saturday). The daily_persistence() function below implements the daily persistence forecast strategy. Another good naive forecast when forecasting a standard week is to use the entire prior week as the forecast for the week ahead. It is based on the idea that next week will be very similar to this week. The weekly_persistence() function below implements the weekly persistence forecast strategy. Similar to the idea of using last week to forecast next week is the idea of using the same week last year to predict next week. That is, use the week of observations from 52 weeks ago as the forecast, based on the idea that next week will be similar to the same week one year ago. The week_one_year_ago_persistence() function below implements the week one year ago forecast strategy. We can compare each of the forecast strategies using the test harness developed in the previous section. First, the dataset can be loaded and split into train and test sets. Each of the strategies can be stored in a dictionary against a unique name. This name can be used in printing and in creating a plot of the scores. We can then enumerate each of the strategies, evaluating it using walk-forward validation, printing the scores, and adding the scores to a line plot for visual comparison. Tying all of this together, the complete example evaluating the three naive forecast strategies is listed below. Running the example first prints the total and daily scores for each model. We can see that the weekly strategy performs better than the daily strategy and that the week one year ago (week-oya) performs slightly better again. We can see this in both the overall RMSE scores for each model and in the daily scores for each forecast day. One exception is the forecast error for the first day (Sunday) where it appears that the daily persistence model performs better than the two weekly strategies. We can use the week-oya strategy with an overall RMSE of 465.294 kilowatts as the baseline in performance for more sophisticated models to be considered skillful on this specific framing of the problem. A line plot of the daily forecast error is also created. We can see the same observed pattern of the weekly strategies performing better than the daily strategy in general, except in the case of the first day. It is surprising (to me) that the week one-year-ago performs better than using the prior week. I would have expected that the power consumption from last week to be more relevant. Reviewing all strategies on the same plot suggests possible combinations of the strategies that may result in even better performance. Line Plot Comparing Naive Forecast Strategies for Household Power Forecasting This section lists some ideas for extending the tutorial that you may wish to explore. If you explore any of these extensions, I¡¯d love to know. This section provides more resources on the topic if you are looking to go deeper. In this tutorial, you discovered how to develop a test harness for the household power consumption dataset and evaluate three naive forecast strategies that provide a baseline for more sophisticated algorithms. Specifically, you learned: Do you have any questions?
Ask your questions in the comments below and I will do my best to answer. ¡¦with just a few lines of python code Discover how in my new Ebook:Deep Learning for Time Series Forecasting It provides self-study tutorials on topics like: CNNs, LSTMs,Multivariate Forecasting, Multi-Step Forecasting and much more¡¦ Skip the Academics. Just Results. Click to learn more. Comment  Name (required)  Email (will not be published) (required)  Website"
"mastery",2018-09-28,"How to Load and Explore Household Electricity Usage Data","https://machinelearningmastery.com/how-to-load-and-explore-household-electricity-usage-data/","Given the rise of smart electricity meters and the wide adoption of electricity generation technology like solar panels, there is a wealth of electricity usage data available. This data represents a multivariate time series of power-related variables, that in turn could be used to model and even forecast future electricity consumption. In this tutorial, you will discover a household power consumption dataset for multi-step time series forecasting and how to better understand the raw data using exploratory analysis. After completing this tutorial, you will know: Let¡¯s get started. How to Load and Explore Household Electricity Usage DataPhoto by Sheila Sund, some rights reserved. This tutorial is divided into five parts; they are: The Household Power Consumption dataset is a multivariate time series dataset that describes the electricity consumption for a single household over four years. The data was collected between December 2006 and November 2010 and observations of power consumption within the household were collected every minute. It is a multivariate series comprised of seven variables (besides the date and time); they are: Active and reactive energy refer to the technical details of alternative current. In general terms, the active energy is the real power consumed by the household, whereas the reactive energy is the unused power in the lines. We can see that the dataset provides the active power as well as some division of the active power by main circuit in the house, specifically the kitchen, laundry, and climate control. These are not all the circuits in the household. The remaining watt-hours can be calculated from the active energy by first converting the active energy to watt-hours then subtracting the other sub-metered active energy in watt-hours, as follows: The dataset seems to have been provided without a seminal reference paper. Nevertheless, this dataset has become a standard for evaluating time series forecasting and machine learning methods for multi-step forecasting, specifically for forecasting active power. Further, it is not clear whether the other features in the dataset may benefit a model in forecasting active power. Take my free 7-day email crash course now (with sample code). Click to sign-up and also get a free PDF Ebook version of the course. Download Your FREE Mini-Course The dataset can be downloaded from the UCI Machine Learning repository as a single 20 megabyte .zip file: Download the dataset and unzip it into your current working directory. You will now have the file ¡°household_power_consumption.txt¡± that is about 127 megabytes in size and contains all of the observations Inspect the data file. Below are the first five rows of data (and the header) from the raw data file. We can see that the data columns are separated by semicolons (¡®;¡®). The data is reported to have one row for each day in the time period. The data does have missing values; for example, we can see 2-3 days worth of missing data around 28/4/2007. We can start-off by loading the data file as a Pandas DataFrame and summarize the loaded data. We can use the read_csv() function to load the data. It is easy to load the data with this function, but a little tricky to load it correctly. Specifically, we need to do a few custom things: Putting all of this together, we can now load the data and summarize the loaded shape and first few rows. Next, we can mark all missing values indicated with a ¡®?¡¯ character with a NaN value, which is a float. This will allow us to work with the data as one array of floating point values rather than mixed types, which is less efficient. Now we can create a new column that contains the remainder of the sub-metering, using the calculation from the previous section. We can now save the cleaned-up version of the dataset to a new file; in this case we will just change the file extension to .csv and save the dataset as ¡®household_power_consumption.csv¡®. To confirm that we have not messed-up, we can re-load the dataset and summarize the first five rows. Tying all of this together, the complete example of loading, cleaning-up, and saving the dataset is listed below. Running the example first loads the raw data and summarizes the shape and first five rows of the loaded data. The dataset is then cleaned up and saved to a new file. We load this new file and again print the first five rows, showing the removal of the date and time columns and addition of the new sub-metered column. We can peek inside the new ¡®household_power_consumption.csv¡® file and check that the missing observations are marked with an empty column, that pandas will correctly read as NaN, for example around row 190,499: Now that we have a cleaned-up version of the dataset, we can investigate it further using visualizations. The data is a multivariate time series and the best way to understand a time series is to create line plots. We can start off by creating a separate line plot for each of the eight variables. The complete example is listed below. Running the example creates a single image with eight subplots, one for each variable. This gives us a really high level of the four years of one minute observations. We can see that something interesting was going on in ¡®Sub_metering_3¡® (environmental control) that may not directly map to hot or cold years. Perhaps new systems were installed. Interestingly, the contribution of ¡®sub_metering_4¡® seems to decrease with time, or show a downward trend, perhaps matching up with the solid increase in seen towards the end of the series for ¡®Sub_metering_3¡®. These observations do reinforce the need to honor the temporal ordering of subsequences of this data when fitting and evaluating any model. We might be able to see the wave of a seasonal effect in the ¡®Global_active_power¡® and some other variates. There is some spiky usage that may match up with a specific period, such as weekends. Line Plots of Each Variable in the Power Consumption Dataset Let¡¯s zoom in and focus on the ¡®Global_active_power¡®, or ¡®active power¡® for short. We can create a new plot of the active power for each year to see if there are any common patterns across the years. The first year, 2006, has less than one month of data, so will remove it from the plot. The complete example is listed below. Running the example creates one single image with four line plots, one for each full year (or mostly full years) of data in the dataset. We can see some common gross patterns across the years, such as around Feb-Mar and around Aug-Sept where we see a marked decrease in consumption. We also seem to see a downward trend over the summer months (middle of the year in the northern hemisphere) and perhaps more consumption in the winter months towards the edges of the plots. These may show an annual seasonal pattern in consumption. We can also see a few patches of missing data in at least the first, third, and fourth plots. Line Plots of Active Power for Most Years We can continue to zoom in on consumption and look at active power for each of the 12 months of 2007. This might help tease out gross structures across the months, such as daily and weekly patterns. The complete example is listed below. Running the example creates a single image with 12 line plots, one for each month in 2007. We can see the sign-wave of power consumption of the days within each month. This is good as we would expect some kind of daily pattern in power consumption. We can see that there are stretches of days with very minimal consumption, such as in August and in April. These may represent vacation periods where the home was unoccupied and where power consumption was minimal. Line Plots for Active Power for All Months in One Year Finally, we can zoom in one more level and take a closer look at power consumption at the daily level. We would expect there to be some pattern to consumption each day, and perhaps differences in days over a week. The complete example is listed below. Running the example creates a single image with 20 line plots, one for the first 20 days in January 2007. There is commonality across the days; for example, many days consumption starts early morning, around 6-7AM. Some days show a drop in consumption in the middle of the day, which might make sense if most occupants are out of the house. We do see some strong overnight consumption on some days, that in a northern hemisphere January may match up with a heating system being used. Time of year, specifically the season and the weather that it brings, will be an important factor in modeling this data, as would be expected. Line Plots for Active Power for 20 Days in One Month Another important area to consider is the distribution of the variables. For example, it may be interesting to know if the distributions of observations are Gaussian or some other distribution. We can investigate the distributions of the data by reviewing histograms. We can start-off by creating a histogram for each variable in the time series. The complete example is listed below. Running the example creates a single figure with a separate histogram for each of the 8 variables. We can see that active and reactive power, intensity, as well as the sub-metered power are all skewed distributions down towards small watt-hour or kilowatt values. We can also see that distribution of voltage data is strongly Gaussian. Histogram plots for Each Variable in the Power Consumption Dataset The distribution of active power appears to be bi-modal, meaning it looks like it has two mean groups of observations. We can investigate this further by looking at the distribution of active power consumption for the four full years of data. The complete example is listed below. Running the example creates a single plot with four figures, one for each of the years between 2007 to 2010. We can see that the distribution of active power consumption across those years looks very similar. The distribution is indeed bimodal with one peak around 0.3 KW and perhaps another around 1.3 KW. There is a long tail on the distribution to higher kilowatt values. It might open the door to notions of discretizing the data and separating it into peak 1, peak 2 or long tail. These groups or clusters for usage on a day or hour may be helpful in developing a predictive model. Histogram Plots of Active Power for Most Years It is possible that the identified groups may vary over the seasons of the year. We can investigate this by looking at the distribution for active power for each month in a year. The complete example is listed below. Running the example creates an image with 12 plots, one for each month in 2007. We can see generally the same data distribution each month. The axes for the plots appear to align (given the similar scales), and we can see that the peaks are shifted down in the warmer northern hemisphere months and shifted up for the colder months. We can also see a thicker or more prominent tail toward larger kilowatt values for the cooler months of December through to March. Histogram Plots for Active Power for All Months in One Year Now that we know how to load and explore the dataset, we can pose some ideas on how to model the dataset. In this section, we will take a closer look at three main areas when working with the data; they are: There does not appear to be a seminal publication for the dataset to demonstrate the intended way to frame the data in a predictive modeling problem. We are therefore left to guess at possibly useful ways that this data may be used. The data is only for a single household, but perhaps effective modeling approaches could be generalized across to similar households. Perhaps the most useful framing of the dataset is to forecast an interval of future active power consumption. Four examples include: Generally, these types of forecasting problems are referred to as multi-step forecasting. Models that make use of all of the variables might be referred to as a multivariate multi-step forecasting models. Each of these models is not limited to forecasting the minutely data, but instead could model the problem at or below the chosen forecast resolution. Forecasting consumption in turn, at scale, could aid in a utility company forecasting demand, which is a widely studied and important problem. There is a lot of flexibility in preparing this data for modeling. The specific data preparation methods and their benefit really depend on the chosen framing of the problem and the modeling methods. Nevertheless, below is a list of general data preparation methods that may be useful: There are many simple human factors that may be helpful in engineering features from the data, that in turn may make specific days easier to forecast. Some examples include: These factors may be significantly less important for forecasting monthly data, and perhaps to a degree for weekly data. More general features may include: There are perhaps four classes of methods that might be interesting to explore on this problem; they are: Naive methods would include methods that make very simple, but often very effective assumptions. Some examples include: Classical linear methods include techniques are very effective for univariate time series forecasting. Two important examples include: They would require that the additional variables be discarded and the parameters of the model be configured or tuned to the specific framing of the dataset. Concerns related to adjusting the data for daily and seasonal structures can also be supported directly. Machine learning methods require that the problem be framed as a supervised learning problem. This would require that lag observations for a series be framed as input features, discarding the temporal relationship in the data. A suite of nonlinear and ensemble methods could be explored, including: Careful attention is required to ensure that the fitting and evaluation of these models preserved the temporal structure in the data. This is important so that the method is not able to ¡®cheat¡¯ by harnessing observations from the future. These methods are often agnostic to large numbers of variables and may aid in teasing out whether the additional variables can be harnessed and add value to predictive models. Generally, neural networks have not proven very effective at autoregression type problems. Nevertheless, techniques such as convolutional neural networks are able to automatically learn complex features from raw data, including one-dimensional signal data. And recurrent neural networks, such as the long short-term memory network, are capable of directly learning across multiple parallel sequences of input data. Further, combinations of these methods, such as CNN LSTM and ConvLSTM, have proven effective on time series classification tasks. It is possible that these methods may be able to harness the large volume of minute-based data and multiple input variables. This section provides more resources on the topic if you are looking to go deeper. In this tutorial, you discovered a household power consumption dataset for multi-step time series forecasting and how to better understand the raw data using exploratory analysis. Specifically, you learned: Do you have any questions?
Ask your questions in the comments below and I will do my best to answer. ¡¦with just a few lines of python code Discover how in my new Ebook:Deep Learning for Time Series Forecasting It provides self-study tutorials on topics like: CNNs, LSTMs,Multivariate Forecasting, Multi-Step Forecasting and much more¡¦ Skip the Academics. Just Results. Click to learn more. Great work Jason! Thanks. Thank you for the post. It is really helpful.
I was wondering how to frame the input data for Forecasting hourly consumption for the next day using SVM, ANN  and Randomforest. Is there any reference for multi-step multi-variate time series prediction?
Also, would Forecast hourly consumption for the next day be more accurate than Forecast hourly consumption for the next week? Yes, I have many examples. Here¡¯s a starting point:https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/ I also have many more examples in my book:https://machinelearningmastery.com/deep-learning-for-time-series-forecasting/ If there was ¡°IoT¡± in the title, people (including me) would faster recognize the immense value in your post/book. Thanks for the suggestion. Comment  Name (required)  Email (will not be published) (required)  Website"
"mastery",2018-09-26,"Deep Learning Models for Human Activity Recognition","https://machinelearningmastery.com/deep-learning-models-for-human-activity-recognition/","Human activity recognition, or HAR, is a challenging time series classification task. It involves predicting the movement of a person based on sensor data and traditionally involves deep domain expertise and methods from signal processing to correctly engineer features from the raw data in order to fit a machine learning model. Recently, deep learning methods such as convolutional neural networks and recurrent neural networks have shown capable and even achieve state-of-the-art results by automatically learning features from the raw sensor data. In this post, you will discover the problem of human activity recognition and the deep learning methods that are achieving state-of-the-art performance on this problem. After reading this post, you will know: Let¡¯s get started. Deep Learning Models for Human Activity RecognitionPhoto by Simon Harrod, some rights reserved. This post is divided into five parts; they are: Human activity recognition, or HAR for short, is a broad field of study concerned with identifying the specific movement or action of a person based on sensor data. Movements are often typical activities performed indoors, such as walking, talking, standing, and sitting. They may also be more focused activities such as those types of activities performed in a kitchen or on a factory floor. The sensor data may be remotely recorded, such as video, radar, or other wireless methods. Alternately, data may be recorded directly on the subject such as by carrying custom hardware or smart phones that have accelerometers and gyroscopes. Sensor-based activity recognition seeks the profound high-level knowledge about human activities from multitudes of low-level sensor readings <U+2014> Deep Learning for Sensor-based Activity Recognition: A Survey, 2018. Historically, sensor data for activity recognition was challenging and expensive to collect, requiring custom hardware. Now smart phones and other personal tracking devices used for fitness and health monitoring are cheap and ubiquitous. As such, sensor data from these devices is cheaper to collect, more common, and therefore is a more commonly studied version of the general activity recognition problem. The problem is to predict the activity given a snapshot of sensor data, typically data from one or a small number of sensor types. Generally, this problem is framed as a univariate or multivariate time series classification task. It is a challenging problem as there are no obvious or direct ways to relate the recorded sensor data to specific human activities and each subject may perform an activity with significant variation, resulting in variations in the recorded sensor data. The intent is to record sensor data and corresponding activities for specific subjects, fit a model from this data, and generalize the model to classify the activity of new unseen subjects from their sensor data. Take my free 7-day email crash course now (with sample code). Click to sign-up and also get a free PDF Ebook version of the course. Download Your FREE Mini-Course Traditionally, methods from the field of signal processing were used to analyze and distill the collected sensor data. Such methods were for feature engineering, creating domain-specific, sensor-specific, or signal processing-specific features and views of the original data. Statistical and machine learning models were then trained on the processed version of the data. A limitation of this approach is the signal processing and domain expertise required to analyze the raw data and engineer the features required to fit a model. This expertise would be required for each new dataset or sensor modality. In essence, it is expensive and not scalable. However, in most daily HAR tasks, those methods may heavily rely on heuristic handcrafted feature extraction, which is usually limited by human domain knowledge. Furthermore, only shallow features can be learned by those approaches, leading to undermined performance for unsupervised and incremental tasks. Due to those limitations, the performances of conventional [pattern recognition] methods are restricted regarding classification accuracy and model generalization. <U+2014> Deep Learning for Sensor-based Activity Recognition: A Survey, 2018. Ideally, learning methods could be used that automatically learn the features required to make accurate predictions from the raw data directly. This would allow new problems, new datasets, and new sensor modalities to be adopted quickly and cheaply. Recently, deep neural network models have started delivering on their promises of feature learning and are achieving stat-of-the-art results for human activity recognition. They are capable of performing automatic feature learning from the raw sensor data and out-perform models fit on hand-crafted domain-specific features. [¡¦] , the feature extraction and model building procedures are often performed simultaneously in the deep learning models. The features can be learned automatically through the network instead of being manually designed. Besides, the deep neural network can also extract high-level representation in deep layer, which makes it more suitable for complex activity recognition tasks. <U+2014> Deep Learning for Sensor-based Activity Recognition: A Survey, 2018. There are two main approaches to neural networks that are appropriate for time series classification and that have been demonstrated to perform well on activity recognition using sensor data from commodity smart phones and fitness tracking devices. They are Convolutional Neural Network Models and Recurrent Neural Network Models. RNN and LSTM are recommended to recognize short activities that have natural order while CNN is better at inferring long term repetitive activities. The reason is that RNN could make use of the time-order relationship between sensor readings, and CNN is more capable of learning deep features contained in recursive patterns. <U+2014> Deep Learning for Sensor-based Activity Recognition: A Survey, 2018. Before we dive into the specific neural networks that can be used for human activity recognition, we need to talk about data preparation. Both types of neural networks suitable for time series classification require that data be prepared in a specific manner in order to fit a model. That is, in a ¡®supervised learning¡® way that allows the model to associate signal data with an activity class. A straight-forward data preparation approach that was used both for classical machine learning methods on the hand-crafted features and for neural networks involves dividing the input signal data into windows of signals, where a given window may have one to a few seconds of observation data. This is often called a ¡®sliding window.¡¯ Human activity recognition aims to infer the actions of one or more persons from a set of observations captured by sensors. Usually, this is performed by following a fixed length sliding window approach for the features extraction where two parameters have to be fixed: the size of the window and the shift. <U+2014> A Dynamic Sliding Window Approach for Activity Recognition, 2011 Each window is also associated with a specific activity. A given window of data may have multiple variables, such as the x, y, and z axes of an accelerometer sensor. Let¡¯s make this concrete with an example. We have sensor data for 10 minutes; that may look like: If the data is recorded at 8 Hz, that means that there will be eight rows of data for one second of elapsed time performing an activity. We may choose to have one window of data represent one second of data; that means eight rows of data for an 8 Hz sensor. If we have x, y, and z data, that means we would have 3 variables. Therefore, a single window of data would be a 2-dimensional array with eight time steps and three features. One window would represent one sample. One minute of data would represent 480 sensor data points, or 60 windows of eight time steps. The total 10 minutes of data would represent 4,800 data points, or 600 windows of data. It is convenient to describe the shape of our prepared sensor data in terms of the number of samples or windows, the number of time steps in a window, and the number of features observed at each time step. Our example of 10 minutes of accelerometer data recorded at 8 Hz would be summarized as a three-dimensional array with the dimensions: There is no best window size, and it really depends on the specific model being used, the nature of the sensor data that was collected, and the activities that are being classified. There is a tension in the size of the window and the size of the model. Larger windows require large models that are slower to train, whereas smaller windows require smaller models that are much easier to fit. Intuitively, decreasing the window size allows for a faster activity detection, as well as reduced resources and energy needs. On the contrary, large data windows are normally considered for the recognition of complex activities <U+2014> Window Size Impact in Human Activity Recognition, 2014. Nevertheless, it is common to use one to two seconds of sensor data in order to classify a current fragment of an activity. From the results, reduced windows (2 s or less) are demonstrated to provide the most accurate detection performance. In fact, the most precise recognizer is obtained for very short windows (0.25<U+2013>0.5 s), leading to the perfect recognition of most activities. Contrary to what is often thought, this study demonstrates that large window sizes do not necessarily translate into a better recognition performance. <U+2014> Window Size Impact in Human Activity Recognition, 2014. There is some risk that the splitting of the stream of sensor data into windows may result in windows that miss the transition of one activity to another. As such, it was traditionally common to split data into windows with an overlap such that the first half of the window contained the observations from the last half of the previous window, in the case of a 50% overlap. [¡¦] an incorrect length may truncate an activity instance. In many cases, errors appear at the beginning or at the end of the activities, when the window overlaps the end of one activity and the beginning of the next one. In other cases, the window length may be too short to provide the best information for the recognition process. <U+2014> A Dynamic Sliding Window Approach for Activity Recognition, 2011 It is unclear whether windows with overlap are required for a given problem. In the adoption of neural network models, the use of overlaps, such as a 50% overlap, will double the size of the training data, which may aid in modeling smaller datasets, but may also lead to models that overfit the training dataset. An overlap between adjacent windows is tolerated for certain applications; however, this is less frequently used. <U+2014> Window Size Impact in Human Activity Recognition, 2014. Convolutional Neural Network models, or CNNs for short, are a type of deep neural network that were developed for use with image data, e.g. such as handwriting recognition. They have proven very effective on challenging computer vision problems when trained at scale for tasks such as identifying and localizing objects in images and automatically describing the content of images. They are models that are comprised of two main types of elements: convolutional layers and pooling layers. Convolutional layers read an input, such as a 2D image or a 1D signal, using a kernel that reads in small segments at a time and steps across the entire input field. Each read results in an the input that is projected onto a filter map and represents an internal interpretation of the input. Pooling layers take the feature map projections and distill them to the most essential elements, such as using a signal averaging or signal maximizing process. The convolution and pooling layers can be repeated at depth, providing multiple layers of abstraction of the input signals. The output of these networks is often one or more fully connected layers that interpret what has been read and map this internal representation to a class value. For more information on convolutional neural networks, can see the post: CNNs can be applied to human activity recognition data. The CNN model learns to map a given window of signal data to an activity where the model reads across each window of data and prepares an internal representation of the window. When applied to time series classification like HAR, CNN has two advantages over other models: local dependency and scale invariance. Local dependency means the nearby signals in HAR are likely to be correlated, while scale invariance refers to the scale-invariant for different paces or frequencies. <U+2014> Deep Learning for Sensor-based Activity Recognition: A Survey, 2018. The first important work using CNNs to HAR was by Ming Zeng, et al in their 2014 paper ¡°Convolutional Neural Networks for Human Activity Recognition using Mobile Sensors.¡± In the paper, the authors develop a simple CNN model for accelerometer data, where each axis of the accelerometer data is fed into separate convolutional layers, pooling layers, then concatenated before being interpreted by hidden fully connected layers. The figure below taken from the paper clearly shows the topology of the model. It provides a good template for how the CNN may be used for HAR problems and time series classification in general. Depiction of CNN Model for Accelerometer DataTaken from ¡°Convolutional Neural Networks for Human Activity Recognition using Mobile Sensors¡± There are many ways to model HAR problems with CNNs. One interesting example was by Heeryon Cho and Sang Min Yoon in their 2018 paper titled ¡°Divide and Conquer-Based 1D CNN Human Activity Recognition Using Test Data Sharpening.¡± In it, they divide activities into those that involve movement, called ¡°dynamic,¡± and those where the subject is stationary, called ¡°static,¡± then develop a CNN model to discriminate between these two main classes. Then, within each class, models are developed to discriminate between activities of that type, such as ¡°walking¡± for dynamic and ¡°sitting¡± for static. Separation of Activities as Dynamic or StaticTaken from ¡°Divide and Conquer-Based 1D CNN Human Activity Recognition Using Test Data Sharpening¡± They refer to this as a two-stage modeling approach. Instead of straightforwardly recognizing the individual activities using a single 6-class classifier, we apply a divide and conquer approach and build a two-stage activity recognition process, where abstract activities, i.e., dynamic and static activity, are first recognized using a 2-class or binary classifier, and then individual activities are recognized using two 3-class classifiers. <U+2014> Divide and Conquer-Based 1D CNN Human Activity Recognition Using Test Data Sharpening, 2018. Quite large CNN models were developed, which in turn allowed the authors to claim state-of-the-art results on challenging standard human activity recognition datasets. Another interesting approach was proposed by Wenchao Jiang and Zhaozheng Yin in their 2015 paper titled ¡°Human Activity Recognition Using Wearable Sensors by Deep Convolutional Neural Networks.¡± Instead of using 1D CNNs on the signal data, they instead combine the signal data together to create ¡°images¡± which are then fed to a 2D CNN and processed as image data with convolutions along the time axis of signals and across signal variables, specifically accelerometer and gyroscope data. Firstly, raw signals are stacked row-by-row into a signal image [¡¦.]. In the signal image, every signal sequence has the chance to be adjacent to every other sequence, which enables DCNN to extract hidden correlations between neighboring signals. Then, 2D Discrete Fourier Transform (DFT) is applied to the signal image and its magnitude is chosen as our activity image <U+2014> Human Activity Recognition Using Wearable Sensors by Deep Convolutional Neural Networks, 2015. Below is a depiction of the processing of raw sensor data into images, and then from images into an ¡°activity image,¡± the result of a discrete Fourier transform. Processing of Raw Sensor Data into an ImageTaken from ¡°Human Activity Recognition Using Wearable Sensors by Deep Convolutional Neural Networks¡± Finally, another good paper on the topic is by Charissa Ann Ronao and Sung-Bae Cho in 2016 titled ¡°Human activity recognition with smartphone sensors using deep learning neural networks.¡± Careful study of the use of CNNs is performed showing that larger kernel sizes of signal data are useful and limited pooling. Experiments show that convnets indeed derive relevant and more complex features with every additional layer, although difference of feature complexity level decreases with every additional layer. A wider time span of temporal local correlation can be exploited (1¡¿9 <U+2013> 1¡¿14) and a low pooling size (1¡¿2 <U+2013> 1¡¿3) is shown to be beneficial. <U+2014> Human activity recognition with smartphone sensors using deep learning neural networks, 2016. Usefully, they also provide the full hyperparameter configuration for the CNN models that may provide a useful starting point on new HAR and other sequence classification problems, summarized below. Table of CNN Model Hyperparameter ConfigurationTaken from ¡°Human activity recognition with smartphone sensors using deep learning neural networks.¡± Recurrent neural networks, or RNNs for short, are a type of neural network that was designed to learn from sequence data, such as sequences of observations over time, or a sequence of words in a sentence. A specific type of RNN called the long short-term memory network, or LSTM for short, is perhaps the most widely used RNN as its careful design overcomes the general difficulties in training a stable RNN on sequence data. LSTMs have proven effective on challenging sequence prediction problems when trained at scale for such tasks as handwriting recognition, language modeling, and machine translation. A layer in an LSTM model is comprised of special units that have gates that govern input, output, and recurrent connections, the weights of which are learned. Each LSTM unit also has internal memory or state that is accumulated as an input sequence is read and can be used by the network as a type of local variable or memory register. For more information on long short-term memory networks, see the post: Like the CNN that can read across an input sequence, the LSTM reads a sequence of input observations and develops its own internal representation of the input sequence. Unlike the CNN, the LSTM is trained in a way that pays specific attention to observations made and prediction errors made over the time steps in the input sequence, called backpropagation through time. For more information on backpropagation through time, see the post: LSTMs can be applied to the problem of human activity recognition. The LSTM learns to map each window of sensor data to an activity, where the observations in the input sequence are read one at a time, where each time step may be comprised of one or more variables (e.g. parallel sequences). There has been limited application of simple LSTM models to HAR problems. One example is by Abdulmajid Murad and Jae-Young Pyun in their 2017 paper titled ¡°Deep Recurrent Neural Networks for Human Activity Recognition.¡± Important, in the paper they comment on the limitation of CNNs in their requirement to operate on fixed-sized windows of sensor data, a limitation that LSTMs do not strictly have. However, the size of convolutional kernels restricts the captured range of dependencies between data samples. As a result, typical models are unadaptable to a wide range of activity-recognition configurations and require fixed-length input windows. <U+2014> Deep Recurrent Neural Networks for Human Activity Recognition, 2017. They explore the use of LSTMs that both process the sequence data forward (normal) and both directions (Bidirectional LSTM). Interestingly, the LSTM predicts an activity for each input time step of a subsequence of sensor data, which are then aggregated in order to predict an activity for the window. There will [be] a score for each time-step predicting the type of activity occurring at time t. The prediction for the entire window T is obtained by merging the individual scores into a single prediction <U+2014> Deep Recurrent Neural Networks for Human Activity Recognition, 2017. The figure below taken from the paper provides a depiction of the LSTM model followed by fully connected layers used to interpret the internal representation of the raw sensor data. Depiction of LSTM RNN for Activity RecognitionTaken from ¡°Deep Recurrent Neural Networks for Human Activity Recognition.¡± It may be more common to use an LSTM in conjunction with a CNN on HAR problems, in a CNN-LSTM model or ConvLSTM model. This is where a CNN model is used to extract the features from a subsequence of raw sample data, and output features from the CNN for each subsequence are then interpreted by an LSTM in aggregate. An example of this is in the 2016 paper by Francisco Javier Ordonez and Daniel Roggen titled ¡°Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition.¡± We introduce a new DNN framework for wearable activity recognition, which we refer to as DeepConvLSTM. This architecture combines convolutional and recurrent layers. The convolutional layers act as feature extractors and provide abstract representations of the input sensor data in feature maps. The recurrent layers model the temporal dynamics of the activation of the feature maps. <U+2014> Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition, 2016. A deep network architecture is used with four convolutional layers without any pooling layers, followed by two LSTM layers to interpret the extracted features over multiple time steps. The authors claim that the removal of the pooling layers is a critical part of their model architecture, where the use of pooling layers after the convolutional layers interferes with the convolutional layers¡¯ ability to learn to downsample the raw sensor data. In the literature, CNN frameworks often include convolutional and pooling layers successively, as a measure to reduce data complexity and introduce translation invariant features. Nevertheless, such an approach is not strictly part of the architecture, and in the time series domain [¡¦] DeepConvLSTM does not include pooling operations because the input of the network is constrained by the sliding window mechanism [¡¦] and this fact limits the possibility of downsampling the data, given that DeepConvLSTM requires a data sequence to be processed by the recurrent layers. However, without the sliding window requirement, a pooling mechanism could be useful to cover different sensor data time scales at deeper layers. <U+2014> Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition, 2016. The figure below taken from the paper makes the architecture clearer. Note that layers 6 and 7 in the image are in fact LSTM layers. Depiction of CNN LSTM Model for Activity RecognitionTaken from ¡°Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition.¡± This section provides more resources on the topic if you are looking to go deeper. In this post, you discovered the problem of human activity recognition and the use of deep learning methods that are achieving state-of-the-art performance on this problem. Specifically, you learned: Do you have any questions?
Ask your questions in the comments below and I will do my best to answer. ¡¦with just a few lines of python code Discover how in my new Ebook:Deep Learning for Time Series Forecasting It provides self-study tutorials on topics like: CNNs, LSTMs,Multivariate Forecasting, Multi-Step Forecasting and much more¡¦ Skip the Academics. Just Results. Click to learn more. can you implement something as an example to recognize any human activity. I don¡¯t see why not. Comment  Name (required)  Email (will not be published) (required)  Website"
