"site","date","headline","url_address","text"
"mastery",2018-09-28,"How to Load and Explore Household Electricity Usage Data","https://machinelearningmastery.com/how-to-load-and-explore-household-electricity-usage-data/","Given the rise of smart electricity meters and the wide adoption of electricity generation technology like solar panels, there is a wealth of electricity usage data available. This data represents a multivariate time series of power-related variables, that in turn could be used to model and even forecast future electricity consumption. In this tutorial, you will discover a household power consumption dataset for multi-step time series forecasting and how to better understand the raw data using exploratory analysis. After completing this tutorial, you will know: Let¡¯s get started. How to Load and Explore Household Electricity Usage DataPhoto by Sheila Sund, some rights reserved. This tutorial is divided into five parts; they are: The Household Power Consumption dataset is a multivariate time series dataset that describes the electricity consumption for a single household over four years. The data was collected between December 2006 and November 2010 and observations of power consumption within the household were collected every minute. It is a multivariate series comprised of seven variables (besides the date and time); they are: Active and reactive energy refer to the technical details of alternative current. In general terms, the active energy is the real power consumed by the household, whereas the reactive energy is the unused power in the lines. We can see that the dataset provides the active power as well as some division of the active power by main circuit in the house, specifically the kitchen, laundry, and climate control. These are not all the circuits in the household. The remaining watt-hours can be calculated from the active energy by first converting the active energy to watt-hours then subtracting the other sub-metered active energy in watt-hours, as follows: The dataset seems to have been provided without a seminal reference paper. Nevertheless, this dataset has become a standard for evaluating time series forecasting and machine learning methods for multi-step forecasting, specifically for forecasting active power. Further, it is not clear whether the other features in the dataset may benefit a model in forecasting active power. Take my free 7-day email crash course now (with sample code). Click to sign-up and also get a free PDF Ebook version of the course. Download Your FREE Mini-Course The dataset can be downloaded from the UCI Machine Learning repository as a single 20 megabyte .zip file: Download the dataset and unzip it into your current working directory. You will now have the file ¡°household_power_consumption.txt¡± that is about 127 megabytes in size and contains all of the observations Inspect the data file. Below are the first five rows of data (and the header) from the raw data file. We can see that the data columns are separated by semicolons (¡®;¡®). The data is reported to have one row for each day in the time period. The data does have missing values; for example, we can see 2-3 days worth of missing data around 28/4/2007. We can start-off by loading the data file as a Pandas DataFrame and summarize the loaded data. We can use the read_csv() function to load the data. It is easy to load the data with this function, but a little tricky to load it correctly. Specifically, we need to do a few custom things: Putting all of this together, we can now load the data and summarize the loaded shape and first few rows. Next, we can mark all missing values indicated with a ¡®?¡¯ character with a NaN value, which is a float. This will allow us to work with the data as one array of floating point values rather than mixed types, which is less efficient. Now we can create a new column that contains the remainder of the sub-metering, using the calculation from the previous section. We can now save the cleaned-up version of the dataset to a new file; in this case we will just change the file extension to .csv and save the dataset as ¡®household_power_consumption.csv¡®. To confirm that we have not messed-up, we can re-load the dataset and summarize the first five rows. Tying all of this together, the complete example of loading, cleaning-up, and saving the dataset is listed below. Running the example first loads the raw data and summarizes the shape and first five rows of the loaded data. The dataset is then cleaned up and saved to a new file. We load this new file and again print the first five rows, showing the removal of the date and time columns and addition of the new sub-metered column. We can peek inside the new ¡®household_power_consumption.csv¡® file and check that the missing observations are marked with an empty column, that pandas will correctly read as NaN, for example around row 190,499: Now that we have a cleaned-up version of the dataset, we can investigate it further using visualizations. The data is a multivariate time series and the best way to understand a time series is to create line plots. We can start off by creating a separate line plot for each of the eight variables. The complete example is listed below. Running the example creates a single image with eight subplots, one for each variable. This gives us a really high level of the four years of one minute observations. We can see that something interesting was going on in ¡®Sub_metering_3¡® (environmental control) that may not directly map to hot or cold years. Perhaps new systems were installed. Interestingly, the contribution of ¡®sub_metering_4¡® seems to decrease with time, or show a downward trend, perhaps matching up with the solid increase in seen towards the end of the series for ¡®Sub_metering_3¡®. These observations do reinforce the need to honor the temporal ordering of subsequences of this data when fitting and evaluating any model. We might be able to see the wave of a seasonal effect in the ¡®Global_active_power¡® and some other variates. There is some spiky usage that may match up with a specific period, such as weekends. Line Plots of Each Variable in the Power Consumption Dataset Let¡¯s zoom in and focus on the ¡®Global_active_power¡®, or ¡®active power¡® for short. We can create a new plot of the active power for each year to see if there are any common patterns across the years. The first year, 2006, has less than one month of data, so will remove it from the plot. The complete example is listed below. Running the example creates one single image with four line plots, one for each full year (or mostly full years) of data in the dataset. We can see some common gross patterns across the years, such as around Feb-Mar and around Aug-Sept where we see a marked decrease in consumption. We also seem to see a downward trend over the summer months (middle of the year in the northern hemisphere) and perhaps more consumption in the winter months towards the edges of the plots. These may show an annual seasonal pattern in consumption. We can also see a few patches of missing data in at least the first, third, and fourth plots. Line Plots of Active Power for Most Years We can continue to zoom in on consumption and look at active power for each of the 12 months of 2007. This might help tease out gross structures across the months, such as daily and weekly patterns. The complete example is listed below. Running the example creates a single image with 12 line plots, one for each month in 2007. We can see the sign-wave of power consumption of the days within each month. This is good as we would expect some kind of daily pattern in power consumption. We can see that there are stretches of days with very minimal consumption, such as in August and in April. These may represent vacation periods where the home was unoccupied and where power consumption was minimal. Line Plots for Active Power for All Months in One Year Finally, we can zoom in one more level and take a closer look at power consumption at the daily level. We would expect there to be some pattern to consumption each day, and perhaps differences in days over a week. The complete example is listed below. Running the example creates a single image with 20 line plots, one for the first 20 days in January 2007. There is commonality across the days; for example, many days consumption starts early morning, around 6-7AM. Some days show a drop in consumption in the middle of the day, which might make sense if most occupants are out of the house. We do see some strong overnight consumption on some days, that in a northern hemisphere January may match up with a heating system being used. Time of year, specifically the season and the weather that it brings, will be an important factor in modeling this data, as would be expected. Line Plots for Active Power for 20 Days in One Month Another important area to consider is the distribution of the variables. For example, it may be interesting to know if the distributions of observations are Gaussian or some other distribution. We can investigate the distributions of the data by reviewing histograms. We can start-off by creating a histogram for each variable in the time series. The complete example is listed below. Running the example creates a single figure with a separate histogram for each of the 8 variables. We can see that active and reactive power, intensity, as well as the sub-metered power are all skewed distributions down towards small watt-hour or kilowatt values. We can also see that distribution of voltage data is strongly Gaussian. Histogram plots for Each Variable in the Power Consumption Dataset The distribution of active power appears to be bi-modal, meaning it looks like it has two mean groups of observations. We can investigate this further by looking at the distribution of active power consumption for the four full years of data. The complete example is listed below. Running the example creates a single plot with four figures, one for each of the years between 2007 to 2010. We can see that the distribution of active power consumption across those years looks very similar. The distribution is indeed bimodal with one peak around 0.3 KW and perhaps another around 1.3 KW. There is a long tail on the distribution to higher kilowatt values. It might open the door to notions of discretizing the data and separating it into peak 1, peak 2 or long tail. These groups or clusters for usage on a day or hour may be helpful in developing a predictive model. Histogram Plots of Active Power for Most Years It is possible that the identified groups may vary over the seasons of the year. We can investigate this by looking at the distribution for active power for each month in a year. The complete example is listed below. Running the example creates an image with 12 plots, one for each month in 2007. We can see generally the same data distribution each month. The axes for the plots appear to align (given the similar scales), and we can see that the peaks are shifted down in the warmer northern hemisphere months and shifted up for the colder months. We can also see a thicker or more prominent tail toward larger kilowatt values for the cooler months of December through to March. Histogram Plots for Active Power for All Months in One Year Now that we know how to load and explore the dataset, we can pose some ideas on how to model the dataset. In this section, we will take a closer look at three main areas when working with the data; they are: There does not appear to be a seminal publication for the dataset to demonstrate the intended way to frame the data in a predictive modeling problem. We are therefore left to guess at possibly useful ways that this data may be used. The data is only for a single household, but perhaps effective modeling approaches could be generalized across to similar households. Perhaps the most useful framing of the dataset is to forecast an interval of future active power consumption. Four examples include: Generally, these types of forecasting problems are referred to as multi-step forecasting. Models that make use of all of the variables might be referred to as a multivariate multi-step forecasting models. Each of these models is not limited to forecasting the minutely data, but instead could model the problem at or below the chosen forecast resolution. Forecasting consumption in turn, at scale, could aid in a utility company forecasting demand, which is a widely studied and important problem. There is a lot of flexibility in preparing this data for modeling. The specific data preparation methods and their benefit really depend on the chosen framing of the problem and the modeling methods. Nevertheless, below is a list of general data preparation methods that may be useful: There are many simple human factors that may be helpful in engineering features from the data, that in turn may make specific days easier to forecast. Some examples include: These factors may be significantly less important for forecasting monthly data, and perhaps to a degree for weekly data. More general features may include: There are perhaps four classes of methods that might be interesting to explore on this problem; they are: Naive methods would include methods that make very simple, but often very effective assumptions. Some examples include: Classical linear methods include techniques are very effective for univariate time series forecasting. Two important examples include: They would require that the additional variables be discarded and the parameters of the model be configured or tuned to the specific framing of the dataset. Concerns related to adjusting the data for daily and seasonal structures can also be supported directly. Machine learning methods require that the problem be framed as a supervised learning problem. This would require that lag observations for a series be framed as input features, discarding the temporal relationship in the data. A suite of nonlinear and ensemble methods could be explored, including: Careful attention is required to ensure that the fitting and evaluation of these models preserved the temporal structure in the data. This is important so that the method is not able to ¡®cheat¡¯ by harnessing observations from the future. These methods are often agnostic to large numbers of variables and may aid in teasing out whether the additional variables can be harnessed and add value to predictive models. Generally, neural networks have not proven very effective at autoregression type problems. Nevertheless, techniques such as convolutional neural networks are able to automatically learn complex features from raw data, including one-dimensional signal data. And recurrent neural networks, such as the long short-term memory network, are capable of directly learning across multiple parallel sequences of input data. Further, combinations of these methods, such as CNN LSTM and ConvLSTM, have proven effective on time series classification tasks. It is possible that these methods may be able to harness the large volume of minute-based data and multiple input variables. This section provides more resources on the topic if you are looking to go deeper. In this tutorial, you discovered a household power consumption dataset for multi-step time series forecasting and how to better understand the raw data using exploratory analysis. Specifically, you learned: Do you have any questions?
Ask your questions in the comments below and I will do my best to answer. ¡¦with just a few lines of python code Discover how in my new Ebook:Deep Learning for Time Series Forecasting It provides self-study tutorials on topics like: CNNs, LSTMs,Multivariate Forecasting, Multi-Step Forecasting and much more¡¦ Skip the Academics. Just Results. Click to learn more. Great work Jason! Thanks. Thank you for the post. It is really helpful.
I was wondering how to frame the input data for Forecasting hourly consumption for the next day using SVM, ANN  and Randomforest. Is there any reference for multi-step multi-variate time series prediction?
Also, would Forecast hourly consumption for the next day be more accurate than Forecast hourly consumption for the next week? Yes, I have many examples. Here¡¯s a starting point:https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/ I also have many more examples in my book:https://machinelearningmastery.com/deep-learning-for-time-series-forecasting/ If there was ¡°IoT¡± in the title, people (including me) would faster recognize the immense value in your post/book. Comment  Name (required)  Email (will not be published) (required)  Website"
"mastery",2018-09-26,"Deep Learning Models for Human Activity Recognition","https://machinelearningmastery.com/deep-learning-models-for-human-activity-recognition/","Human activity recognition, or HAR, is a challenging time series classification task. It involves predicting the movement of a person based on sensor data and traditionally involves deep domain expertise and methods from signal processing to correctly engineer features from the raw data in order to fit a machine learning model. Recently, deep learning methods such as convolutional neural networks and recurrent neural networks have shown capable and even achieve state-of-the-art results by automatically learning features from the raw sensor data. In this post, you will discover the problem of human activity recognition and the deep learning methods that are achieving state-of-the-art performance on this problem. After reading this post, you will know: Let¡¯s get started. Deep Learning Models for Human Activity RecognitionPhoto by Simon Harrod, some rights reserved. This post is divided into five parts; they are: Human activity recognition, or HAR for short, is a broad field of study concerned with identifying the specific movement or action of a person based on sensor data. Movements are often typical activities performed indoors, such as walking, talking, standing, and sitting. They may also be more focused activities such as those types of activities performed in a kitchen or on a factory floor. The sensor data may be remotely recorded, such as video, radar, or other wireless methods. Alternately, data may be recorded directly on the subject such as by carrying custom hardware or smart phones that have accelerometers and gyroscopes. Sensor-based activity recognition seeks the profound high-level knowledge about human activities from multitudes of low-level sensor readings <U+2014> Deep Learning for Sensor-based Activity Recognition: A Survey, 2018. Historically, sensor data for activity recognition was challenging and expensive to collect, requiring custom hardware. Now smart phones and other personal tracking devices used for fitness and health monitoring are cheap and ubiquitous. As such, sensor data from these devices is cheaper to collect, more common, and therefore is a more commonly studied version of the general activity recognition problem. The problem is to predict the activity given a snapshot of sensor data, typically data from one or a small number of sensor types. Generally, this problem is framed as a univariate or multivariate time series classification task. It is a challenging problem as there are no obvious or direct ways to relate the recorded sensor data to specific human activities and each subject may perform an activity with significant variation, resulting in variations in the recorded sensor data. The intent is to record sensor data and corresponding activities for specific subjects, fit a model from this data, and generalize the model to classify the activity of new unseen subjects from their sensor data. Take my free 7-day email crash course now (with sample code). Click to sign-up and also get a free PDF Ebook version of the course. Download Your FREE Mini-Course Traditionally, methods from the field of signal processing were used to analyze and distill the collected sensor data. Such methods were for feature engineering, creating domain-specific, sensor-specific, or signal processing-specific features and views of the original data. Statistical and machine learning models were then trained on the processed version of the data. A limitation of this approach is the signal processing and domain expertise required to analyze the raw data and engineer the features required to fit a model. This expertise would be required for each new dataset or sensor modality. In essence, it is expensive and not scalable. However, in most daily HAR tasks, those methods may heavily rely on heuristic handcrafted feature extraction, which is usually limited by human domain knowledge. Furthermore, only shallow features can be learned by those approaches, leading to undermined performance for unsupervised and incremental tasks. Due to those limitations, the performances of conventional [pattern recognition] methods are restricted regarding classification accuracy and model generalization. <U+2014> Deep Learning for Sensor-based Activity Recognition: A Survey, 2018. Ideally, learning methods could be used that automatically learn the features required to make accurate predictions from the raw data directly. This would allow new problems, new datasets, and new sensor modalities to be adopted quickly and cheaply. Recently, deep neural network models have started delivering on their promises of feature learning and are achieving stat-of-the-art results for human activity recognition. They are capable of performing automatic feature learning from the raw sensor data and out-perform models fit on hand-crafted domain-specific features. [¡¦] , the feature extraction and model building procedures are often performed simultaneously in the deep learning models. The features can be learned automatically through the network instead of being manually designed. Besides, the deep neural network can also extract high-level representation in deep layer, which makes it more suitable for complex activity recognition tasks. <U+2014> Deep Learning for Sensor-based Activity Recognition: A Survey, 2018. There are two main approaches to neural networks that are appropriate for time series classification and that have been demonstrated to perform well on activity recognition using sensor data from commodity smart phones and fitness tracking devices. They are Convolutional Neural Network Models and Recurrent Neural Network Models. RNN and LSTM are recommended to recognize short activities that have natural order while CNN is better at inferring long term repetitive activities. The reason is that RNN could make use of the time-order relationship between sensor readings, and CNN is more capable of learning deep features contained in recursive patterns. <U+2014> Deep Learning for Sensor-based Activity Recognition: A Survey, 2018. Before we dive into the specific neural networks that can be used for human activity recognition, we need to talk about data preparation. Both types of neural networks suitable for time series classification require that data be prepared in a specific manner in order to fit a model. That is, in a ¡®supervised learning¡® way that allows the model to associate signal data with an activity class. A straight-forward data preparation approach that was used both for classical machine learning methods on the hand-crafted features and for neural networks involves dividing the input signal data into windows of signals, where a given window may have one to a few seconds of observation data. This is often called a ¡®sliding window.¡¯ Human activity recognition aims to infer the actions of one or more persons from a set of observations captured by sensors. Usually, this is performed by following a fixed length sliding window approach for the features extraction where two parameters have to be fixed: the size of the window and the shift. <U+2014> A Dynamic Sliding Window Approach for Activity Recognition, 2011 Each window is also associated with a specific activity. A given window of data may have multiple variables, such as the x, y, and z axes of an accelerometer sensor. Let¡¯s make this concrete with an example. We have sensor data for 10 minutes; that may look like: If the data is recorded at 8 Hz, that means that there will be eight rows of data for one second of elapsed time performing an activity. We may choose to have one window of data represent one second of data; that means eight rows of data for an 8 Hz sensor. If we have x, y, and z data, that means we would have 3 variables. Therefore, a single window of data would be a 2-dimensional array with eight time steps and three features. One window would represent one sample. One minute of data would represent 480 sensor data points, or 60 windows of eight time steps. The total 10 minutes of data would represent 4,800 data points, or 600 windows of data. It is convenient to describe the shape of our prepared sensor data in terms of the number of samples or windows, the number of time steps in a window, and the number of features observed at each time step. Our example of 10 minutes of accelerometer data recorded at 8 Hz would be summarized as a three-dimensional array with the dimensions: There is no best window size, and it really depends on the specific model being used, the nature of the sensor data that was collected, and the activities that are being classified. There is a tension in the size of the window and the size of the model. Larger windows require large models that are slower to train, whereas smaller windows require smaller models that are much easier to fit. Intuitively, decreasing the window size allows for a faster activity detection, as well as reduced resources and energy needs. On the contrary, large data windows are normally considered for the recognition of complex activities <U+2014> Window Size Impact in Human Activity Recognition, 2014. Nevertheless, it is common to use one to two seconds of sensor data in order to classify a current fragment of an activity. From the results, reduced windows (2 s or less) are demonstrated to provide the most accurate detection performance. In fact, the most precise recognizer is obtained for very short windows (0.25<U+2013>0.5 s), leading to the perfect recognition of most activities. Contrary to what is often thought, this study demonstrates that large window sizes do not necessarily translate into a better recognition performance. <U+2014> Window Size Impact in Human Activity Recognition, 2014. There is some risk that the splitting of the stream of sensor data into windows may result in windows that miss the transition of one activity to another. As such, it was traditionally common to split data into windows with an overlap such that the first half of the window contained the observations from the last half of the previous window, in the case of a 50% overlap. [¡¦] an incorrect length may truncate an activity instance. In many cases, errors appear at the beginning or at the end of the activities, when the window overlaps the end of one activity and the beginning of the next one. In other cases, the window length may be too short to provide the best information for the recognition process. <U+2014> A Dynamic Sliding Window Approach for Activity Recognition, 2011 It is unclear whether windows with overlap are required for a given problem. In the adoption of neural network models, the use of overlaps, such as a 50% overlap, will double the size of the training data, which may aid in modeling smaller datasets, but may also lead to models that overfit the training dataset. An overlap between adjacent windows is tolerated for certain applications; however, this is less frequently used. <U+2014> Window Size Impact in Human Activity Recognition, 2014. Convolutional Neural Network models, or CNNs for short, are a type of deep neural network that were developed for use with image data, e.g. such as handwriting recognition. They have proven very effective on challenging computer vision problems when trained at scale for tasks such as identifying and localizing objects in images and automatically describing the content of images. They are models that are comprised of two main types of elements: convolutional layers and pooling layers. Convolutional layers read an input, such as a 2D image or a 1D signal, using a kernel that reads in small segments at a time and steps across the entire input field. Each read results in an the input that is projected onto a filter map and represents an internal interpretation of the input. Pooling layers take the feature map projections and distill them to the most essential elements, such as using a signal averaging or signal maximizing process. The convolution and pooling layers can be repeated at depth, providing multiple layers of abstraction of the input signals. The output of these networks is often one or more fully connected layers that interpret what has been read and map this internal representation to a class value. For more information on convolutional neural networks, can see the post: CNNs can be applied to human activity recognition data. The CNN model learns to map a given window of signal data to an activity where the model reads across each window of data and prepares an internal representation of the window. When applied to time series classification like HAR, CNN has two advantages over other models: local dependency and scale invariance. Local dependency means the nearby signals in HAR are likely to be correlated, while scale invariance refers to the scale-invariant for different paces or frequencies. <U+2014> Deep Learning for Sensor-based Activity Recognition: A Survey, 2018. The first important work using CNNs to HAR was by Ming Zeng, et al in their 2014 paper ¡°Convolutional Neural Networks for Human Activity Recognition using Mobile Sensors.¡± In the paper, the authors develop a simple CNN model for accelerometer data, where each axis of the accelerometer data is fed into separate convolutional layers, pooling layers, then concatenated before being interpreted by hidden fully connected layers. The figure below taken from the paper clearly shows the topology of the model. It provides a good template for how the CNN may be used for HAR problems and time series classification in general. Depiction of CNN Model for Accelerometer DataTaken from ¡°Convolutional Neural Networks for Human Activity Recognition using Mobile Sensors¡± There are many ways to model HAR problems with CNNs. One interesting example was by Heeryon Cho and Sang Min Yoon in their 2018 paper titled ¡°Divide and Conquer-Based 1D CNN Human Activity Recognition Using Test Data Sharpening.¡± In it, they divide activities into those that involve movement, called ¡°dynamic,¡± and those where the subject is stationary, called ¡°static,¡± then develop a CNN model to discriminate between these two main classes. Then, within each class, models are developed to discriminate between activities of that type, such as ¡°walking¡± for dynamic and ¡°sitting¡± for static. Separation of Activities as Dynamic or StaticTaken from ¡°Divide and Conquer-Based 1D CNN Human Activity Recognition Using Test Data Sharpening¡± They refer to this as a two-stage modeling approach. Instead of straightforwardly recognizing the individual activities using a single 6-class classifier, we apply a divide and conquer approach and build a two-stage activity recognition process, where abstract activities, i.e., dynamic and static activity, are first recognized using a 2-class or binary classifier, and then individual activities are recognized using two 3-class classifiers. <U+2014> Divide and Conquer-Based 1D CNN Human Activity Recognition Using Test Data Sharpening, 2018. Quite large CNN models were developed, which in turn allowed the authors to claim state-of-the-art results on challenging standard human activity recognition datasets. Another interesting approach was proposed by Wenchao Jiang and Zhaozheng Yin in their 2015 paper titled ¡°Human Activity Recognition Using Wearable Sensors by Deep Convolutional Neural Networks.¡± Instead of using 1D CNNs on the signal data, they instead combine the signal data together to create ¡°images¡± which are then fed to a 2D CNN and processed as image data with convolutions along the time axis of signals and across signal variables, specifically accelerometer and gyroscope data. Firstly, raw signals are stacked row-by-row into a signal image [¡¦.]. In the signal image, every signal sequence has the chance to be adjacent to every other sequence, which enables DCNN to extract hidden correlations between neighboring signals. Then, 2D Discrete Fourier Transform (DFT) is applied to the signal image and its magnitude is chosen as our activity image <U+2014> Human Activity Recognition Using Wearable Sensors by Deep Convolutional Neural Networks, 2015. Below is a depiction of the processing of raw sensor data into images, and then from images into an ¡°activity image,¡± the result of a discrete Fourier transform. Processing of Raw Sensor Data into an ImageTaken from ¡°Human Activity Recognition Using Wearable Sensors by Deep Convolutional Neural Networks¡± Finally, another good paper on the topic is by Charissa Ann Ronao and Sung-Bae Cho in 2016 titled ¡°Human activity recognition with smartphone sensors using deep learning neural networks.¡± Careful study of the use of CNNs is performed showing that larger kernel sizes of signal data are useful and limited pooling. Experiments show that convnets indeed derive relevant and more complex features with every additional layer, although difference of feature complexity level decreases with every additional layer. A wider time span of temporal local correlation can be exploited (1¡¿9 <U+2013> 1¡¿14) and a low pooling size (1¡¿2 <U+2013> 1¡¿3) is shown to be beneficial. <U+2014> Human activity recognition with smartphone sensors using deep learning neural networks, 2016. Usefully, they also provide the full hyperparameter configuration for the CNN models that may provide a useful starting point on new HAR and other sequence classification problems, summarized below. Table of CNN Model Hyperparameter ConfigurationTaken from ¡°Human activity recognition with smartphone sensors using deep learning neural networks.¡± Recurrent neural networks, or RNNs for short, are a type of neural network that was designed to learn from sequence data, such as sequences of observations over time, or a sequence of words in a sentence. A specific type of RNN called the long short-term memory network, or LSTM for short, is perhaps the most widely used RNN as its careful design overcomes the general difficulties in training a stable RNN on sequence data. LSTMs have proven effective on challenging sequence prediction problems when trained at scale for such tasks as handwriting recognition, language modeling, and machine translation. A layer in an LSTM model is comprised of special units that have gates that govern input, output, and recurrent connections, the weights of which are learned. Each LSTM unit also has internal memory or state that is accumulated as an input sequence is read and can be used by the network as a type of local variable or memory register. For more information on long short-term memory networks, see the post: Like the CNN that can read across an input sequence, the LSTM reads a sequence of input observations and develops its own internal representation of the input sequence. Unlike the CNN, the LSTM is trained in a way that pays specific attention to observations made and prediction errors made over the time steps in the input sequence, called backpropagation through time. For more information on backpropagation through time, see the post: LSTMs can be applied to the problem of human activity recognition. The LSTM learns to map each window of sensor data to an activity, where the observations in the input sequence are read one at a time, where each time step may be comprised of one or more variables (e.g. parallel sequences). There has been limited application of simple LSTM models to HAR problems. One example is by Abdulmajid Murad and Jae-Young Pyun in their 2017 paper titled ¡°Deep Recurrent Neural Networks for Human Activity Recognition.¡± Important, in the paper they comment on the limitation of CNNs in their requirement to operate on fixed-sized windows of sensor data, a limitation that LSTMs do not strictly have. However, the size of convolutional kernels restricts the captured range of dependencies between data samples. As a result, typical models are unadaptable to a wide range of activity-recognition configurations and require fixed-length input windows. <U+2014> Deep Recurrent Neural Networks for Human Activity Recognition, 2017. They explore the use of LSTMs that both process the sequence data forward (normal) and both directions (Bidirectional LSTM). Interestingly, the LSTM predicts an activity for each input time step of a subsequence of sensor data, which are then aggregated in order to predict an activity for the window. There will [be] a score for each time-step predicting the type of activity occurring at time t. The prediction for the entire window T is obtained by merging the individual scores into a single prediction <U+2014> Deep Recurrent Neural Networks for Human Activity Recognition, 2017. The figure below taken from the paper provides a depiction of the LSTM model followed by fully connected layers used to interpret the internal representation of the raw sensor data. Depiction of LSTM RNN for Activity RecognitionTaken from ¡°Deep Recurrent Neural Networks for Human Activity Recognition.¡± It may be more common to use an LSTM in conjunction with a CNN on HAR problems, in a CNN-LSTM model or ConvLSTM model. This is where a CNN model is used to extract the features from a subsequence of raw sample data, and output features from the CNN for each subsequence are then interpreted by an LSTM in aggregate. An example of this is in the 2016 paper by Francisco Javier Ordonez and Daniel Roggen titled ¡°Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition.¡± We introduce a new DNN framework for wearable activity recognition, which we refer to as DeepConvLSTM. This architecture combines convolutional and recurrent layers. The convolutional layers act as feature extractors and provide abstract representations of the input sensor data in feature maps. The recurrent layers model the temporal dynamics of the activation of the feature maps. <U+2014> Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition, 2016. A deep network architecture is used with four convolutional layers without any pooling layers, followed by two LSTM layers to interpret the extracted features over multiple time steps. The authors claim that the removal of the pooling layers is a critical part of their model architecture, where the use of pooling layers after the convolutional layers interferes with the convolutional layers¡¯ ability to learn to downsample the raw sensor data. In the literature, CNN frameworks often include convolutional and pooling layers successively, as a measure to reduce data complexity and introduce translation invariant features. Nevertheless, such an approach is not strictly part of the architecture, and in the time series domain [¡¦] DeepConvLSTM does not include pooling operations because the input of the network is constrained by the sliding window mechanism [¡¦] and this fact limits the possibility of downsampling the data, given that DeepConvLSTM requires a data sequence to be processed by the recurrent layers. However, without the sliding window requirement, a pooling mechanism could be useful to cover different sensor data time scales at deeper layers. <U+2014> Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition, 2016. The figure below taken from the paper makes the architecture clearer. Note that layers 6 and 7 in the image are in fact LSTM layers. Depiction of CNN LSTM Model for Activity RecognitionTaken from ¡°Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition.¡± This section provides more resources on the topic if you are looking to go deeper. In this post, you discovered the problem of human activity recognition and the use of deep learning methods that are achieving state-of-the-art performance on this problem. Specifically, you learned: Do you have any questions?
Ask your questions in the comments below and I will do my best to answer. ¡¦with just a few lines of python code Discover how in my new Ebook:Deep Learning for Time Series Forecasting It provides self-study tutorials on topics like: CNNs, LSTMs,Multivariate Forecasting, Multi-Step Forecasting and much more¡¦ Skip the Academics. Just Results. Click to learn more. Comment  Name (required)  Email (will not be published) (required)  Website"
"mastery",2018-09-24,"How to Develop RNN Models for Human Activity Recognition Time Series Classification","https://machinelearningmastery.com/how-to-develop-rnn-models-for-human-activity-recognition-time-series-classification/","Human activity recognition is the problem of classifying sequences of accelerometer data recorded by specialized harnesses or smart phones into known well-defined movements. Classical approaches to the problem involve hand crafting features from the time series data based on fixed-sized windows and training machine learning models, such as ensembles of decision trees. The difficulty is that this feature engineering requires strong expertise in the field. Recently, deep learning methods such as recurrent neural networks like as LSTMs and variations that make use of one-dimensional convolutional neural networks or CNNs have been shown to provide state-of-the-art results on challenging activity recognition tasks with little or no data feature engineering, instead using feature learning on raw data. In this tutorial, you will discover three recurrent neural network architectures for modeling an activity recognition time series classification problem. After completing this tutorial, you will know: Let¡¯s get started. How to Develop RNN Models for Human Activity Recognition Time Series ClassificationPhoto by Bonnie Moreland, some rights reserved. This tutorial is divided into four parts; they are: Human Activity Recognition, or HAR for short, is the problem of predicting what a person is doing based on a trace of their movement using sensors. A standard human activity recognition dataset is the ¡®Activity Recognition Using Smart Phones Dataset¡¯ made available in 2012. It was prepared and made available by Davide Anguita, et al. from the University of Genova, Italy and is described in full in their 2013 paper ¡°A Public Domain Dataset for Human Activity Recognition Using Smartphones.¡± The dataset was modeled with machine learning algorithms in their 2012 paper titled ¡°Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine.¡± The dataset was made available and can be downloaded for free from the UCI Machine Learning Repository: The data was collected from 30 subjects aged between 19 and 48 years old performing one of six standard activities while wearing a waist-mounted smartphone that recorded the movement data. Video was recorded of each subject performing the activities and the movement data was labeled manually from these videos. Below is an example video of a subject performing the activities while their movement data is being recorded. The six activities performed were as follows: The movement data recorded was the x, y, and z accelerometer data (linear acceleration) and gyroscopic data (angular velocity) from the smart phone, specifically a Samsung Galaxy S II. Observations were recorded at 50 Hz (i.e. 50 data points per second). Each subject performed the sequence of activities twice; once with the device on their left-hand-side and once with the device on their right-hand side. The raw data is not available. Instead, a pre-processed version of the dataset was made available. The pre-processing steps included: Feature engineering was applied to the window data, and a copy of the data with these engineered features was made available. A number of time and frequency features commonly used in the field of human activity recognition were extracted from each window. The result was a 561 element vector of features. The dataset was split into train (70%) and test (30%) sets based on data for subjects, e.g. 21 subjects for train and nine for test. Experiment results with a support vector machine intended for use on a smartphone (e.g. fixed-point arithmetic) resulted in a predictive accuracy of 89% on the test dataset, achieving similar results as an unmodified SVM implementation. The dataset is freely available and can be downloaded from the UCI Machine Learning repository. The data is provided as a single zip file that is about 58 megabytes in size. The direct link for this download is below: Download the dataset and unzip all files into a new directory in your current working directory named ¡°HARDataset¡±. Take my free 7-day email crash course now (with sample code). Click to sign-up and also get a free PDF Ebook version of the course. Download Your FREE Mini-Course In this section, we will develop a Long Short-Term Memory network model (LSTM) for the human activity recognition dataset. LSTM network models are a type of recurrent neural network that are able to learn and remember over long sequences of input data. They are intended for use with data that is comprised of long sequences of data, up to 200 to 400 time steps. They may be a good fit for this problem. The model can support multiple parallel sequences of input data, such as each axis of the accelerometer and gyroscope data. The model learns to extract features from sequences of observations and how to map the internal features to different activity types. The benefit of using LSTMs for sequence classification is that they can learn from the raw time series data directly, and in turn do not require domain expertise to manually engineer input features. The model can learn an internal representation of the time series data and ideally achieve comparable performance to models fit on a version of the dataset with engineered features. This section is divided into four parts; they are: The first step is to load the raw dataset into memory. There are three main signal types in the raw data: total acceleration, body acceleration, and body gyroscope. Each has 3 axises of data. This means that there are a total of nine variables for each time step. Further, each series of data has been partitioned into overlapping windows of 2.65 seconds of data, or 128 time steps. These windows of data correspond to the windows of engineered features (rows) in the previous section. This means that one row of data has (128 * 9), or 1,152 elements. This is a little less than double the size of the 561 element vectors in the previous section and it is likely that there is some redundant data. The signals are stored in the /Inertial Signals/ directory under the train and test subdirectories. Each axis of each signal is stored in a separate file, meaning that each of the train and test datasets have nine input files to load and one output file to load. We can batch the loading of these files into groups given the consistent directory structures and file naming conventions. The input data is in CSV format where columns are separated by whitespace. Each of these files can be loaded as a NumPy array. The load_file() function below loads a dataset given the fill path to the file and returns the loaded data as a NumPy array. We can then load all data for a given group (train or test) into a single three-dimensional NumPy array, where the dimensions of the array are [samples, time steps, features]. To make this clearer, there are 128 time steps and nine features, where the number of samples is the number of rows in any given raw signal data file. The load_group() function below implements this behavior. The dstack() NumPy function allows us to stack each of the loaded 3D arrays into a single 3D array where the variables are separated on the third dimension (features). We can use this function to load all input signal data for a given group, such as train or test. The load_dataset_group() function below loads all input signal data and the output data for a single group using the consistent naming conventions between the directories. Finally, we can load each of the train and test datasets. The output data is defined as an integer for the class number. We must one hot encode these class integers so that the data is suitable for fitting a neural network multi-class classification model. We can do this by calling the to_categorical() Keras function. The load_dataset() function below implements this behavior and returns the train and test X and y elements ready for fitting and evaluating the defined models. Now that we have the data loaded into memory ready for modeling, we can define, fit, and evaluate an LSTM model. We can define a function named evaluate_model() that takes the train and test dataset, fits a model on the training dataset, evaluates it on the test dataset, and returns an estimate of the model¡¯s performance. First, we must define the LSTM model using the Keras deep learning library. The model requires a three-dimensional input with [samples, time steps, features]. This is exactly how we have loaded the data, where one sample is one window of the time series data, each window has 128 time steps, and a time step has nine variables or features. The output for the model will be a six-element vector containing the probability of a given window belonging to each of the six activity types. Thees input and output dimensions are required when fitting the model, and we can extract them from the provided training dataset. The model is defined as a Sequential Keras model, for simplicity. We will define the model as having a single LSTM hidden layer. This is followed by a dropout layer intended to reduce overfitting of the model to the training data. Finally, a dense fully connected layer is used to interpret the features extracted by the LSTM hidden layer, before a final output layer is used to make predictions. The efficient Adam version of stochastic gradient descent will be used to optimize the network, and the categorical cross entropy loss function will be used given that we are learning a multi-class classification problem. The definition of the model is listed below. The model is fit for a fixed number of epochs, in this case 15, and a batch size of 64 samples will be used, where 64 windows of data will be exposed to the model before the weights of the model are updated. Once the model is fit, it is evaluated on the test dataset and the accuracy of the fit model on the test dataset is returned. Note, it is common to not shuffle sequence data when fitting an LSTM. Here we do shuffle the windows of input data during training (the default). In this problem, we are interested in harnessing the LSTMs ability to learn and extract features across the time steps in a window, not across windows. The complete evaluate_model() function is listed below. There is nothing special about the network structure or chosen hyperparameters, they are just a starting point for this problem. We cannot judge the skill of the model from a single evaluation. The reason for this is that neural networks are stochastic, meaning that a different specific model will result when training the same model configuration on the same data. This is a feature of the network in that it gives the model its adaptive ability, but requires a slightly more complicated evaluation of the model. We will repeat the evaluation of the model multiple times, then summarize the performance of the model across each of those runs. For example, we can call evaluate_model() a total of 10 times. This will result in a population of model evaluation scores that must be summarized. We can summarize the sample of scores by calculating and reporting the mean and standard deviation of the performance. The mean gives the average accuracy of the model on the dataset, whereas the standard deviation gives the average variance of the accuracy from the mean. The function summarize_results() below summarizes the results of a run. We can bundle up the repeated evaluation, gathering of results, and summarization of results into a main function for the experiment, called run_experiment(), listed below. By default, the model is evaluated 10 times before the performance of the model is reported. Now that we have all of the pieces, we can tie them together into a worked example. The complete code listing is provided below. Running the example first prints the shape of the loaded dataset, then the shape of the train and test sets and the input and output elements. This confirms the number of samples, time steps, and variables, as well as the number of classes. Next, models are created and evaluated and a debug message is printed for each. Finally, the sample of scores is printed, followed by the mean and standard deviation. We can see that the model performed well, achieving a classification accuracy of about 89.7% trained on the raw dataset, with a standard deviation of about 1.3. This is a good result, considering that the original paper published a result of 89%, trained on the dataset with heavy domain-specific feature engineering, not the raw dataset. Note: given the stochastic nature of the algorithm, your specific results may vary. If so, try running the code a few times. Now that we have seen how to develop an LSTM model for time series classification, let¡¯s look at how we can develop a more sophisticated CNN LSTM model. The CNN LSTM architecture involves using Convolutional Neural Network (CNN) layers for feature extraction on input data combined with LSTMs to support sequence prediction. CNN LSTMs were developed for visual time series prediction problems and the application of generating textual descriptions from sequences of images (e.g. videos). Specifically, the problems of: You can learn more about the CNN LSTM architecture in the post: To learn more about the consequences of combining these models, see the paper: The CNN LSTM model will read subsequences of the main sequence in as blocks, extract features from each block, then allow the LSTM to interpret the features extracted from each block. One approach to implementing this model is to split each window of 128 time steps into subsequences for the CNN model to process. For example, the 128 time steps in each window can be split into four subsequences of 32 time steps. We can then define a CNN model that expects to read in sequences with a length of 32 time steps and nine features. The entire CNN model can be wrapped in a TimeDistributed layer to allow the same CNN model to read in each of the four subsequences in the window. The extracted features are then flattened and provided to the LSTM model to read, extracting its own features before a final mapping to an activity is made. It is common to use two consecutive CNN layers followed by dropout and a max pooling layer, and that is the simple structure used in the CNN LSTM model here. The updated evaluate_model() is listed below. We can evaluate this model as we did the straight LSTM model in the previous section. The complete code listing is provided below. Running the example summarizes the model performance for each of the 10 runs before a final summary of the models performance on the test set is reported. We can see that the model achieved a performance of about 90.6% with a standard deviation of about 1%. Note: given the stochastic nature of the algorithm, your specific results may vary. If so, try running the code a few times. A further extension of the CNN LSTM idea is to perform the convolutions of the CNN (e.g. how the CNN reads the input sequence data) as part of the LSTM. This combination is called a Convolutional LSTM, or ConvLSTM for short, and like the CNN LSTM is also used for spatio-temporal data. Unlike an LSTM that reads the data in directly in order to calculate internal state and state transitions, and unlike the CNN LSTM that is interpreting the output from CNN models, the ConvLSTM is using convolutions directly as part of reading input into the LSTM units themselves. For more information for how the equations for the ConvLSTM are calculated within the LSTM unit, see the paper: The Keras library provides the ConvLSTM2D class that supports the ConvLSTM model for 2D data. It can be configured for 1D multivariate time series classification. The ConvLSTM2D class, by default, expects input data to have the shape: Where each time step of data is defined as an image of (rows * columns) data points. In the previous section, we divided a given window of data (128 time steps) into four subsequences of 32 time steps. We can use this same subsequence approach in defining the ConvLSTM2D input where the number of time steps is the number of subsequences in the window, the number of rows is 1 as we are working with one-dimensional data, and the number of columns represents the number of time steps in the subsequence, in this case 32. For this chosen framing of the problem, the input for the ConvLSTM2D would therefore be: We can now prepare the data for the ConvLSTM2D model. The ConvLSTM2D class requires configuration both in terms of the CNN and the LSTM. This includes specifying the number of filters (e.g. 64), the two-dimensional kernel size, in this case (1 row and 3 columns of the subsequence time steps), and the activation function, in this case rectified linear. As with a CNN or LSTM model, the output must be flattened into one long vector before it can be interpreted by a dense layer. We can then evaluate the model as we did the LSTM and CNN LSTM models before it. The complete example is listed below. As with the prior experiments, running the model prints the performance of the model each time it is fit and evaluated. A summary of the final model performance is presented at the end of the run. We can see that the model does consistently perform well on the problem achieving an accuracy of about 90%, perhaps with fewer resources than the larger CNN LSTM model. Note: given the stochastic nature of the algorithm, your specific results may vary. If so, try running the code a few times. This section lists some ideas for extending the tutorial that you may wish to explore. If you explore any of these extensions, I¡¯d love to know. This section provides more resources on the topic if you are looking to go deeper. In this tutorial, you discovered three recurrent neural network architectures for modeling an activity recognition time series classification problem. Specifically, you learned: Do you have any questions?
Ask your questions in the comments below and I will do my best to answer. ¡¦with just a few lines of python code Discover how in my new Ebook:Deep Learning for Time Series Forecasting It provides self-study tutorials on topics like: CNNs, LSTMs,Multivariate Forecasting, Multi-Step Forecasting and much more¡¦ Skip the Academics. Just Results. Click to learn more. Hi Jason, So enjoy reading with your stuff, very helpful. As we can use CNN+LSTM to predict the spatial-temporal data, can we reverse the architecture as LSTM+CNN to do the same job? Any examples for LSTM + CNN? Not that I have seen. What application did you have in mind exactly? Sequence to image? Comment  Name (required)  Email (will not be published) (required)  Website"
