"","site","date","headline","url_address","text","keyword"
"1","kaggle",2018-11-06,"New: Maintained Datasets","http://blog.kaggle.com/2018/11/06/new-maintained-datasets/","Can you trust the data you use on Kaggle? Is it licensed? Has it been updated recently? Those sensible questions are the reason for the new ¡°Maintained by Kaggle¡± badge you may have noticed while browsing select datasets. This badge signifies that a dataset is maintained by Kaggle, though it may or may not be data that Kaggle has collected (e.g. Kaggle - Meta Kaggle vs. SF Open Data - Police Calls). Kaggle connects to datasets of other organizations using public APIs like Socrata and FRED. The ¡°Maintained by Kaggle¡± badge means that Kaggle is now and will continue to actively maintain that dataset. This includes regular updates to descriptions and metadata, quicker response rates in discussion, and accurate current data from the source. Our goal is to create seamless workflows that allow everyone to do data science on Kaggle and be confident in the data they work with. Kaggle maintains data from various sources and in a variety of subject areas. Here a few examples of open-source datasets we're currently maintaining:  See even more datasets currently maintained by Kaggle! Are there other datasets you¡¯d like to see ¡°Maintained by Kaggle?¡± Do you manage a data repository that you¡¯d like to integrate with Kaggle? Check out our Product Feedback Forum to send us your comments and discuss your thoughts with other Kagglers. ","Keyword(freq): dataset(5), api(1), call(1), comment(1), description(1), example(1), kaggler(1), metadata(1), organization(1), question(1)"
"2","datacamp",2018-11-05,"Peter Bull discusses the importance of human-centered design in data science. ","https://www.datacamp.com/community/blog/human-centered-design-data-science","Hugo Bowne-Anderson, the host of DataFramed, the DataCamp podcast, recently interviewed Peter Bull, a data scientist for social good and co-founder of Driven Data. Here is the podcast link. Hugo:               Hi there, Peter, and welcome to Data Framed. Peter:               Thanks, Hugo. I'm happy to be here. Hugo:               I'm happy to have you here. I'm really excited to be talking about human centered design and data science, the role of design in data science, and what data science can tell us about human centered design as well. Before we get into this, I want to find out a bit about you. What are you known for in the data community? Peter:               Primarily I'm known for my work at Driven Data. Driven Data is an organization that runs machine learning competitions that have a social impact. We work with non-profits, NGOs, government groups to help them figure out a way that machine learning can help them to be more effective. Then we put that online so that our global community of data scientists can come up with the best solution to this particular problem. Then after the competition, we help the organization to use that going forward. Peter:               That's probably one of the things, is just that work at Driven Data that we've been doing for the last five years. Outside of that, there are two particular areas of data science that I often talk about and I'm very interested in. The first one is engineering best practices for data science. I'm one of the maintainers of the cookie cutter data science project, which is a project template, that I hope we get some time to talk about because it's one of my pet projects and I think it makes a big difference in our own work, and I hope it makes a difference for other people. Peter:               The other one is thinking about the social impact that data science can have, and its relationship to the larger data ethics conversation that's happening. We just released a package called ""Deon"", D-E-O-N, that's for building ethics checklists that you can use as part of your data science project. If we get a chance, I'd love to talk about both of those as well, because they're things that I care deeply about. Hugo:               I would love to jump into all of these things. To recap, we have machine learning competitions with social impact, engineering best practices, which I think is incredibly important, particularly because there is an argument that in data science ... the idea of best practices in general is in a woeful state and something that a lot of people are working on a correction for, and bringing engineering best principles into that will be essential. Then of course, the data ethics aspect of your work, very recently ... Mike Loukides, Hilary Mason, DJ Patil, have started writing their series on data ethics for O'Reilly where they've actually got a post on checklists versus oaths versus codes of conduct. I think all of these things are incredibly topical. Hugo:               Let's just spend a bit of time to go through each of these. In terms of your machine learning competitions with social impact, could you just give us a couple of examples? Peter:               Yeah, sure. I'll start with one of my favorites, and that was the first competition we ever ran. There's a nonprofit organization called Education Resource Strategies. Really what they want to do is they want to help school districts to spend their money more effectively. Schools are spending money on things like student transportation, teacher salaries, textbooks. They have a wide range of operational costs. Right now, it's very difficult for a school district to say, ""Am I paying a lot more for textbooks than neighboring districts and getting the same outcomes? Are my investments being effective?"" The biggest barrier to doing that kind of benchmarking or comparison is that school budgets come in wildly different formats. There's not standard for reporting the categories of a budget expenditure so that I can say, ""We're spending more on textbooks than a neighboring school, and we need to look at this."" Peter:               Education Resource Strategies gathers all of this budget information from the districts they work with. Ultimately, what their output is is a recommendation for how to think about the school district's budgeting after they go through this process of benchmarking that district against other districts. The big problem is that they spend hundreds of person hours a year looking at Excel spreadsheets, reading a budget line item, and trying to assign it a standard set of categories. Peter:               As I'm sure your audience will have picked up on from the description, they have a lot of labelled data that they've generated through the course of their operations. That label data is a budget line item, a description of it, the cost of that budget item, and then what category it belongs to, whether that is transportation, textbooks, extracurricular activities, administrative salaries. All of those things, they've captured over their history of working with school districts. Peter:               So our first competition was how do we help this organization that really cares about the output report and not about this taxonomy process? How do we help them to automate that? So we ran a competition where people built algorithms to parse the natural language in these budgets, to look at these budget costs, and to automatically assign categories for those school budgets to those line items. We took the output of that competition, we turned it into a tool that fits into the workflow that this organization already had. It's saving their analysts tons of time in terms of just reading through sales spreadsheets so that they can focus that time where they can really add value, which is about making recommendations for how those budgets can be changed. Hugo:               That's great. It seems like it would reduce so much of the manual labor involved. Peter:               Yeah, really it's ... Last time we checked in, it was saving them about 300 person hours a year to automate that process. For a relatively small nonprofit organization, that's actually a huge amount of labor savings. Really, their goal is to employ those savings more effectively, where their employees actually add value, rather than in the labeling of spreadsheets where it's just this task that had to happen, any way. Hugo:               Yeah, absolutely. We should mention that if people find this type of stuff pretty exciting and interesting, they can check out all of the competitions at Driven Data, but if they find this particular competition interesting, they can even take the DataCamp course that you've built and that I collaborated on, which is learning from the experts: you get to build the winning solution in the end. Peter:               Yeah, that's right. That course will walk through not only what a baseline solution to a problem like this is, but also how the person who won the competition combined a number of interesting techniques to get to that best-performing solution. Hugo:               I'm not going to spoil the punch line. I don't want you to either, but I will say that it's not an LSTM or any crazy deep learning architecture that wins the competition. Hugo:               Now we've talked about the types of machine learning competitions you do at Driven Data. Maybe you can tell us a bit about your thoughts on engineering best practices for data science, and in particular your cookie cutter data science project that you maintain? Peter:               Great. Yeah, so my background is in software engineering. One of the things that I think about while I'm working on data science projects is how software and data science go together. I think there are some important differences between the processes, in that data science tends to be more open-ended, tends to be more of a research and development effort. It's still the fact that a lot of what we do in data science is, at its core, building software. Even if that software exists in a Jupyter notebook or in an Rmarkdown file, it's still a piece of software. A lot of the best practices that come out of software engineering can be employed to improve those products. Peter:               The cookie cutter data science project is what we think of as the first pass at standardizing our process to make ourselves more effective. That's to have a consistent layout of what a data science project looks like. If you were to look at a web application in Django, which is a Python web framework, or in Ruby on Rails, or in Node.js, all of these are different programming languages but any time you build a web application in one of those frameworks, you have more or less the same structure. What that means is, that anyone who's a web developer can go into a project like that and have some expectation about where they would find certain kinds of code. The code that talks to the database usually lives in one place. The code that talks to the front end usually lives in another place. Those expectations make it very easy to work together and collaborate on projects. Peter:               The cookie cutter data science project idea is to bring that kind of standardization to our own data science work. We have a defined folder structure where our data lives. We have a set of folders for raw data, data that has some processing but is in an interim state, and then processed data. We have a particular folder structure for where we keep our Jupyter notebooks or Rmarkdown files that are built in the literate programming style. We have another set of folder structures for data processing pipelines that may exist as scripts, and then ultimately may get refactored in something like a Python package. Peter:               Because of this consistency, it's very easy for us to move from project to project, and pick up something and remember where we are, how to reproduce something, and because we work with lots of different clients on lots of different projects, this means that anyone who works on the team can jump into any project without having to spend a lot of time figuring out what happens where. Hugo:               That's great. I find all the details very interesting, but as you've hammered home, the idea of actually having an overarching, overall consistent layout to data science projects and a system of best practices, I think is incredibly important. I presume this actually plays a role in your approach to building the package for data ethics and ethical checklists, of having something that you can carry across projects. If there are biases involved or challenges, they are systematic in the sense that they won't be induced by a human working on the project. They'll be in this structure as a whole, so you'll become aware of it. Peter:               Yeah, so I think the two are related in that we really spend a lot of our time building tools for people who are data scientists. A lot of times they start out as tools that we're using ourselves, and then we open source those tools so that other people who are working in data science can use them. That's how the cookie cutter data science project started, and that's really how this ethics checklist package DEON started as well. Peter:               The idea there was, there are a lot of conversations around data ethics that we found very compelling from a standpoint of really seeing where things had gone wrong in the process, and feeling like ourselves, we were vulnerable to some of these things that could go wrong. It's very very hard to have perfect foresight and to understand exactly what can go wrong in any given circumstance. Because we kept seeing these examples and feeling like, ""Would we necessarily have caught this in our own kind of work,"" we wanted to have a more actionable way of engaging with that data ethics conversation, to make sure that we didn't fall into some of these traps that just exist in the work. That if you're focused on methods, if you're thinking about data, you can get into these really technical aspects and not have a chance to pull up and look at the ethical implications. Peter:               We wanted to have a really process-driven way of engaging that conversation for our own projects. What this package we built does, is it generates a data ethics checklist that's really framed around the data science process. It starts with the data collection phase. There are a set of checklist items that ask you questions like, do the participants in your data collection give informed consent for the data that is collected? That's one example of an item on the checklist. Peter:               What we've done is we've taken each of these checklist items at different parts in the data science process, and we've mapped them to real world examples where something has gone wrong. We've got this collection of news articles and academic papers that explain when data science projects have hit ethical implications and the problems that have arisen. Peter:               There was actually just a really great article about Amazon really trying to build a resume filtering algorithm. They get an unbelievable volume of resumes for any position that they open up. They had the belief that they could use all of their historical data to train an algorithm to identify the top candidates that were applying for a given position. Now, as a sort of framing that may seem from a data science perspective like it makes a lot of sense. We've got a long set of training data, and we want to be able to replicate this with an algorithm. Peter:               They just actually shut down the team that had been working on this project for years, because they found that the algorithm was biased against women. In particular, it wasn't saying, ""Oh, is this person a woman and they've indicated that on their application and now I want to use that and discount their application,"" but it was using things that were a little more implicit than that. In particular, if the applicant had attended a women's college, then their score went down. They discovered these problems with their algorithm and disbanded the team that was working on this project entirely, because they couldn't get it over this bump in the process. They're still having humans review all of these resumes that come in. Peter:               This is just sort of a classic example of something that's seems like a great setup for a machine learning problem in the abstract, but if you don't think about how it's affecting your outputs that aren't just some measure of accuracy, it can go really really wrong. Hugo:               These are the types of things that DEON would ask you to check for? Peter:               That's exactly right. Yeah. It goes through the data science process from data collection to data cleaning to exploratory data analysis to actually building models and that's where this would come in. Then actually it's got a section on deploying models. When the model is deployed, what are the questions that you should ask? Really, the goal is not to have all of the answers about what's right and what's wrong in a checklist. Given all of the different domains people work in, that's really an impossible task. Peter:               The goal is to take people who are already conscientious actors that want to be doing the right thing and make sure they're having the conversations about the ways that things can be misused. Really the workflow we see for the tool is you generate a checklist using the tool, and then you submit a PR to your project that says, ""Hey, here's our ethics checklist, let's make sure we talk about each of these items as a team."" It's really about spurring that team discussion to make sure you've considered the particular implications of your project and you've made the right decision about it. Hugo:               We'll include links to the cookie cutter project and the DEON package in the show notes. I think you discussing data ethics in terms of thinking about the variety of stakeholders really dovetails nicely into our conversation about human centered design in data science and why it's important. As a prelude to human centered design though, I'd just like to ask you a quick question about the role of empathy in data science as a whole. I'm wondering what is the role of empathy in data science for you? Peter:               That's a great question. I actually feel like empathy is a term that has started to pop up in the data science conversation as a core skill of a data scientist. In my mind, empathy is just one way to get at a particular kind of approach. That approach is to be problem focused rather than method focused. What I mean by that is we should start as data scientists that are really in a professional service role. We're providing a service to different parts of a business or different parts of an organization. We should start with what the problem is that we're solving, and understand the context for that problem, rather than saying, ""Hey, who's got an NLP problem that I can solve with an LSTM?"" Or, ""Who's got a computer vision problem where I can try out the latest neural network methods and get a really cool result."" Peter:               If you start methods first, a lot of times you end up with a solution that's not going to be really useful in the context in which it operates. When we talk about data science and empathy, what we're really saying is that you should empathize with how your data science output will be used. You should empathize with what's the problem we're solving. When we talk about empathy, I think that's one way of getting to a perspective that's problem first rather than method first. Hugo:               And do any concrete examples spring to mind? Peter:               Yeah, so I think that for me, a good example is we worked on a project that is trying to automatically identify species in videos. Species of animals, that is. There's a research organization that has these motion-detecting cameras that they set up in the jungle and they try to record videos of chimpanzees, but they get a lot of videos of other animals as well. Instead of sitting there and watching all of these videos and saying which one has a chimpanzee and which one doesn't, we were helping them to build an algorithm to automatically identify the animals that appear. We actually ran a competition around this last year. If you're curious, you can look at DrivenData.org and see the results of that competition. Hugo:               What was the name of the competition? Peter:               The name of the competition was ""Primate-rix"" Factorization. Hugo:               Stop it. Peter:               Thanks for asking. Hugo:               That's brilliant. Peter:               We really care about our data science puns, and that's one of my absolutely favorites. Hugo:               When talking about the data science puns, we have to mention Naive Bees, as well. Peter:               Yeah. To be honest Hugo, with your accent I wasn't even sure if you were saying Bees or Bayes, so it works even better in Australia. Hugo:               Naive Bees of course, is currently being turned into a series of DataCamp projects as well. Peter:               That's right, yeah. The Naive Bees competition was to build an algorithm to identify honey bees from bumblebees. We're working on a set of DataCamp projects to help people work through that problem to give them that first exposure to a computer-visioned task that fits into a classification framework, and look at the more traditional methods and then move on to deep learning, neural networks, and convolutional neural networks. Hugo:               After that pun-tastic interlude, back to the role of empathy in identifying primates? Peter:               Back to the role of empathy. Really, this is about going back to the context and understanding the context in which you operate. We were working with this team of ecologists and biologists. They spent a lot of time in the field setting up these cameras, capturing data, watching videos, and then writing papers about what they see in the videos. The output that we ended up working on after the competition was an open source package that let you run from the command line, predict here are my new videos, and it would output a CSV with each of the videos and a probability that a certain kind of animal appeared in the videos. We were pretty pleased with this output. It'd be super useful for us. Peter:               The first thing we heard from the team we were working with is, ""We can't even get this tool installed. I can't get XGBoost to install on my machine. I'm having trouble getting the version of TensorFlow installed. I'm having trouble getting GPU Drivers installed."" All of this stuff that feels like second nature to us as data scientists, sort of blinded us to the context in which this tool was actually going to be used and it's by ecologists that aren't used to all of this complex machinery around the packaging of data science tools, that can make it really challenging to use the latest methods. That's just a really concrete example of a place where we weren't doing the right thing upfront to really understand that context and make sure we built something useful. We were building something that we knew would be useful for us. Hugo:               I've got to make clear that, I'm sure a non-trivial proportion of working expert data scientists have a lot of problems getting XGBoost installed occasionally, as well. Peter:               Yeah, if someone wants to take on the initiative to improve the XGBoost installation experience, that's a really valuable project that someone could do for the open source community. Hugo:               Let's jump into human centered design and why it's important in data science. I think probably a lot of our listeners wouldn't necessarily think of design principles as being something which would play a huge role in the data science process. Maybe you can tell us about human centered design and why it's important in data science? Peter:               Great, yeah. Human centered design is a way of framing the design process. It's really related to other terms that are in this field that you may have heard of, like design thinking, the double diamond method, and design sprints. Those are all sort of popular terms that people may talk about. It's really referring to the same set of ideas, which is about having a design process. Peter:               Human centered design in particular is the one that we're most familiar with through our work with an organization called IDO.Org. IDO is one of the leading human centered design firms. They helped design the first Apple mouse. They have a long history of being designers both from an industrial design perspective, but also from a digital design and then eventually service design perspective. They have a really long history and track record of working and using these design tools to spur innovation. Peter:               They spun out a nonprofit arm, IDO.org, that works with NGOs to have the same sort of results. We partnered with that organization to look at digital financial services in Tanzania. Just to take a step back, that's sort of the context that we're working in, is with this team of human centered designers. What that human centered design process looks like, and I'll give you the overview first and after that we can dig into the details of that particular project which I think are pretty enlightening for how data science and design work together ... The big picture is that human centered design is about starting with what's desirable. There's a perspective that the best solutions to a problem are desirable in that someone wants to use them, they're feasible from a technological perspective, and they're viable from a business perspective. The best solutions sit at the intersection of that Venn Diagram. You know you're not having a good data science conversation until you're talking about a Venn Diagram. Hugo:               I was waiting for the Venn Diagram. Peter:               Right? This particular Venn Diagram is desirable, feasible, viable. We want the intersection of all three of those things. Hugo:               Of course a lot of data science work maybe will start with feasible, like the newest cutting edge technology and the coolest most efficient algorithms and that type of stuff, right? Peter:               That's exactly right. I think that that is one of our tendencies as data scientists that I see in myself all the time, where I'm getting excited about lots of these new technologies and I want to find ways to use them. The trick is just to find the balance for really solving a problem where using that is appropriate. The human centered design process starts from this perspective of what's desirable to a user. It gets there by moving through these three phases of the design process. Peter:               The first is inspiration. Inspiration is about going and observing the people who will be users of your end product. In the case where you're a data scientist, let's say that your job is to create this report that's emailed out to your executive team once a month. What you would actually do is you would go and talk to the people who get that email and you would say, hey, when you get this email, what do you use it for? What does it go into? Do you say, ""Okay, I need some top line numbers here that I put into slides?"" Or is something you read to get context that then you say to the people that you manage, ""We need to change things, XY and Z."" Peter:               You would go and you would actually talk to the consumers of your data science process to see how does it fit into the bigger picture. The inspiration part of the phase is really about going broad, brainstorming, and trying to get inspired by everything you might see around you. It's not about, ""Let me see the data,"" and get inspired by what's in my data. It's ""let's get inspired by everything before we even think about the data"". That's the first phase. Peter:               The second phase is ideation. What this means is trying to come up with particular solutions to a problem and then testing those really quickly. One of the core concepts here is having the lowest fidelity prototypes possible, and getting real user feedback on them. It might be the case that you're working on a model to do some classification and ultimately it's going to be this big, complex machine learning system that's deployed in the Cloud. What you might do first is ... Let's say we're working on this honeybee/bumblebee problem. You might just say, ""Okay, here's a spreadsheet of probabilities for each of these species, what would you do with this?"" That's sort of my lowest fidelity one. Take the most basic method, take the most basic output and say, ""Is this useful?"" Then you take that and you learn from that. Peter:               The ideation phase is about these iterative cycles of learning from low fidelity prototypes, that slowly and slowly build fidelity around them, but it sort of helps to keep your project going in a direction that ensures that the output is going to be targeted at a real problem. That it's actually going to be useful, and that as you come up with new ideas throughout that process, you can see which of those are good ideas and which ones aren't. Hugo:               It keeps you honest, right, in the sense that you're not going to end up building something which is useless, or going down the entirely wrong path. Peter:               That's exactly right. Yeah. I mean, I've seen so many times that ... even work that we've done where you build a dashboard that no one ever looks at. Everyone thought the dashboard was what they wanted, but that's not the right tool for the job. People really cared about answering one specific question and just if they went to one page with a thumbs up for a yes and a thumbs down for a no, that would have been either better than the dashboard that you created. Hugo:               In this dashboard case, instead of building the dashboard, perhaps the inspiration or ideation phase would involve drawing the type of figure on a whiteboard or on a piece of paper that the dashboard would show and say to the stakeholders, ""Hey, is this actually what you want?"" Peter:               Yeah, that's exactly right. Or even mocking it up in PowerPoint or using Microsoft Paint to make a little prototype and say, ""Hey, is this graph something that you would need? How would you actually use this in your process?"" Trying to get at, not just saying, ""Hey, do you like this, is this something you want to see?"" More, ""How would you use it then?"" That question of how you actually use something will change people's answers. Peter:               I think in a lot of data science work, it's very clear that if you ask, ""Hey, do you want to see this, hey do you want to see that, hey do you want to see something else?"" people say yes to all of those questions. How could you not want to have all of the information that you could have? Really, the question of how would you use it helps you to narrow it down on the things that are going to be valuable, and not create this information overload. Hugo:            Tell us about the third phase. We've got inspiration, ideation, and the third ""I"" is ...? Peter:               The third ""I"" is implementation. Implementation here is not just, okay, you finished it, now go build it. Implementation is actually a continuation of this process, to go from prototyping to actually piloting a solution. We think of prototypes as being small scale, low fidelity, something we do with a couple of people to get some feedback. We think of implementation as, okay, how do we become more data driven about this decision that we're making now? Implementation is about picking a pilot cohort, a set of users that will actually consume this and then saying, ""Okay, here's the version we're working with now. Here's a higher fidelity prototype that we have. Let's put it out there for a particular user group, and let's do some real testing of if this solution is working and solving the problem that we want to solve."" Implementation is this piloting phase to get to the point where not only do you have a lot of great anecdotal and qualitative evidence that you've built up from these discussions, but you're also starting to get this quantitative evidence for how what you built is changing the metrics that you care about. Hugo:               You and I have discussed a really interesting project you worked on previously, which I think illuminates all of these steps really wonderfully. It's a project where you were looking at digital financial services in Tanzania. Maybe you could tell us a bit about this project and how human centered design actually played a pivotal role for you. Peter:               Great, yeah. This project, I'm going to step back and sort of give you the context that this project is done in. For a lot of people, your money has always been digital. What I mean by that is that when I opened my first bank account, my parents brought me to a bank in middle school and said, ""You're going to have a bank account. You have to be responsible for your finances now."" I gave that bank some money and they wrote down on a piece of paper how much money I had. That amount of money wasn't physical cash that I was holding, that was actually in a database that the bank had. That was purely digital. That's my native experience of what it's like to interact with money, is to have what is really a digital representation of that currency. Peter:               Whereas in lots of places, bank infrastructure is not very good. It's expensive to build banks, there are security risks of moving physical money around. In many countries, it's the case that people do most of their interaction with money in pure cash. That means when they want to save money, they have cash. When they want to spend money, that have to get enough cash to buy something. That can be very limiting in terms of your ability to save money over time, your ability to get loans that you might need to buy particular things. There's a belief in the international development space that one of the ways in which we can help lift people out of poverty is to provide them access to digital financial services. This same digital experience that people have had growing up where they put their money in a bank, how can we provide that without having to build all of that physical banking infrastructure? Peter:               One of the approaches to this is to have a digital wallet on your phone that's associated with your mobile phone account. Mobile phones have been one of these leapfrogging technologies where people who didn't even have a landline now have access to a mobile phone. The mobile phone providers are now starting to offer services where you can actually save cash on your phone. You can say, ""Okay, I've got a wallet with $10 in it,"" and that's just associated with my phone. Peter:               There's this transition from a world in which you just work with cash to a world in which you have some digital representation. For people who haven't had the experience of always having a digital representation, you have to build trust in that system. You have to make sure that the digital financial services actually fit the needs that this community has. That's the big project background and context, is how do we increase uptick of these digital financial services that are providing for people in these environments that have very volatile incomes, some sense of stability for their money, some access to loan infrastructure, some access to savings infrastructure? That's the context. Peter:               This is a project that's funded by the Gates Foundation to try to understand what levers we can pull to help engage people and give them access to these tools. One of the particular things about this digital financial services system is that you need a way to exchange your digital currency for cash. There's always going to be some sort of transaction that's like working with an ATM. However, ATMs are relatively expensive and there's a lot of physical infrastructure you'd need for an ATM to work. Peter:               What happens in places where they have digital financial services, and this also goes by the name ""Mobile Money"", so I'll use those interchangeably, you have what are called Mobile Money agents. These are usually people that have a small shop somewhere, that are selling home goods, snacks, drinks. They also become Mobile Money agents. What that means is, you can go to them and say, ""I want to trade five digital dollars for five dollars in cash,"" or, ""I want to take five dollars in cash and put that in my digital wallet."" They're the interface between physical cash and digital cash. Peter:               The focus of our project was, how do we make that interaction between agents and customers one that can help build trust in this Mobile Money system, and that direction was driven by this human centered design process. When we went out, the first thing we did was talk to people who used Mobile Money and people who didn't. We went and sat in a number of markets. We watched people buy things, and we asked them, ""Why did you buy that with cash? Why did you buy that with Mobile Money? Do you have a Mobile Money account? What's your experience been like?"" Hugo:               It sounds like in this process as well then, you're getting qualitative data as well as quantitative data. Peter:               That's right. Really, a big part of what you do is try to gather that qualitative data as well. We've been gathering this qualitative data through these interviews, but we also got Mobile Money transactions from one of the mobile network operators for a full nine months. It was tens of gigabytes of data, all of the transactions. Hundreds of millions of Mobile Money transactions in the country. Our goal was to combine that very rich data source about real behaviors with behaviors that we heard about, with these qualitative experiences that people actually had. Peter:               One really great example that I think just highlights the value of human centered design is the fact that we kept talking to agents and saying, ""What are your biggest struggles with Mobile Money? How do you see it fitting into the larger context of your business where Mobile Money is one of your revenue streams, but you also sell other goods?"" What we kept hearing from these Mobile Money agents is, ""Well, it can be really tricky to predict how much money I'm going to make on Mobile Money transactions, because I earn some commission on each transaction, but it's really opaque what those commissions are and it's very hard for me to predict on any aggregated timeframe for some given week or some given month how much money I'm going to get in commissions."" Peter:               This was particularly interesting to us because we as data scientists had been digging into this huge treasure trove of data thinking, ""Oh, this has all the answers in it, this is going to be amazing. We can find so many insights in this huge range of transactions that we have."" One of the things that we realized after doing these interviews is, we didn't know what the commissions for an agent were. That was not data that was in the dataset that we had. We had the amount of the transaction, but the portion that then the agent got as a commission was calculated totally separately by some business logic that existed in another application. Hugo:               Even if you did know how much they got, you may not know whether that was a lot or a little or how that affected them on the ground. Peter:               Oh, absolutely. Yeah. Just the thought that we could have known what was valuable to agents by looking at the dataset and figuring out these patterns, that dataset didn't even have the most important variable to the agents that we were working with. We wouldn't have learned that if we didn't talk to them and just try to learn things from the data alone. Peter:               One of the big things that we try to do in all of our work, and I really encourage all data scientists to do, is to go out and observe how your data gets collected. If you're working with IoT data in a factory, actually go to the factory floor, watch how things happen. If you're like us working with digital financial services, go watch people make transactions. See what actions in the real world correspond with something in your data, because that perspective changes how you think about the data itself. It changes where you trust the data and where you don't trust the data. I really encourage people to get away from their screen, step away from their desk, and go watch the data collection in action. I think in nearly every case, you can go do this and it will have a transformative effect on how you think about that data. Hugo:               I think that's really important, particularly as we live in an age when people maybe first get associated, have experience with data science, online competitions, for example, such as yours ... platforms like DataCamp, getting tech data or getting data online, and not actually thinking a lot about the data-generating process. Peter:               Yeah. It's very easy to just start with the data and say, ""Okay, what's in here?"" Until you really understand that data-generating process, you won't know to ask, ""What's not in this data that I might care about?"" Or, ""What in this data is not reliable?"" For example, we saw a lot of these Mobile Money transactions fail because of network connectivity, for example. For some of those transactions, we wouldn't have seen that in the data. If the network failed, the transaction never when through, it doesn't get recorded in the database. Understanding the limitations of the connectivity and how that affects the experience, is something that we can only even start asking about, how do we measure those transactions, when we've actually observed them. Hugo:               We're going to need to wrap up in a few minutes Peter. I was just wondering, are there any other aspects of the project in Tanzania that you wanted to discuss? Peter:               Yeah, so just to share one other example of where the human centered design approach I think really made a difference. We were looking at the times of day which a Mobile Money agent was busiest. When were people coming to trade cash for digital currency or do the opposite. We took the data and we looked at it for days of the week and times of day, and we built this really beautiful heat map visualization that you can think of as checkerboard where each of the squares is either lighter or darker based on how many transactions you have. We made it interactive so that you can hover and you can see how busy, for a different region, it's a different time of day, it's a different day of week, and really get a great sense of the patterns of Mobile Money use that happened. Hugo:               It's also colorblind human friendly. Peter:               It absolutely is. We did build it using viridis, which is colorblind friendly. If you're not thinking about that for your visualizations, you should be, because that's a little bit of human centered design. Hugo:               Speaking as a colorblind individual, I'm red-green colorblind as you know 8% of human males are. Peter:               You appreciate viridis even more than the rest of us that think it's a beautiful color map. Hugo:               I can't get enough of it. Peter:               Well, I think it's a really compelling and beautiful color map, which is one of the reasons that we loved this visualization, which is one of the reasons the people we worked with loved this visualization, and how interactive it was ... but, none of the agents that we were working with had access to a computer. They weren't sitting at a laptop and they wanted to look at a dashboard that had this beautiful visualization on it. That wasn't going to be useful to them. Peter:               What we ended up actually building was a text-based visualization that was essentially just a bar chart where it would say ""M"" for Monday and then it would have three capital ""I's"" in a row. Then it would have ""T"" for Tuesday, and it would have eight capital ""I's"" in a row. By building these text-based visualizations, essentially bar charts built out of characters, we could actually give a data visualization experience to these agents that were working on feature phones. That process of taking something that we think of as an amazing data science output, this really compelling interactive visualization, and putting that visualization into a context where it can actually get used, is one of the transformative experiences of that project for us where we started to think about, ""Okay, what's the context for all of our output?"" Not, ""How do we make the most amazing data visualization?"" Hugo:               Yeah, and it's so reliant on the knowledge of what actual technology, what phones humans have on the ground. Peter:               Yeah, that's absolutely right. Hugo:               Peter, as a final question, I'm wondering if you have a final call to action to all our listeners out there? Peter:               Yeah. I think there are, in my mind, four core activities of a human centered data scientist, and I think we should all be human centered data scientists. The first one is, go to the field and observe the data being generated. Without understanding what a row in your dataset means, without actually observing that happening, without knowing what gets captured, what doesn't, what happens when something goes wrong, you'll be very limited in the output that you can have. Also, if you do go and do that, you'll be so much better positioned to ask questions that matter of your data. Without talking to those agents, we wouldn't have asked that commission question of the dataset. Going to the field, observing data being generated, is item number one. Peter:               Item two is design with, not for, by iterating on prototypes. This process of constant iteration, conversation with people who will actually be using the output, getting their buy-in on the decisions that you're making, means that it's going to be something that's useful when you finish the project. Not, ""I worked for three months, is this good for you?"" ""Oh, no, it's not,"" or it requires some major changes. It's how do we keep that process tighter in-sync so that we're actually building things that are useful. We do that with really low fidelity prototypes that we're constantly testing. Peter:               The third is to put outcomes, not methods or outputs, first. That's really saying, what is the outcome we care about? In our case, it was the increase in the adoption of digital financial services. That's what we cared about, and in particular we thought we could do that by improving the tools that Mobile Money agents had. Our goal was to say, ""Okay, the best outcome is for Mobile Money agents to be making more transactions."" That's what we want to measure. It wasn't, how do we do the most interesting dimensionality reduction on this huge dataset that we have. Peter:               The fourth item is to build consensus on metrics for success. I think this is one of the most difficult but most important ones, is you need to define upfront what success means and you need to get buy-in from everyone on that being successful. I think this is one of the things that people assume they've got the same goals if they're working on the same project from the get-go, but until you have that explicit discussion about what success means and what those metrics are, you won't be optimizing for exactly the same thing. Peter:               Those, I think ... My call to action really is to take those and try to build them into your process as a data scientist. Other than becoming a human centered data scientist, thinking about your users, and using a more collaborative process, I would encourage people to come check out a competition on DrivenData.org. We've got a lot of interesting social impact projects happening there. Or, to check out one of the open source projects that we had as part of this discussion, that's cookie cutter data science on DEON, the ethics checklist package. Hugo:               Of course, both of those projects and engaging in competitions and all the other great stuff you do on Driven Data, will help any budding data scientist, or established data scientist, to doing more human centered data work, as well. Peter:               Yeah, that's the goal. Hugo:               Peter, it's been such a pleasure having you on the show. Peter:               Hugo, thanks for having me. I loved chatting, as always.","Keyword(freq): agent(12), ethic(12), project(12), transaction(11), service(10), scientist(9), video(9), competition(7), tool(7), method(6)"
"3","mastery",2018-11-09,"How to Develop Multilayer Perceptron Models for Time Series Forecasting","https://machinelearningmastery.com/how-to-develop-multilayer-perceptron-models-for-time-series-forecasting/","Multilayer Perceptrons, or MLPs for short, can be applied to time series forecasting. A challenge with using MLPs for time series forecasting is in the preparation of the data. Specifically, lag observations must be flattened into feature vectors. In this tutorial, you will discover how to develop a suite of MLP models for a range of standard time series forecasting problems. The objective of this tutorial is to provide standalone examples of each model on each type of time series problem as a template that you can copy and adapt for your specific time series forecasting problem. In this tutorial, you will discover how to develop a suite of Multilayer Perceptron models for a range of standard time series forecasting problems. After completing this tutorial, you will know: Let¡¯s get started. How to Develop Multilayer Perceptron Models for Time Series ForecastingPhoto by Bureau of Land Management, some rights reserved. This tutorial is divided into four parts; they are: Multilayer Perceptrons, or MLPs for short, can be used to model univariate time series forecasting problems. Univariate time series are a dataset comprised of a single series of observations with a temporal ordering and a model is required to learn from the series of past observations to predict the next value in the sequence. This section is divided into two parts; they are: Before a univariate series can be modeled, it must be prepared. The MLP model will learn a function that maps a sequence of past observations as input to an output observation. As such, the sequence of observations must be transformed into multiple examples from which the model can learn. Consider a given univariate sequence: We can divide the sequence into multiple input/output patterns called samples, where three time steps are used as input and one time step is used as output for the one-step prediction that is being learned. The split_sequence() function below implements this behavior and will split a given univariate sequence into multiple samples where each sample has a specified number of time steps and the output is a single time step. We can demonstrate this function on our small contrived dataset above. The complete example is listed below. Running the example splits the univariate series into six samples where each sample has three input time steps and one output time step. Now that we know how to prepare a univariate series for modeling, let¡¯s look at developing an MLP model that can learn the mapping of inputs to outputs. Take my free 7-day email crash course now (with sample code). Click to sign-up and also get a free PDF Ebook version of the course. Download Your FREE Mini-Course A simple MLP model has a single hidden layer of nodes, and an output layer used to make a prediction. We can define an MLP for univariate time series forecasting as follows. Important in the definition is the shape of the input; that is what the model expects as input for each sample in terms of the number of time steps. The number of time steps as input is the number we chose when preparing our dataset as an argument to the split_sequence() function. The input dimension for each sample is specified in the input_dim argument on the definition of first hidden layer. Technically, the model will view each time step as a separate feature instead of separate time steps. We almost always have multiple samples, therefore, the model will expect the input component of training data to have the dimensions or shape: Our split_sequence() function in the previous section outputs the X with the shape [samples, features] ready to use for modeling. The model is fit using the efficient Adam version of stochastic gradient descent and optimized using the mean squared error, or ¡®mse¡®, loss function. Once the model is defined, we can fit it on the training dataset. After the model is fit, we can use it to make a prediction. We can predict the next value in the sequence by providing the input: And expecting the model to predict something like: The model expects the input shape to be two-dimensional with [samples, features], therefore, we must reshape the single input sample before making the prediction, e.g with the shape [1, 3] for 1 sample and 3 time steps used as input features. We can tie all of this together and demonstrate how to develop an MLP for univariate time series forecasting and make a single prediction. Running the example prepares the data, fits the model, and makes a prediction. Your results may vary given the stochastic nature of the algorithm; try running the example a few times. We can see that the model predicts the next value in the sequence. Multivariate time series data means data where there is more than one observation for each time step. There are two main models that we may require with multivariate time series data; they are: Let¡¯s take a look at each in turn. A problem may have two or more parallel input time series and an output time series that is dependent on the input time series. The input time series are parallel because each series has an observation at the same time step. We can demonstrate this with a simple example of two parallel input time series where the output series is the simple addition of the input series. We can reshape these three arrays of data as a single dataset where each row is a time step and each column is a separate time series. This is a standard way of storing parallel time series in a CSV file. The complete example is listed below. Running the example prints the dataset with one row per time step and one column for each of the two input and one output parallel time series. As with the univariate time series, we must structure these data into samples with input and output samples. We need to split the data into samples maintaining the order of observations across the two input sequences. If we chose three input time steps, then the first sample would look as follows: Input: Output: That is, the first three time steps of each parallel series are provided as input to the model and the model associates this with the value in the output series at the third time step, in this case 65. We can see that, in transforming the time series into input/output samples to train the model, that we will have to discard some values from the output time series where we do not have values in the input time series at prior time steps. In turn, the choice of the size of the number of input time steps will have an important effect on how much of the training data is used. We can define a function named split_sequences() that will take a dataset as we have defined it with rows for time steps and columns for parallel series and return input/output samples. We can test this function on our dataset using three time steps for each input time series as input. The complete example is listed below. Running the example first prints the shape of the X and y components. We can see that the X component has a three-dimensional structure. The first dimension is the number of samples, in this case 7. The second dimension is the number of time steps per sample, in this case 3, the value specified to the function. Finally, the last dimension specifies the number of parallel time series or the number of variables, in this case 2 for the two parallel series. We can then see that the input and output for each sample is printed, showing the three time steps for each of the two input series and the associated output for each sample. Before we can fit an MLP on this data, we must flatten the shape of the input samples. MLPs require that the shape of the input portion of each sample is a vector. With a multivariate input, we will have multiple vectors, one for each time step. We can flatten the temporal structure of each input sample, so that: Becomes: First, we can calculate the length of each input vector as the number of time steps multiplied by the number of features or time series. We can then use this vector size to reshape the input. We can now define an MLP model for the multivariate input where the vector length is used for the input dimension argument. When making a prediction, the model expects three time steps for two input time series. We can predict the next value in the output series proving the input values of: The shape of the 1 sample with 3 time steps and 2 variables would be [1, 3, 2]. We must again reshape this to be 1 sample with a vector of 6 elements or [1, 6] We would expect the next value in the sequence to be 100 + 105 or 205. The complete example is listed below. Running the example prepares the data, fits the model, and makes a prediction. There is another more elaborate way to model the problem. Each input series can be handled by a separate MLP and the output of each of these submodels can be combined before a prediction is made for the output sequence. We can refer to this as a multi-headed input MLP model. It may offer more flexibility or better performance depending on the specifics of the problem that are being modeled. This type of model can be defined in Keras using the Keras functional API. First, we can define the first input model as an MLP with an input layer that expects vectors with n_steps features. We can define the second input submodel in the same way. Now that both input submodels have been defined, we can merge the output from each model into one long vector, which can be interpreted before making a prediction for the output sequence. We can then tie the inputs and outputs together. The image below provides a schematic for how this model looks, including the shape of the inputs and outputs of each layer. Plot of Multi-Headed MLP for Multivariate Time Series Forecasting This model requires input to be provided as a list of two elements, where each element in the list contains data for one of the submodels. In order to achieve this, we can split the 3D input data into two separate arrays of input data: that is from one array with the shape [7, 3, 2] to two 2D arrays with the shape [7, 3] These data can then be provided in order to fit the model. Similarly, we must prepare the data for a single sample as two separate two-dimensional arrays when making a single one-step prediction. We can tie all of this together; the complete example is listed below. Running the example prepares the data, fits the model, and makes a prediction. An alternate time series problem is the case where there are multiple parallel time series and a value must be predicted for each. For example, given the data from the previous section: We may want to predict the value for each of the three time series for the next time step. This might be referred to as multivariate forecasting. Again, the data must be split into input/output samples in order to train a model. The first sample of this dataset would be: Input: Output: The split_sequences() function below will split multiple parallel time series with rows for time steps and one series per column into the required input/output shape. We can demonstrate this on the contrived problem; the complete example is listed below. Running the example first prints the shape of the prepared X and y components. The shape of X is three-dimensional, including the number of samples (6), the number of time steps chosen per sample (3), and the number of parallel time series or features (3). The shape of y is two-dimensional as we might expect for the number of samples (6) and the number of time variables per sample to be predicted (3). Then, each of the samples is printed showing the input and output components of each sample. We are now ready to fit an MLP model on this data. As with the previous case of multivariate input, we must flatten the three dimensional structure of the input data samples to a two dimensional structure of [samples, features], where lag observations are treated as features by the model. The model output will be a vector, with one element for each of the three different time series. We can now define our model, using the flattened vector length for the input layer and the number of time series as the vector length when making a prediction. We can predict the next value in each of the three parallel series by providing an input of three time steps for each series. The shape of the input for making a single prediction must be 1 sample, 3 time steps and 3 features, or [1, 3, 3]. Again, we can flatten this to [1, 6] to meet the expectations of the model. We would expect the vector output to be: We can tie all of this together and demonstrate an MLP for multivariate output time series forecasting below. Running the example prepares the data, fits the model, and makes a prediction. As with multiple input series, there is another, more elaborate way to model the problem. Each output series can be handled by a separate output MLP model. We can refer to this as a multi-output MLP model. It may offer more flexibility or better performance depending on the specifics of the problem that is being modeled. This type of model can be defined in Keras using the Keras functional API. First, we can define the input model as an MLP with an input layer that expects flattened feature vectors. We can then define one output layer for each of the three series that we wish to forecast, where each output submodel will forecast a single time step. We can then tie the input and output layers together into a single model. To make the model architecture clear, the schematic below clearly shows the three separate output layers of the model and the input and output shapes of each layer. Plot of Multi-Output MLP for Multivariate Time Series Forecasting When training the model, it will require three separate output arrays per sample. We can achieve this by converting the output training data that has the shape [7, 3] to three arrays with the shape [7, 1]. These arrays can be provided to the model during training. Tying all of this together, the complete example is listed below. Running the example prepares the data, fits the model, and makes a prediction. In practice, there is little difference to the MLP model in predicting a vector output that represents different output variables (as in the previous example) or a vector output that represents multiple time steps of one variable. Nevertheless, there are subtle and important differences in the way the training data is prepared. In this section, we will demonstrate the case of developing a multi-step forecast model using a vector model. Before we look at the specifics of the model, let¡¯s first look at the preparation of data for multi-step forecasting. As with one-step forecasting, a time series used for multi-step time series forecasting must be split into samples with input and output components. Both the input and output components will be comprised of multiple time steps and may or may not have the same number of steps. For example, given the univariate time series: We could use the last three time steps as input and forecast the next two time steps. The first sample would look as follows: Input: Output: The split_sequence() function below implements this behavior and will split a given univariate time series into samples with a specified number of input and output time steps. We can demonstrate this function on the small contrived dataset. The complete example is listed below. Running the example splits the univariate series into input and output time steps and prints the input and output components of each. Now that we know how to prepare data for multi-step forecasting, let¡¯s look at an MLP model that can learn this mapping. The MLP can output a vector directly that can be interpreted as a multi-step forecast. This approach was seen in the previous section were one time step of each output time series was forecasted as a vector. With the number of input and output steps specified in the n_steps_in and n_steps_out variables, we can define a multi-step time-series forecasting model. The model can make a prediction for a single sample. We can predict the next two steps beyond the end of the dataset by providing the input: We would expect the predicted output to be: As expected by the model, the shape of the single sample of input data when making the prediction must be [1, 3] for the 1 sample and 3 time steps (features) of the input and the single feature. Tying all of this together, the MLP for multi-step forecasting with a univariate time series is listed below. Running the example forecasts and prints the next two time steps in the sequence. In the previous sections, we have looked at univariate, multivariate, and multi-step time series forecasting. It is possible to mix and match the different types of MLP models presented so far for the different problems. This too applies to time series forecasting problems that involve multivariate and multi-step forecasting, but it may be a little more challenging, particularly in preparing the data and defining the shape of inputs and outputs for the model. In this section, we will look at short examples of data preparation and modeling for multivariate multi-step time series forecasting as a template to ease this challenge, specifically: Perhaps the biggest stumbling block is in the preparation of data, so this is where we will focus our attention. There are those multivariate time series forecasting problems where the output series is separate but dependent upon the input time series, and multiple time steps are required for the output series. For example, consider our multivariate time series from a prior section: We may use three prior time steps of each of the two input time series to predict two time steps of the output time series. Input: Output: The split_sequences() function below implements this behavior. We can demonstrate this on our contrived dataset. The complete example is listed below. Running the example first prints the shape of the prepared training data. We can see that the shape of the input portion of the samples is three-dimensional, comprised of six samples, with three time steps and two variables for the two input time series. The output portion of the samples is two-dimensional for the six samples and the two time steps for each sample to be predicted. The prepared samples are then printed to confirm that the data was prepared as we specified. We can now develop an MLP model for multi-step predictions using a vector output. The complete example is listed below. Running the example fits the model and predicts the next two time steps of the output sequence beyond the dataset. We would expect the next two steps to be [185, 205]. It is a challenging framing of the problem with very little data, and the arbitrarily configured version of the model gets close. A problem with parallel time series may require the prediction of multiple time steps of each time series. For example, consider our multivariate time series from a prior section: We may use the last three time steps from each of the three time series as input to the model and predict the next time steps of each of the three time series as output. The first sample in the training dataset would be the following. Input: Output: The split_sequences() function below implements this behavior. We can demonstrate this function on the small contrived dataset. The complete example is listed below. Running the example first prints the shape of the prepared training dataset. We can see that both the input (X) and output (Y) elements of the dataset are three dimensional for the number of samples, time steps, and variables or parallel time series respectively. The input and output elements of each series are then printed side by side so that we can confirm that the data was prepared as we expected. We can now develop an MLP model to make multivariate multi-step forecasts. In addition to flattening the shape of the input data, as we have in prior examples, we must also flatten the three-dimensional structure of the output data. This is because the MLP model is only capable of taking vector inputs and outputs. The complete example is listed below. Running the example fits the model and predicts the values for each of the three time steps for the next two time steps beyond the end of the dataset. We would expect the values for these series and time steps to be as follows: We can see that the model forecast gets reasonably close to the expected values. In this tutorial, you discovered how to develop a suite of Multilayer Perceptron, or MLP, models for a range of standard time series forecasting problems. Specifically, you learned: Do you have any questions?
Ask your questions in the comments below and I will do my best to answer. ¡¦with just a few lines of python code Discover how in my new Ebook:Deep Learning for Time Series Forecasting It provides self-study tutorials on topics like: CNNs, LSTMs,Multivariate Forecasting, Multi-Step Forecasting and much more¡¦ Skip the Academics. Just Results. Click to learn more. Hello  Jason, Really good intro to MLP Neural Networks, just wondering if you had any training or tutorials on the same thing but on R instead of Python? Sorry, I only have examples in Python. Comment  Name (required)  Email (will not be published) (required)  Website","Keyword(freq): step(47), sample(27), feature(8), array(7), observation(7), problem(7), variable(7), component(6), model(6), value(6)"
"4","mastery",2018-11-07,"How to Use the TimeseriesGenerator for Time Series Forecasting in Keras","https://machinelearningmastery.com/how-to-use-the-timeseriesgenerator-for-time-series-forecasting-in-keras/","Time series data must be transformed into a structure of samples with input and output components before it can be used to fit a supervised learning model. This can be challenging if you have to perform this transformation manually. The Keras deep learning library provides the TimeseriesGenerator to automatically transform both univariate and multivariate time series data into samples, ready to train deep learning models. In this tutorial, you will discover how to use the Keras TimeseriesGenerator for preparing time series data for modeling with deep learning methods. After completing this tutorial, you will know: Let¡¯s get started. How to Use the TimeseriesGenerator for Time Series Forecasting in KerasPhoto by Chris Fithall, some rights reserved. This tutorial is divided into six parts; they are: Note: This tutorial assumes that you are using Keras v2.2.4 or higher. Time series data requires preparation before it can be used to train a supervised learning model, such as a deep learning model. For example, a univariate time series is represented as a vector of observations: A supervised learning algorithm requires that data is provided as a collection of samples, where each sample has an input component (X) and an output component (y). The model will learn how to map inputs to outputs from the provided examples. A time series must be transformed into samples with input and output components. The transform both informs what the model will learn and how you intend to use the model in the future when making predictions, e.g. what is required to make a prediction (X) and what prediction is made (y). For a univariate time series interested in one-step predictions, the observations at prior time steps, so-called lag observations, are used as input and the output is the observation at the current time step. For example, the above 10-step univariate series can be expressed as a supervised learning problem with three time steps for input and one step as output, as follows: You can write code to perform this transform yourself; for example, see the post: Alternately, when you are interested in training neural network models with Keras, you can use the TimeseriesGenerator class. Take my free 7-day email crash course now (with sample code). Click to sign-up and also get a free PDF Ebook version of the course. Download Your FREE Mini-Course Keras provides the TimeseriesGenerator that can be used to automatically transform a univariate or multivariate time series dataset into a supervised learning problem. There are two parts to using the TimeseriesGenerator: defining it and using it to train models. You can create an instance of the class and specify the input and output aspects of your time series problem and it will provide an instance of a Sequence class that can then be used to iterate across the inputs and outputs of the series. In most time series prediction problems, the input and output series will be the same series. For example: Technically, the class is not a generator in the sense that it is not a Python Generator and you cannot use the next() function on it. In addition to specifying the input and output aspects of your time series problem, there are some additional parameters that you should configure; for example: You must define a length argument based on your designed framing of the problem. That is the desired number of lag observations to use as input. You must also define the batch size as the batch size of your model during training. If the number of samples in your dataset is less than your batch size, you can set the batch size in the generator and in your model to the total number of samples in your generator found via calculating its length; for example: There are also other arguments such as defining start and end offsets into your data, the sampling rate, stride, and more. You are less likely to use these features, but you can see the full API for more details. The samples are not shuffled by default. This is useful for some recurrent neural networks like LSTMs that maintain state across samples within a batch. It can benefit other neural networks, such as CNNs and MLPs, to shuffle the samples when training. Shuffling can be enabled by setting the ¡®shuffle¡® argument to True. This will have the effect of shuffling samples returned for each batch. At the time of writing, the TimeseriesGenerator is limited to one-step outputs. Multi-step time series forecasting is not supported. Once a TimeseriesGenerator instance has been defined, it can be used to train a neural network model. A model can be trained using the TimeseriesGenerator as a data generator. This can be achieved by fitting the defined model using the fit_generator() function. This function takes the generator as an argument. It also takes a steps_per_epoch argument that defines the number of samples to use in each epoch. This can be set to the length of the TimeseriesGenerator instance to use all samples in the generator. For example: Similarly, the generator can be used to evaluate a fit model by calling the evaluate_generator() function, and using a fit model to make predictions on new data with the predict_generator() function. A model fit with the data generator does not have to use the generator versions of the evaluate and predict functions. They can be used only if you wish to have the data generator prepare your data for the model. We can make the TimeseriesGenerator concrete with a worked example with a small contrived univariate time series dataset. First, let¡¯s define our dataset. We will choose to frame the problem where the last two lag observations will be used to predict the next value in the sequence. For example: For now, we will use a batch size of 1, so that we can explore the data in the generator. Next, we can see how many samples will be prepared by the data generator for this time series. Finally, we can print the input and output components of each sample, to confirm that the data was prepared as we expected. The complete example is listed below. Running the example first prints the total number of samples in the generator, which is eight. We can then see that each input array has the shape [1, 2] and each output has the shape [1,]. The observations are prepared as we expected, with two lag observations that will be used as input and the subsequent value in the sequence as the output. Now we can fit a model on this data and learn to map the input sequence to the output sequence. We will start with a simple Multilayer Perceptron, or MLP, model. The generator will be defined so that all samples will be used in each batch, given the small number of samples. We can define a simple model with one hidden layer with 50 nodes and an output layer that will make the prediction. We can then fit the model with the generator using the fit_generator() function. We only have one batch worth of data in the generator so we¡¯ll set the steps_per_epoch to 1. The model will be fit for 200 epochs. Once fit, we will make an out of sample prediction. Given the inputs [9, 10], we will make a prediction and expect the model to predict [11], or close to it. The model is not tuned; this is just an example of how to use the generator. The complete example is listed below. Running the example prepares the generator, fits the model, and makes the out of sample prediction, correctly predicting a value close to 11. We can also use the generator to fit a recurrent neural network, such as a Long Short-Term Memory network, or LSTM. The LSTM expects data input to have the shape [samples, timesteps, features], whereas the generator described so far is providing lag observations as features or the shape [samples, features]. We can reshape the univariate time series prior to preparing the generator from [10, ] to [10, 1] for 10 time steps and 1 feature; for example: The TimeseriesGenerator will then split the series into samples with the shape [batch, n_input, 1] or [8, 2, 1] for all eight samples in the generator and the two lag observations used as time steps. The complete example is listed below. Again, running the example prepares the data, fits the model, and predicts the next out of sample value in the sequence. The TimeseriesGenerator also supports multivariate time series problems. These are problems where you have multiple parallel series, with observations at the same time step in each series. We can demonstrate this with an example. First, we can contrive a dataset of two parallel series. It is a standard structure to have multivariate time series formatted such that each time series is a separate column and rows are the observations at each time step. The series we have defined are vectors, but we can convert them into columns. We can reshape each series into an array with the shape [10, 1] for the 10 time steps and 1 feature. We can now horizontally stack the columns into a dataset by calling the hstack() NumPy function. We can now provide this dataset to the TimeseriesGenerator directly. We will use the prior two observations of each series as input and the next observation of each series as output. Each sample will then be a three-dimensional array of [1, 2, 2] for the 1 sample, 2 time steps, and 2 features or parallel series. The output will be a two-dimensional series of [1, 2] for the 1 sample and 2 features. The first sample will be: The complete example is listed below. Running the example will first print the prepared dataset, followed by the total number of samples in the dataset. Next, the input and output portion of each sample is printed, confirming our intended structure. The three-dimensional structure of the samples means that the generator cannot be used directly for simple models like MLPs. This could be achieved by first flattening the time series dataset to a one-dimensional vector prior to providing it to the TimeseriesGenerator and set length to the number of steps to use as input multiplied by the number of columns in the series (n_steps * n_features). A limitation of this approach is that the generator will only allow you to predict one variable. You almost certainly may be better off writing your own function to prepare multivariate time series for an MLP than using the TimeseriesGenerator. The three-dimensional structure of the samples can be used directly by CNN and LSTM models. A complete example for multivariate time series forecasting with the TimeseriesGenerator is listed below. Running the example prepares the data, fits the model, and makes a prediction for the next value in each of the input time series, which we expect to be [110, 115]. There are multivariate time series problems where there are one or more input series and a separate output series to be forecasted that is dependent upon the input series. To make this concrete, we can contrive one example with two input time series and an output series that is the sum of the input series. Where values in the output sequence are the sum of values at the same time step in the input time series. This is different from prior examples where, given inputs, we wish to predict a value in the target time series for the next time step, not the same time step as the input. For example, we want samples like: We don¡¯t want samples like the following: Nevertheless, the TimeseriesGenerator class assumes that we are predicting the next time step and will provide data as in the second case above. For example: Running the example prints the input and output portions of the samples with the output values for the next time step rather than the current time step as we may desire for this type of problem. We can therefore modify the target series (out_seq) and insert an additional value at the beginning in order to push all observations down by one time step. This artificial shift will allow the preferred framing of the problem. The complete example with this shift is provided below. Running the example shows the preferred framing of the problem. This approach will work regardless of the length of the input sample. A benefit of neural network models over many other types of classical and machine learning models is that they can make multi-step forecasts. That is, that the model can learn to map an input pattern of one or more features to an output pattern of more than one feature. This can be used in time series forecasting to directly forecast multiple future time steps. This can be achieved either by directly outputting a vector from the model, by specifying the desired number of outputs as the number of nodes in the output layer, or it can be achieved by specialized sequence prediction models such as an encoder-decoder model. A limitation of the TimeseriesGenerator is that it does not directly support multi-step outputs. Specifically, it will not create the multiple steps that may be required in the target sequence. Nevertheless, if you prepare your target sequence to have multiple steps, it will honor and use them as the output portion of each sample. This means the onus is on you to prepare the expected output for each time step. We can demonstrate this with a simple univariate time series with two time steps in the output sequence. You can see that you must have the same number of rows in the target sequence as you do in the input sequence. In this case, we must know values beyond the values in the input sequence, or trim the input sequence to the length of the target sequence. The complete example is listed below. Running the example prints the input and output portions of the samples showing the two lag observations as input and the two steps as output in the multi-step forecasting problem. This section provides more resources on the topic if you are looking to go deeper. In this tutorial, you discovered how to use the Keras TimeseriesGenerator for preparing time series data for modeling with deep learning methods. Specifically, you learned: Do you have any questions?
Ask your questions in the comments below and I will do my best to answer. ¡¦with just a few lines of python code Discover how in my new Ebook:Deep Learning for Time Series Forecasting It provides self-study tutorials on topics like: CNNs, LSTMs,Multivariate Forecasting, Multi-Step Forecasting and much more¡¦ Skip the Academics. Just Results. Click to learn more. Hi Jason
Great tutorials.
When I run your code. The univariate one step problem with lstm.
there is an error when running model.fit Traceback (most recent call last):
  File ¡°¡±, line 2, in
  File ¡°C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\lib\site-packages\keras\legacy\interfaces.py¡±, line 91, in wrapper
    return func(*args, **kwargs)
  File ¡°C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\lib\site-packages\keras\engine\training.py¡±, line 1415, in fit_generator
    initial_epoch=initial_epoch)
  File ¡°C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\lib\site-packages\keras\engine\training_generator.py¡±, line 177, in fit_generator
    generator_output = next(output_generator)
  File ¡°C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\lib\site-packages\keras\utils\data_utils.py¡±, line 793, in get
    six.reraise(value.__class__, value, value.__traceback__)
  File ¡°C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\lib\site-packages\six.py¡±, line 693, in reraise
    raise value
  File ¡°C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\lib\site-packages\keras\utils\data_utils.py¡±, line 658, in _data_generator_task
    generator_output = next(self._generator)
TypeError: ¡®TimeseriesGenerator¡¯ object is not an iterator Something you know how to overcome? Are you able to confirm that you Keras library is up to date?  E.g. v2.2.4 or higher? Hi Jason Thank you for your fast reply.
No, I was running v2.2.2 but have updated now to 2.2.4 and it works <U+0001F642> Thank you Glad to hear it. I have added a note to the tutorial. Hi Jason,
Thanks for the tutorials, it helps me a lot.
But I still have a huge problem when I deal with my dataset. I think it¡¯s a multi-site multivariate time series forecasting dataset (the trajectory data of multiple vehicles over a period of time). I don¡¯t know how to pre-process it before using the TimeseriesGenerator.
Could you give me some advice?
Thanks a lot. Before pre-processing, perhaps start with a strong framing of the problem <U+2014> it will guide you as to how to prepare the data. Thanks for your advice. But what is a frame? Like a model? I don¡¯t quite understand. Could you give a simple example or a link?
Thank you in advance. A frame is the choice of the type of problem (classification/regression) and the choice of inputs and outputs. More here:http://machinelearningmastery.com/how-to-define-your-machine-learning-problem/ I have read another article titled ¡®A Standard Multivariate, Multi-Step, and Multi-Site Time Series Forecasting Problem¡¯ on your blog. I have some kind of understanding the framing problem.
My project is quite like the ¡®Air Quality Prediction¡¯ project. Do you think it¡¯s possible to use LSTM for the global forecasting problem? Perhaps try it and see. Great tutorial Jason. I was wondering how you could include other independent variables to forecast the output. In my case I want to forecast the air pollution for a set of measurement stations. Besides the historical pollution I also have other variables like termperature and humidity. Do you know how to deal with that? Thanks! I show how to use it for multivariate data with a dependent series, does that help? Hey, thanks for the great tutorial. I¡¯m getting an error in the multivariate case. When I insert the 0 the input and output series¡¯ aren¡¯t the same length anymore: ValueError: Data and targets have to be of same length. Data length is 10 while target length is 11 Hmmm, perhaps post to stackoverflow or Keras help:https://machinelearningmastery.com/get-help-with-keras/ Comment  Name (required)  Email (will not be published) (required)  Website","Keyword(freq): sample(27), observation(14), step(12), model(8), feature(6), file(6), output(6), input(5), thank(5), value(5)"
"5","mastery",2018-11-05,"A Gentle Introduction to LSTM Autoencoders","https://machinelearningmastery.com/lstm-autoencoders/","An LSTM Autoencoder is an implementation of an autoencoder for sequence data using an Encoder-Decoder LSTM architecture. Once fit, the encoder part of the model can be used to encode or compress sequence data that in turn may be used in data visualizations or as a feature vector input to a supervised learning model. In this post, you will discover the LSTM Autoencoder model and how to implement it in Python using Keras. After reading this post, you will know: Let¡¯s get started. A Gentle Introduction to LSTM AutoencodersPhoto by Ken Lund, some rights reserved. This post is divided into six sections; they are: An autoencoder is a neural network model that seeks to learn a compressed representation of an input. They are an unsupervised learning method, although technically, they are trained using supervised learning methods, referred to as self-supervised. They are typically trained as part of a broader model that attempts to recreate the input. For example: The design of the autoencoder model purposefully makes this challenging by restricting the architecture to a bottleneck at the midpoint of the model, from which the reconstruction of the input data is performed. There are many types of autoencoders, and their use varies, but perhaps the more common use is as a learned or automatic feature extraction model. In this case, once the model is fit, the reconstruction aspect of the model can be discarded and the model up to the point of the bottleneck can be used. The output of the model at the bottleneck is a fixed length vector that provides a compressed representation of the input data. Input data from the domain can then be provided to the model and the output of the model at the bottleneck can be used as a feature vector in a supervised learning model, for visualization, or more generally for dimensionality reduction. Sequence prediction problems are challenging, not least because the length of the input sequence can vary. This is challenging because machine learning algorithms, and neural networks in particular, are designed to work with fixed length inputs. Another challenge with sequence data is that the temporal ordering of the observations can make it challenging to extract features suitable for use as input to supervised learning models, often requiring deep expertise in the domain or in the field of signal processing. Finally, many predictive modeling problems involving sequences require a prediction that itself is also a sequence. These are called sequence-to-sequence, or seq2seq, prediction problems. You can learn more about sequence prediction problems here: Recurrent neural networks, such as the Long Short-Term Memory, or LSTM, network are specifically designed to support sequences of input data. They are capable of learning the complex dynamics within the temporal ordering of input sequences as well as use an internal memory to remember or use information across long input sequences. The LSTM network can be organized into an architecture called the Encoder-Decoder LSTM that allows the model to be used to both support variable length input sequences and to predict or output variable length output sequences. This architecture is the basis for many advances in complex sequence prediction problems such as speech recognition and text translation. In this architecture, an encoder LSTM model reads the input sequence step-by-step. After reading in the entire input sequence, the hidden state or output of this model represents an internal learned representation of the entire input sequence as a fixed-length vector. This vector is then provided as an input to the decoder model that interprets it as each step in the output sequence is generated. You can learn more about the encoder-decoder architecture here: An LSTM Autoencoder is an implementation of an autoencoder for sequence data using an Encoder-Decoder LSTM architecture. For a given dataset of sequences, an encoder-decoder LSTM is configured to read the input sequence, encode it, decode it, and recreate it. The performance of the model is evaluated based on the model¡¯s ability to recreate the input sequence. Once the model achieves a desired level of performance recreating the sequence, the decoder part of the model may be removed, leaving just the encoder model. This model can then be used to encode input sequences to a fixed-length vector. The resulting vectors can then be used in a variety of applications, not least as a compressed representation of the sequence as an input to another supervised learning model. One of the early and widely cited applications of the LSTM Autoencoder was in the 2015 paper titled ¡°Unsupervised Learning of Video Representations using LSTMs.¡± LSTM Autoencoder ModelTaken from ¡°Unsupervised Learning of Video Representations using LSTMs¡± In the paper, Nitish Srivastava, et al. describe the LSTM Autoencoder as an extension or application of the Encoder-Decoder LSTM. They use the model with video input data to both reconstruct sequences of frames of video as well as to predict frames of video, both of which are described as an unsupervised learning task. The input to the model is a sequence of vectors (image patches or features). The encoder LSTM reads in this sequence. After the last input has been read, the decoder LSTM takes over and outputs a prediction for the target sequence. <U+2014> Unsupervised Learning of Video Representations using LSTMs, 2015. More than simply using the model directly, the authors explore some interesting architecture choices that may help inform future applications of the model. They designed the model in such a way as to recreate the target sequence of video frames in reverse order, claiming that it makes the optimization problem solved by the model more tractable. The target sequence is same as the input sequence, but in reverse order. Reversing the target sequence makes the optimization easier because the model can get off the ground by looking at low range correlations. <U+2014> Unsupervised Learning of Video Representations using LSTMs, 2015. They also explore two approaches to training the decoder model, specifically a version conditioned in the previous output generated by the decoder, and another without any such conditioning. The decoder can be of two kinds <U+2013> conditional or unconditioned. A conditional decoder receives the last generated output frame as input [¡¦]. An unconditioned decoder does not receive that input. <U+2014> Unsupervised Learning of Video Representations using LSTMs, 2015. A more elaborate autoencoder model was also explored where two decoder models were used for the one encoder: one to predict the next frame in the sequence and one to reconstruct frames in the sequence, referred to as a composite model. ¡¦ reconstructing the input and predicting the future can be combined to create a composite [¡¦]. Here the encoder LSTM is asked to come up with a state from which we can both predict the next few frames as well as reconstruct the input. <U+2014> Unsupervised Learning of Video Representations using LSTMs, 2015. LSTM Autoencoder Model With Two DecodersTaken from ¡°Unsupervised Learning of Video Representations using LSTMs¡± The models were evaluated in many ways, including using encoder to seed a classifier. It appears that rather than using the output of the encoder as an input for classification, they chose to seed a standalone LSTM classifier with the weights of the encoder model directly. This is surprising given the complication of the implementation. We initialize an LSTM classifier with the weights learned by the encoder LSTM from this model. <U+2014> Unsupervised Learning of Video Representations using LSTMs, 2015. The composite model without conditioning on the decoder was found to perform the best in their experiments. The best performing model was the Composite Model that combined an autoencoder and a future predictor. The conditional variants did not give any significant improvements in terms of classification accuracy after fine-tuning, however they did give slightly lower prediction errors. <U+2014> Unsupervised Learning of Video Representations using LSTMs, 2015. Many other applications of the LSTM Autoencoder have been demonstrated, not least with sequences of text, audio data and time series. Creating an LSTM Autoencoder in Keras can be achieved by implementing an Encoder-Decoder LSTM architecture and configuring the model to recreate the input sequence. Let¡¯s look at a few examples to make this concrete. The simplest LSTM autoencoder is one that learns to reconstruct each input sequence. For these demonstrations, we will use a dataset of one sample of nine time steps and one feature: We can start-off by defining the sequence and reshaping it into the preferred shape of [samples, timesteps, features]. Next, we can define the encoder-decoder LSTM architecture that expects input sequences with nine time steps and one feature and outputs a sequence with nine time steps and one feature. Next, we can fit the model on our contrived dataset. The complete example is listed below. The configuration of the model, such as the number of units and training epochs, was completely arbitrary. Running the example fits the autoencoder and prints the reconstructed input sequence. The results are close enough, with very minor rounding errors. A plot of the architecture is created for reference. LSTM Autoencoder for Sequence Reconstruction We can modify the reconstruction LSTM Autoencoder to instead predict the next step in the sequence. In the case of our small contrived problem, we expect the output to be the sequence: This means that the model will expect each input sequence to have nine time steps and the output sequence to have eight time steps. The complete example is listed below. Running the example prints the output sequence that predicts the next time step for each input time step. We can see that the model is accurate, barring some minor rounding errors. A plot of the architecture is created for reference. LSTM Autoencoder for Sequence Prediction Finally, we can create a composite LSTM Autoencoder that has a single encoder and two decoders, one for reconstruction and one for prediction. We can implement this multi-output model in Keras using the functional API. You can learn more about the functional API in this post: First, the encoder is defined. Then the first decoder that is used for reconstruction. Then the second decoder that is used for prediction. We then tie the whole model together. The complete example is listed below. Running the example both reconstructs and predicts the output sequence, using both decoders. A plot of the architecture is created for reference. Composite LSTM Autoencoder for Sequence Reconstruction and Prediction Regardless of the method chosen (reconstruction, prediction, or composite), once the autoencoder has been fit, the decoder can be removed and the encoder can be kept as a standalone model. The encoder can then be used to transform input sequences to a fixed length encoded vector. We can do this by creating a new model that has the same inputs as our original model, and outputs directly from the end of encoder model, before the RepeatVector layer. A complete example of doing this with the reconstruction LSTM autoencoder is listed below. Running the example creates a standalone encoder model that could be used or saved for later use. We demonstrate the encoder by predicting the sequence and getting back the 100 element output of the encoder. Obviously, this is overkill for our tiny nine-step input sequence. A plot of the architecture is created for reference. Standalone Encoder LSTM Model This section provides more resources on the topic if you are looking to go deeper. In this post, you discovered the LSTM Autoencoder model and how to implement it in Python using Keras. Specifically, you learned: Do you have any questions?
Ask your questions in the comments below and I will do my best to answer. ¡¦with just a few lines of python code Discover how in my new Ebook:Long Short-Term Memory Networks with Python It provides self-study tutorials on topics like:CNN LSTMs, Encoder-Decoder LSTMs, generative models, data preparation, making predictions and much more¡¦ Skip the Academics. Just Results. Click to learn more. Nice Explained¡¦¡¦¡¦. Thanks. Thanks for the great posts! I have learn a lot from them.
Can this approach for classification problems such as sentiment analysis? Perhaps. Hi Jason,
Thanks for the posts, I really enjoy reading this.
I¡¯m trying to use this method to do time series data anomaly detection and I got few questions here:
When you reshape the sequence into [samples, timesteps, features], samples and features always equal to 1. What is the guidance to choose the value here? If the input sequences have variable length, how to set timesteps, always choose max length? Also, if the input is two dimension tabular data with each row has different length, how will you do the reshape or normalization?
Thanks in advance! The time steps should provide enough history to make a prediction, the features are the observations recorded at each time step. More on preparing data for LSTMs here:https://machinelearningmastery.com/faq/single-faq/how-do-i-prepare-my-data-for-an-lstm Hi, I am wondering why the output of encoder has a much higher dimension(100), since we usually use encoders to create lower dimensions! Could you please bring examples if I am wrong? And what about variable length of samples? You keep saying that LSTM is useful for variable length. So how does it deal with a training set like: dataX[0] = [1,2,3,4]
dataX[1] = [2,5,7,8,4]
dataX[2] = [0,3] I am really confused with my second question and I¡¯d be very thankful for your help! <U+0001F642> The model reproduces the output, e.g. a 1D vector with 9 elements. You can pad the variable length inputs with 0 and use a masking layer to ignore the padded values. I really likes your posts and they are important.I got a lot of knowledge from your post.
Today, am going to ask your help. I am doing research on local music classifications. the key features of the music is it sequence and it uses five keys out of the seven keys, we call it scale. 1.  C <U+2013> E <U+2013> F <U+2013> G <U+2013> B. This is a major 3rd, minor 2nd, major 2nd, major 3rd, and minor 2nd
2.  C <U+2013> Db <U+2013> F <U+2013> G <U+2013> Ab. This is a minor 2nd, major 3rd, major 2nd, minor 2nd, and major 3rd.
3.  C <U+2013> Db <U+2013> F <U+2013> Gb <U+2013> A. This is a minor 2nd, major 3rd, minor 2nd, minor 3rd, and a minor 3rd.
4.  C <U+2013> D <U+2013> E <U+2013> G <U+2013> A. This is a major 2nd, major 2nd, minor 3rd, major 2nd, and a minor 3rd
it is not dependent on range, rythm, melody and other features. This key has to be in order. Otherwise it will be out of scale. So, which tools /algorithm do i need to use for my research purpose and also any sampling mechanism to take 30 sec sample music from each track without affecting the sequence of the keys ? Regards Perhaps try a suite of models and discover what works best for your specific dataset. More here:https://machinelearningmastery.com/faq/single-faq/what-algorithm-config-should-i-use Hi, can you please explain the use of repeat vector between encoder and decoder?
Encoder is encoding 1-feature time-series into fixed length 100 vector. In my understanding, decoder should take this 100-length vector and transform it into 1-feature time-series.
So, encoder is like many-to-one lstm, and decoder is one-to-many (even though that ¡®one¡¯ is a vector of length 100). Is this understanding correct? The RepeatVector repeats the internal representation of the input n times for the number of required output steps. Which model is most suited for stock market prediction None, a time series of prices is a random walk as far as I¡¯ve read. More here:https://machinelearningmastery.com/faq/single-faq/can-you-help-me-with-machine-learning-for-finance-or-the-stock-market Hi, thanks for the instructive post! I am trying to repeat your first example (Reconstruction LSTM Autoencoder) using a different syntax of Keras; here is the code: import numpy as np
from keras.layers import Input, LSTM, RepeatVector
from keras.models import Model timesteps = 9
input_dim = 1
latent_dim = 100 # input placeholder
inputs = Input(shape=(timesteps, input_dim)) # ¡°encoded¡± is the encoded representation of the input
encoded = LSTM(latent_dim,activation=¡¯relu¡¯)(inputs) # ¡°decoded¡± is the lossy reconstruction of the input
decoded = RepeatVector(timesteps)(encoded)
decoded = LSTM(input_dim, activation=¡¯relu¡¯, return_sequences=True)(decoded) sequence_autoencoder = Model(inputs, decoded)
encoder = Model(inputs, encoded) # compile model
sequence_autoencoder.compile(optimizer=¡¯adadelta¡¯, loss=¡¯mse¡¯) # run model
sequence_autoencoder.fit(sequence,sequence,epochs=300, verbose=0) # prediction
sequence_autoencoder.predict(sequence,verbose=0) I did not know why, but I always get a poor result than the model using your code.
So my question is: is there any difference between the two method (syntax) under the hood? or they are actually the same ? Thanks. Comment  Name (required)  Email (will not be published) (required)  Website","Keyword(freq): sequence(13), lstm(12), representation(9), feature(7), model(7), step(7), problem(6), thank(6), frame(5), kera(5)"
"6","vidhya",2018-11-08,"Want to Become a Data Engineer? Here¡¯s a Comprehensive List of Resources to get Started","https://www.analyticsvidhya.com/blog/2018/11/data-engineer-comprehensive-list-resources-get-started/","Before a model is built, before the data is cleaned and made ready for exploration, even before the role of a data scientist begins <U+2013> this is where data engineers come into the picture. Every data-driven business needs to have a framework in place for the data science pipeline, otherwise it¡¯s a setup for failure. Most people enter the data science world with the aim of becoming a data scientist, without ever realizing what a data engineer is, or what that role entails. These data engineers are vital parts of any data science project and their demand in the industry is growing exponentially in the current data-rich environment. There is currently no coherent or formal path available for data engineers. Most folks in this role got there by learning on the job, rather than following a detailed route. My aim for writing this article was to help anyone who wants to become a data engineer but doesn¡¯t know where to start and where to find study resources. In this article, I have put together a list of things every aspiring data engineer needs to know. Initially we¡¯ll see what a data engineer is and how the role differs from a data scientist. Then, we¡¯ll move on to the core skills you should have in your skillset before being considered a good fit for the role. I have also mentioned some industry recognized certifications you should consider. Right, let¡¯s dive right into it. A data engineer is responsible for building and maintaining the data architecture of a data science project. These engineers have to ensure that there is uninterrupted flow of data between servers and applications. Some of the responsibilities of a data engineer include improving data foundational procedures, integrating new data management technologies and softwares into the existing system, building data collection pipelines, among various other things. One of the most sought-after skills in data engineering is the ability to design and build data warehouses. This is where all the raw data is collected, stored and retrieved from. Without data warehouses, all the tasks that a data scientist does will become either too expensive or too large to scale. ETL (Extract, Transform, and Load) are the steps which a data engineer follows to build the data pipelines. ETL is essentially a blueprint for how the collected raw data is processed and transformed into data ready for analysis. Data engineers usually come from engineering backgrounds. Unlike data scientists, there is not much academic or scientific understanding required for this role. Developers or engineers who are interested in building large scale structures and architectures are ideally suited to thrive in this role. It is important to know the distinction between these 2 roles. Broadly speaking, a data scientist builds models using a combination of statistics, mathematics, machine learning and domain based knowledge. He/she has to code and build these models using the same tools/languages and framework that the organization supports. A data engineer on the other hand has to build and maintain data structures and architectures for data ingestion, processing, and deployment for large-scale data-intensive applications. To build a pipeline for data collection and storage, to funnel the data to the data scientists, to put the model into production <U+2013> these are just some of the tasks a data engineer has to perform. For any large scale data science project to succeed, data scientists and data engineers need to work hand-in-hand. Otherwise things can go wrong very quickly! To learn more about the difference between these 2 roles, head over to our detailed infographic here. It¡¯s essential to first understand what data engineering actually is, before diving into the different facets of the role. What are the different functions a data engineer performs day-to-day? What do the top technology companies look for in a data engineer? Are you expected to know just about everything under the sun or just enough to be a good fit for a specific role? My aim is to provide you an answer to these questions (and more) in the resources below. A Beginner¡¯s Guide to Data Engineering (Part 1): A very popular post on data engineering from a data scientist at Airbnb. The author first explains why data engineering is such a critical aspect of any machine learning project, and then deep dives into the various component of this subject. I consider this a compulsory read for all aspiring data engineers AND data scientists. A Beginner¡¯s Guide to Data Engineering (Part 2): Continuing on from the above post, part 2 looks at data modeling, data partitioning, Airflow, and best practices for ETL. A Beginner¡¯s Guide to Data Engineering (Part 3): The final part of this amazing series looks at the concept of a data engineering framework. Throughout the series, the author keeps relating the theory to practical concepts at Airbnb, and that trend continues here. A truly exquisitely written series of articles. O¡¯Reilly¡¯s Suite of Free Data Engineering E-Books:<U+00A0>O¡¯Reilly is known for their excellent books, and this collection is no exception to that. Except, these books are free! Scroll down to the ¡®Big Data Architecture¡¯ section and check out the books there. Some of these require a bit of knowledge regarding Big Data infrastructure, but these books will help you get acquainted with the intricacies of data engineering tasks. While there are other data engineering-specific programming languages out there (like Java and Scala), we¡¯ll be focusing on Python in this article. We have seen a clear shift in the industry towards Python and is seeing a rapid adoption rate. It¡¯s become an essential part of a data engineer¡¯s (and a data scientist¡¯s) skillset. There are tons of resources online to learn Python. I have mentioned a few of them below. A complete tutorial to learn Data Science with Python from Scratch: This article by Kunal Jain covers a list of resources you can use to begin and advance your Python journey. A must-read resource. Introduction to Data Science using Python: This is Analytics Vidhya¡¯s most popular course that covers the basics of Python. We additionally cover core statistics concepts and predictive modeling methods to solidify your grasp on Python and basic data science. Codeacademy¡¯s Learn Python course: This course assumes no prior knowledge of programming. It starts from the absolute basics of Python and is a good starting point. If you prefer learning through books, below are a couple of free ebooks to get you started: Think Python by Allen Downey:<U+00A0>A comprehensive go-through of the Python language. Perfect for newcomers and even non-programmers. Non-Programmer¡¯s Tutorial for Python 3:<U+00A0>As the name suggests, it¡¯s a perfect starting point for folks coming from a non-IT background or a non-technical background. There are plenty of examples in each chapter to test your knowledge. A key cog in the entire data science machine, operating systems are what make the pipelines tick. A data engineer is expected to know the ins and outs of infrastructure components, such as virtual machines, networks, applications services, etc. How well versed are you with server management? Do you know Linux well enough to navigate around different configurations? How familiar are you with access control methods? These are just some of the questions you¡¯ll face as a data engineer. Linux Server Management and Security: This Coursera offering is designed for folks looking to understand how Linux works in the enterprise. The course is divided into 4 weeks (and a project at the end) and covers the basics well enough. CS401: Operating Systems: As comprehensive a course as any around operating systems. This contains nine sections dedicated to different aspects of an operating system. The primary focus is on UNIX-based systems, though Windows is covered as well. Raspberry Pi Platform and Python Programming for the Raspberry Pi: A niche topic, for sure, but the demand for this one is off the charts these days. This course aims to make you familiar with the Raspberry Pi environment and get you started with basic Python code on the Raspberry Pi. In order to become a data engineer, you need to have a very strong grasp on database languages and tools. This is another very basic requirement. You need to be able to collect, store and query information from these databases in real-time. There are tons of databases available today but I have listed down resources for the ones that are currently widely used in the industry today. These are divided into SQL and NoSQL databases. Source: MacWorld UK Learn SQL for Free: Another codeacademy entry, you can learn the absolute basics of SQL here. Topics like manipulation, queries, aggregate functions and multiple tables are covered from the ground up. If you¡¯re completely new to this field, not many places better than this to kick things off. Quick SQL Cheatsheet: An ultra helpful GitHub repository with regularly updated SQL queries and examples. Ensure you star/bookmark this repository as a reference point anytime you quickly need to check a command. MySQL Tutorial: MySQL was created over two decades ago, and still remains a popular choice in the industry. This resource is a text-based tutorial, presented in an easy-to-follow manner. The cool thing about this site is that practical examples with SQL scripts (and screenshots) accompany each topic. Learn Microsoft SQL Server: This text tutorial explores SQL Server concepts starting from the basics to more advanced topics. Concepts have been explained using codes and detailed screenshots. PostgreSQL Tutorial: An incredible detailed guide to get you started and well acquainted with PostgreSQL. The tutorial has been divided into 16 sections so you can imagine how well this subject has been covered. Oracle Live SQL: Who better to learn Oracle¡¯s SQL database than the creators themselves? The platform is really well designed and makes for a great end user experience. You can view scripts and tutorials to get your feet wet, and then start coding on the same platform. Sounds awesome! Source: Eventil MongoDB from MongoDB: This is currently the most popular NoSQL Database out there. And as with the Oracle training mentioned above, MongoDB is best learned from the masters themselves. I have linked their entire course catalogue here, so you can pick and choose which trainings you want to take. Introduction to MongoDB:<U+00A0>This course will get you up and running with MongoDB quickly, and teach you how to leverage its power for data analytics. It¡¯s a short three weeks course but has plenty of exercises to make you feel like an expert by the time you¡¯re finished! Learn Cassandra: If you¡¯re looking for an excellent text-based and beginner-friendly introduction to Cassandra, this is the perfect resource. Topics like Cassandra¡¯s architecture, installation, key operations, etc. are covered here. The tutorial also has dedicated chapters to explain the data types and collections available in CQL and how to make use of user-defined data types. Redis Enterprise: There are not many resources out there to learn about Redis Databases, but this one site is enough. There are multiple courses and beautifully designed videos to make the learning experience engaging and interactive. And it¡¯s free! Google Bigtable: Being Google¡¯s offering, there are surprisingly sparse resources available to learn how Bigtable works. I have linked a Coursera course that includes plenty of Google Cloud topics but you can scroll down and select Bigtable (or BigQuery). I would, however, recommend going through the full course as it provides valuable insights into how Google¡¯s entire Cloud offerings work. Couchbase: Multiple trainings are available here (scroll down to see the free trainings), and they range from beginner to advanced. If Couchbase is your organization¡¯s database of choice, this is where you¡¯ll learn everything about it. Distributed file systems like Hadoop (HDFS) can be found in any data engineer job description these days. It¡¯s a common role requirement and one you should be familiar with intimately. Apart from that, you need to gain an understanding of platforms and frameworks like Apache Spark, Hive, PIG, Kafka, etc. I have listed the resources for all these topics in this section. Hadoop Fundamentals: This is essentially a learning path for Hadoop. It includes 5 courses that will give you a solid understanding of what Hadoop is, the architecture and components that define it, how to use it, it¡¯s applications and a whole lot more. Hadoop Starter Kit: This is a really good and comprehensive free course for anyone looking to get started with Hadoop. It includes topics like HDFS, MapReduce, Pig and HIVE with free access to clusters for practising what you¡¯ve learned. Hortonworks Tutorials: As the creators of Hadoop, Hortonworks have a well respected set of courses for learning various things related to Hadoop. From beginners to advanced, this page has a very comprehensive list of tutorials. Ensure you check this out. Introduction to MapReduce: Before reading this article, you need to have some basic knowledge of how Hadoop works. Once done, come back and take a deep dive into the world of MapReduce. Hadoop Beyond Traditional MapReduce <U+2013> Simplified: This article covers an overview of the Hadoop ecosystem that goes beyond simply MapReduce. Prefer books? No worries, I have you covered! Below are a few free ebooks that cover Hadoop and it¡¯s components. Hadoop Explained: A basic introduction to the complicated world of Hadoop. It gives a high-level overview of how Hadoop works, it¡¯s advantages, applications in real-life scenarios, among other things. Hadoop: What you Need to Know: This one is on similar lines to the above book. As the description says, the books covers just about enough to ensure you can make informed and intelligent decisions about Hadoop. Data-Intensive Text Processing with MapReduce:<U+00A0>This free ebook covers the basics of MapReduce, its algorithm design, and then deep dives into examples and applications you should know about. It¡¯s recommended that you take the above courses first before reading this book. You should also join the Hadoop LinkedIn group to keep yourself up-to-date and to ask any queries you might have. Comprehensive Guide to Apache Spark, RDDs and Dataframes (using PySpark): This is the ultimate article to get you stared with Apache Spark. It covers the history of Apache Spark, how to install it using Python, RDD/Dataframes/Datasets and then rounds-up by solving a machine learning problem. A must-read guide. Step by Step Guide for Beginners to Learn SparkR: In case you are a R user, this one is for you! You can of course use Spark with R and this article will be your guide. Spark Fundamentals: This course covers the basics of Spark, it¡¯s components, how to work with them, interactive examples of using Spark, introduction to various Spark libraries and finally understanding the Spark cluster. What more could you ask for from one course? Introduction to Apache Spark and AWS: This is a practical and practice focused course. You will work with the Gutenberg Project data, the world¡¯s largest open collection of ebooks. You will need knowledge of Python and the Unix command line to extract the most out of this course. Big Data Essentials: HDFS, MapReduce and Spark RDD: This course takes real-life datasets to teach you basic Big Data technologies <U+2013> HDFS, MapReduce and Spark. It¡¯s a typical Coursera course <U+2013> detailed, filled with examples and useful datasets, and taught by excellent instructors. Big Data Analysis: Hive, Spark SQL, DataFrames and GraphFrames: MapReduce and Spark tackle the issue of working with Big Data partially. Learn high-level tools with this intuitive course where you¡¯ll master your knowledge of Hive and Spark SQL, among other things. Big Data Applications: Real-Time Streaming:<U+00A0>One of the challenges of working with enourmous amounts of data is not just the computational power to process it, but to do so as quickly as possible. Applications like recommendation engines require real-time data processing and to store and query this amount of data requires knowledge of systems like Kafka, Cassandra and Redis, which this course provides.<U+00A0>But to take this course, you need a working knowledge of Hadoop, Hive, Python, Spark and Spark SQL. Simplifying Data Pipelines with Apache Kafka:<U+00A0>Get the low down on what Apache Kafka is, its architecture and how to use it. You need a basic understanding of Hadoop, Spark and Python to truly gain the most from this course. Kafka¡¯s Official Documentation: This is an excellent intuitive introduction to how Kafka works and the various components that go toward making it work. This page also includes a nice explanation of what a distributed streaming platform is. Putting the Power of Kafka into the Hands of Data Scientists:<U+00A0>Not quite a learning resource per se, but a very interesting and detailed article on how data engineers at Stitch Fix built a platform tailored to the requirements of their data scientists. While machine learning is primarily considered the domain of a data scientist, a data engineer needs to be well versed with certain techniques as well. Why, you ask? Getting models into production and making pipelines for data collection or generation need to be streamlined, and these require at least a basic understanding of machine learning algorithms. Machine Learning Basics for a Newbie: A superb introduction to the world of machine learning by Kunal Jain. The aim of the article is to do away with all the jargon you¡¯ve heard or read about. The guide cuts straight to heart of the matter, and you end up appreciating that style of writing. Essentials of Machine Learning Algorithms: This is an excellent article that provides a high-level understanding of various machine learning algorithms. It includes an implementation of these techniques in R and Python as well <U+2013> a perfect place to start your journey. Must-Read Books for Beginners on Machine Learning and Artificial Intelligence:<U+00A0>If books are more to your taste, then check out this article! This is a collection of the best of the best, so even if you read only a few of these books, you¡¯ll have gone a long way towards your dream career. 24 Ultimate Data Science Projects to Boost your Knowledge and Skills: Once you¡¯ve acquired a certain amount of knowledge and skill, it¡¯s always highly recommended to put your theoretical knowledge into practice. Check out these datasets, ranked in order of their difficulty, and get your hands dirty. Google¡¯s Certified Professional Source: Fourcast.io This is one of the premier data engineering certifications available today. To earn this certification, you need to successfully clear a challenging 2 hour multiple choice exam. You can find the general outline of what to expect on this link. Also available are links to get hands-on practice with Google Cloud technologies. Ensure you check this out! IBM Certified Data Engineer To attain this certification, you need to pass one exam <U+2013> this one. The exam contains 54 questions out of which you have to answer 44 correctly. I recommend going through what IBM expects you to know before you sit for the exam. The exam link also contains further links to study materials you can refer to for preparing yourself. Cloudera¡¯s CCP Data Engineer This is another globally recognized certification, and a pretty challenging one for a newcomer. Your concepts need to be up-to-date and in-depth, you should have some hands-on experience with data engineering tools like Hadoop, Oozie, AWS Sandbox, etc. But if you clear this exam, you are looking at a very promising start to this field of work! Cloudera has mentioned that it would help if you took their training for Apache Spark and Hadoop since the exam is heavily based on these two tools. Becoming a data engineer is no easy feat, as you¡¯ll have gathered from all the above resources. It requires a deep understanding of tools, techniques and a solid work ethic to become one. This role is in huge demand in the industry thanks to the recent data boom and will continue to be a rewarding career option for anyone willing to take it. Once you go through this path, you will be gunning for the data engineer role! Let me know your feedback and suggestions about this set of resources in the comments section below. Super!!! Glad you liked the article, Jingmiao Shen! Very Detailed and well explained Article.. Thanks","Keyword(freq): book(11), engineer(10), resource(10), application(8), basic(8), scientist(7), example(6), system(6), topic(6), component(5)"
"7","vidhya",2018-11-04,"A Practical Implementation of the Faster R-CNN Algorithm for Object Detection (Part 2 <U+2013> with Python codes)","https://www.analyticsvidhya.com/blog/2018/11/implementation-faster-r-cnn-python-object-detection/","Which algorithm do you use for object detection tasks? I have tried out quite a few of them in my quest to build the most precise model in the least amount of time. And this journey, spanning multiple hackathons and real-world datasets, has usually always led me to the R-CNN family of algorithms. It has been an incredible useful framework for me, and that¡¯s why I decided to pen down my learnings in the form of a series of articles. The aim behind this series is to showcase how useful the different types of R-CNN algorithms are. The first part received an overwhelmingly positive response from our community, and I¡¯m thrilled to present part two! In this article, we will first briefly summarize what we learned in part 1, and then deep dive into the implementation of the fastest member of the R-CNN family <U+2013> Faster R-CNN. I highly recommend going through this article if you need to refresh your object detection concepts first:<U+00A0>A Step-by-Step Introduction to the Basic Object Detection Algorithms (Part 1). We will work on a very interesting dataset here, so let¡¯s dive right in! Let¡¯s quickly summarize the different algorithms in the R-CNN family (R-CNN, Fast R-CNN, and Faster R-CNN) that we saw in the first article. This will help lay the ground for our implementation part later when we will predict the bounding boxes present in previously unseen images (new data). R-CNN extracts a bunch of regions from the given image using selective search, and then checks if any of these boxes contains an object. We first extract these regions, and for each region, CNN is used to extract specific features. Finally, these features are then used to detect objects. Unfortunately, R-CNN becomes rather slow due to these multiple steps involved in the process. R-CNN Fast R-CNN, on the other hand, passes the entire image to ConvNet which generates regions of interest (instead of passing the extracted regions from the image). Also, instead of using three different models (as we saw in R-CNN), it uses a single model which extracts features from the regions, classifies them into different classes, and returns the bounding boxes. All these steps are done simultaneously, thus making it execute faster as compared to R-CNN. Fast R-CNN is, however, not fast enough when applied on a large dataset as it also uses selective search for extracting the regions. Fast R-CNN Faster R-CNN fixes the problem of selective search by replacing it with Region Proposal Network (RPN). We first extract feature maps from the input image using ConvNet and then pass those maps through a RPN which returns object proposals. Finally, these maps are classified and the bounding boxes are predicted. Faster R-CNN I have summarized below the steps followed by a Faster R-CNN algorithm to detect objects in an image: What better way to compare these different algorithms than in a tabular format? So here you go! Now that we have a grasp on this topic, it¡¯s time to jump from the theory into the practical part of our article. Let¡¯s implement Faster R-CNN using a really cool (and rather useful) dataset with potential real-life applications! We will be working on a healthcare related dataset and the aim here is to solve a Blood Cell Detection problem. Our task is to detect all the Red Blood Cells (RBCs), White Blood Cells (WBCs), and Platelets in each image taken via microscopic image readings. Below is a sample of what our final predictions should look like: The reason for choosing this dataset is that the density of RBCs, WBCs and Platelets in our blood stream provides a lot of information about the immune system and hemoglobin. This can help us potentially identify whether a person is healthy or not, and if any discrepancy is found in their blood, actions can be taken quickly to diagnose that. Manually looking at the sample via a microscope is a tedious process. And this is where Deep Learning models play such a vital role. They can classify and detect the blood cells from microscopic images with impressive precision. The full blood cell detection dataset for our challenge can be downloaded from here. I have modified the data a tiny bit for the scope of this article: Note that we will be using the popular Keras framework with a TensorFlow backend in Python to train and build our model. Before we actually get into the model building phase, we need to ensure that the right libraries and frameworks have been installed. The below libraries are required to run this project: Most of the above mentioned libraries will already be present on your machine if you have Anaconda and Jupyter Notebooks installed. Additionally, I recommend<U+00A0>downloading the requirement.txt file from this link and use that to install the remaining libraries. Type the following command in the terminal to do this: Alright, our system is now set and we can move on to working with the data! It¡¯s always a good idea (and frankly, a mandatory step) to first explore the data we have. This helps us not only unearth hidden patterns, but gain a valuable overall insight into what we are working with. The three files I have created out of the entire dataset are: Let¡¯s read the .csv file (you can create your own .csv file from the original dataset if you feel like experimenting) and print out the first few rows. We¡¯ll need to first import the below libraries for this: There are 6 columns in the train file. Let¡¯s understand what each column represents: Let¡¯s now print an image to visualize what we¡¯re working with: This is what a blood cell image looks like. Here, the blue part represents the WBCs, and the slightly red parts represent the RBCs. Let¡¯s look at how many images, and the different type of classes, there are in our training set. So, we have 254 training images. We have three different classes of cells, i.e., RBC, WBC and Platelets. Finally, let¡¯s look at how an image with detected objects will look like: This is what a training example looks like. We have the different classes and their corresponding bounding boxes. Let¡¯s now train our model on these images. We will be using the keras_frcnn library to train our model as well as to get predictions on the test images. For implementing the Faster R-CNN algorithm, we will be following the steps mentioned in<U+00A0>this Github repository. So as the first step, make sure you clone this repository. Open a new terminal window and type the following to do this: Move the train_images and test_images folder, as well as the train.csv file, to the cloned repository. In order to train the model on a new dataset, the format of the input should be: where, We need to convert the .csv format into a .txt file which will have the same format as described above. Make a new dataframe, fill all the values as per the format into that dataframe, and then save it as a .txt file. What¡¯s next? Train our model! We will be using the train_frcnn.py file to train the model. It will take a while to train the model due to the size of the data. If possible, you can use a GPU to make the training phase faster. You can also try to reduce the number of epochs as an alternate option. To change the number of epochs, go to the train_frcnn.py file in the cloned repository and change the num_epochs<U+00A0>parameter accordingly. Every time the model sees an improvement, the weights of that particular epoch will be saved in the same directory as ¡°model_frcnn.hdf5¡±. These weights will be used when we make predictions on the test set. It might take a lot of time to train the model and get the weights, depending on the configuration of your machine. I suggest using the weights I¡¯ve got after training the model for around 500 epochs. You can download these weights<U+00A0>from here. Ensure you save these weights in the cloned repository. So our model has been trained and the weights are set. It¡¯s prediction time! Keras_frcnn makes the predictions for the new images and saves them in a new folder.<U+00A0>We just have to make two changes in the test_frcnn.py file to save the images: Let¡¯s make the predictions for the new images: Finally, the images with the detected objects will be saved in the ¡°results_imgs¡± folder. Below are a few examples of the predictions I got after implementing Faster R-CNN: Result 1 Result 2 Result 3 Result 4 R-CNN algorithms have truly been a game-changer for object detection tasks. There has suddenly been a spike in recent years in the amount of computer vision applications being created, and R-CNN is at the heart of most of them. Keras_frcnn proved to be an excellent library for object detection, and in the next article of this series, we will focus on more advanced techniques like YOLO, SSD, etc. If you have any query or suggestions regarding what we covered here, feel free to post them in the comments section below and I will be happy to connect with you! Thanks for article.
Most of object detection algorithms fail if size of object to be detected is very small and with varying size. For example detection of small cracks on metal surface. What is your view on this? Any advice and best possible approach? Hi, I believe Faster RCNN works good enough for small objects as well. Currently, I am working on YOLO and SSD and will share my learnings on how they deal with small objects. Hey Pulkit,  I am a Freshman at UIUC studying CS and one of my projects is in the same domain. Would it be possible to connect with you and talk more about this? Hi Vishnu, You can ask any query related to this project here. I will try my best to respond to them. The dataset that you have provided, it doesn¡¯t correspond with your example. Can you provide the right source? Hi Toni, The original dataset is available on GitHub, link for the same is provided in the article. I have made some changes in that dataset and have mentioned the changes as well. You just have to convert the dataset in csv format. Can you please provide the code to do that? Thank you","Keyword(freq): image(10), algorithm(7), object(6), prediction(6), region(6), weight(6), box(5), library(5), cell(4), step(4)"
