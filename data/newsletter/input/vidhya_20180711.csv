"site","date","headline","url_address","text"
"vidhya",2018-07-09,"DataHack Radio #4 <U+2013> Data Privacy, Women in Data Science and More with Carla Gentry","https://www.analyticsvidhya.com/blog/2018/07/datahack-radio-episode-4-carla-gentry/","Carla Gentry is one of most popular social media influencers in the data science field. She has over 300,000 followers on LinkedIn and 48k followers on Twitter. Her experience in this field is unparalleled and we are grateful for leaders like her who consistently give back to the community. She has been a regular reader of Analytics Vidhya¡¯s articles for quite a while now. It was a pleasure to have her appear on the podcast and to hear her views on data privacy, how the domain has changed in the last few years, her advice for women in data science, and a whole host of other topics. This article contains highlights of Carla¡¯s conversation with Kunal Jain. You can listen to the podcast by clicking on the above SoundCloud link or on our iTunes channel. Happy listening! You can subscribe to DataHack Radio and listen to this, and all previous episodes, on any of the below platforms: Carla holds a number of degrees including one in advanced economics, one in advanced mathematics, among others. Right after college she got an internship at one of the few econometrics firms in the United States. There she worked with terabytes of data (this was well before ¡®Big Data¡¯ was a buzzword). Her experience started with tools and platforms like SAS, Pico, etc. Her role was working with credit card data but the nature of the work was such that it became monotonous after a while. From there, she moved to the Weinstein Organization as a Senior Analyst and Data Specialist. Here Carla¡¯s role expanded to include direct marketing experience. This was followed by a year at the University of Chicago Booth School of Business as a Research Support Analyst where she taught Ph.D students how to work with data, how to do data mining, etc. Carla then moved on to work as the Marketing Information Manager at Career Education Corporation for the next 4 years. Post that she spent the next 3.5 years in the marketing and data field at PromoWorks, Tandus and Area203. She is now the owner and data scientist at Analytical Solution, where she has worked with clients like Kellogg, Johnson & Johnson, among various other organizations. Carla considers data mining a critical aspect in any data driven project. It helps you understand trends, see patterns, interpret reasons why a person was denied a loan or credit card, etc. It¡¯s at the core of the business and should be respected as such. But she stressed on the importance of privacy and the need to be clear with your clients and customers about where you are going to use their data, for what purposes, and how it might impact them (if at all). GDPR has of course changed the game in Europe with regards to being transparent with users but Carla feels everyone, regardless of laws, should have this as a best practice. With the amount of data that¡¯s being generated in the world, from websites to social media, it¡¯s critical to have that level of sensitivity. Data scientists have a responsibility to be unbiased, have integrity and use their experience to add a positive background to the dataset, rather than let their feelings cloud the model building exercise. Carla recalled that if a business had terabytes of data in the 90s, running a program on that was next to impossible because the mainframe would have crashed. Now a mainframe isn¡¯t even required! If you have a good database architecture set up, you can access millions and billions of rows in a fraction of the time it used to take previously. COBOL, PASCAL, C++, SAS, Mathematica, MATLAB <U+2013> these were the only programs available back when Carla started her journey. Of course now we have much more robust tools like R, Visual Studio (SQL), IBM¡¯s suite of tools, etc. One of the biggest reasons why the older programs have been phased out is because of their inability to handle gigantic datasets, which the new tools can. Of course with the rise of this data wave, and the advent of the digital era, the number of hackers and cyber thieves has also risen. So as things have gotten better in many ways, they have also gotten worse when it comes to security of your data. Carla expects more laws like GDPR to come to action in the next few years that will dictate how organizations collect and deal with your data. She has a warning for businesses that abuse data <U+2013> people will leave and look for ways to go incognito, which will leave your business with no data at all. ¡°We have got to get rid of the thinking that it¡¯s always been this way, so it should stay that way.¡± Carla is a champion of women in data science. She strongly believes that in order to incorporate more females into this field, the change has to start from the top. The CEO should have an obligation to encourage diversity into the organization by going to the HR department and digging deeper to understand the percentage of women in the company, and how to further improve upon that. Her advice to aspiring female data scientists was to the point <U+2013> stand your ground, be confident in yourself, find mentors, keep going and keep learning. You will find the perfect fit for you as long as you continue to believe in yourself and your abilities. Carla is an avid social media user and a HUGE influencer, especially in the data science field. It¡¯s very time consuming (2-3 hours per day at times) but if what she shares helps even one person, she definitely considers it worth that investment. She feels it¡¯s her responsibility to give back to the community, given that she has gotten so much from it over the years. There are some awesome rapid fire questions at the end of the podcast <U+2013> ensure you listen to those as well! *P.S. <U+2013> All views expressed by the guests on DataHack Radio are their own, and not of Analytics Vidhya."
"vidhya",2018-07-05,"Learn and Test your Machine Learning Skills with AV¡¯s New Practice Problems and Free Courses!","https://www.analyticsvidhya.com/blog/2018/07/learn-and-test-your-machine-learning-skills-with-avs-new-practice-problems-and-free-courses/","¡°Knowledge is of no value unless you put it into practice.¡± <U+2013> Anton Chekhov Gaining knowledge of new concepts is a critical aspect of data science and machine learning. But the real gold lies in putting these concepts into practice. The more you practice, the better your concepts become! I am excited to announce that Analytics Vidhya has launched two brand new practice problems for both machine learning and deep learning enthusiasts and experts. We have also added three new courses to our burgeoning training portal. These courses cover a variety of challenges machine learning folks will find useful. We believe in providing only top class content for our community and our trainings, hackathons, articles and practice problems reflect that commitment. Let¡¯s look at these practice problems and training courses in a bit more detail. Analytics Vidhya¡¯s practice problems bring out the data scientist within you. Our collection of practice problems span varying domains <U+2013> performing sentiment analysis, building recommendation systems, prediction loan default, identifying digits from images, estimating the age of Indian actors, among a whole host of other challenges. We are excited to launch two new practice problems: This is an intriguing computer vision problem which has been recently gained a lot of traction in the deep learning community. The dataset we are providing for this is called ¡®Fashion MNIST¡¯. It¡¯s inspired from MNIST, a very popular dataset in the machine learning community (you can check out the MNIST practice problem in our<U+00A0>¡®Identify the digits¡¯<U+00A0>challenge). In ¡®Identify the apparels¡¯, instead of digits the images show a type of apparel, e.g. tee-shirt, trousers, bag, etc. The dataset used in this problem was created by Zalando Research. This practice problem is meant for beginners in deep learning. Intermediate or experts in this field can also work on this to refresh their concepts. This is quite a unique practice problem.<U+00A0>You are challenged with predicting the ratings for jokes given by the users provided the ratings provided by the same users for another set of jokes. This dataset has been taken from the famous jester online Joke Recommender system dataset. This practice problem is meant for everyone in the machine learning field <U+2013> from beginners to experts. I recommend getting familiar with recommendation systems to get the most from this challenge. Analytics Vidhya¡¯s aim has always been to build and help data scientists all over the globe by providing top notch training resources. So, we have expanded our training catalogue exponentially this year. We launched the ¡®Introduction to Data Science¡® course which has quickly become our most popular training. We also have trainings on Excel and problem solving using data, and of course a comprehensive learning path to become a data scientist. We have recently added three more exciting trainings to this list! Time Series forecasts come in handy for creating simple forecasts like number of airline passengers, website traffic, etc. This course is a comprehensive guide to getting you started in this vast and intriguing domain. Time Series forecasting is a skill every data scientist should have in their skillset so ensure you take this course! This course is meant for newcomers in data science and machine learning. Predicting the sales of a business is one of the most common challenges in this field and this course will give you a very good idea of how to approach this challenge. This course will equip you with the skills and techniques required for solving a regression problem in R. This course is designed for people who want to learn how to solve binary classification problems. In this course, you will solve a real life case study of Dream Housing Finance. The company wants to automate the loan eligibility process (real-time) based on the customer details provided through an online application form. By the end of the course, you will have a solid understanding of classification problems and various approaches to solve them."
"vidhya",2018-07-05,"Using the Power of Deep Learning for Cyber Security","https://www.analyticsvidhya.com/blog/2018/07/using-power-deep-learning-cyber-security/","The majority of the deep learning applications that we see in the community are usually geared towards fields like marketing, sales, finance, etc. We hardly ever read articles or find resources about deep learning being used to protect these products, and the business, from malware and hacker attacks. While the big technology companies like Google, Facebook, Microsoft, and Salesforce have already embedded deep learning into their products, the cybersecurity industry is still playing catch up.<U+00A0>It¡¯s a challenging field but one that needs our full attention. In this article, we briefly introduce Deep Learning (DL) along with a few existing Information Security (hereby referred to as InfoSec) applications it enables. We then deep dive into the interesting problem of anonymous tor traffic detection and also present a DL-based solution to detect TOR traffic. The target audience for this article is data science professionals who are already working on machine learning projects. The content of this article assumes that you have foundation knowledge of machine learning and are currently either a beginner, or are exploring, deep learning and it¡¯s use cases. The below pre-reads are highly recommended to get the most out of this article: Deep learning is not a silver bullet that can solve all the InfoSec problems because it needs extensive labeled datasets. Unfortunately, no such labeled datasets are readily available. However, there are several InfoSec use cases where the deep learning networks are making significant improvements to the existing solutions. Malware detection and network intrusion detection are two such areas where deep learning has shown significant improvements over the rule-based and classic machine learning-based solutions. Network intrusion detection systems are typically rule-based and signature-based controls that are deployed at the perimeter to detect known threats. Adversaries change the malware signatures and easily evade the traditional network intrusion detection systems. Quamar et al. [1], in their IEEE transaction paper, showed deep learning (DL)-based systems using self-taught learning to be promising in detecting unknown network intrusions. Traditional security use cases such as malware detection and spyware detection have been tackled with deep neural net-based systems [2]. The generalization power of DL-based techniques is better compared to traditional ML-based approaches. Jung et al.¡¯s [3] DL based system can even detect zero-day malware. Daniel Gibert [2], a Ph.D. graduate from the University of Barcelona, has done extensive work related to convolutional neural networks (CNN, a type of DL architecture) and malware detection. In his Ph.D. thesis, he says that CNNs can detect even polymorphic malware. The DL-based neural nets are now getting used in User and Entity Behaviour Analytics (UEBA). Traditionally, UEBA employs anomaly detection and machine learning algorithms which distill the security events to profile and baseline every user and network element in the enterprise IT environment. Any significant deviations from the baselines were triggered as anomalies that further raised alerts to be investigated by the security analysts. UEBA enhanced the detection of insider threats, albeit to a limited extent. Now, deep learning-based systems are used to detect many other types of anomalies. Pawe©© Kobojek from Warsaw university, Poland [4] uses keystroke dynamics to verify the user using an LSTM network. Jason Trost, director of security data engineering at Capital One, has published several blogs [5] that have a list of technical papers and talks on applying deep learning in InfoSec. The artificial neural network is inspired from the biological neural network. Neurons are the atomic unit of a biological neural network. Each neuron consists of dendrites, nucleus, and axons. It receives signals through dendrites and is carried out through axons (Figure 1 below). The computations are performed in the nucleus. The entire network is made up of a chain of neurons. AI researchers borrowed this idea to develop the artificial neural network (ANN). In this setting, each neuron accomplishes three actions: Each neuron thus can classify whether a set of inputs belong to one class or another. This power is limited when only a single neuron is used. However, coining a set of neurons makes it a powerful machinery for classification and sequence labelling tasks. Figure 1: Greatest inspiration that we can get is from the nature <U+2013> figure depicts a biological neuron and an artificial neuron. A set of neuron layers can be used to create a neural network. The network architecture differs based on the objective it needs to achieve. A common network architecture is a Feed Forward Neural Network (FFN). Neurons are arranged linearly without any cycles to form a FFN. It is called feed forward because information travels in the forward direction inside the network, first through the input neurons layer, then through the hidden neuron layers, and the output neurons layer (Figure 2 below). Figure 2: A feed forward network with two hidden layers  Like any supervised machine learning model, the FFN needs to be trained using labeled data. The training is in the form of optimizing the parameters by reducing the error between the output value and the true value. One such important parameter to optimize is the weight each neuron gives to each of its input signals. For a single neuron, the weight can be easily computed using the error. However, when a set of neurons are collated in multiple layers, it is challenging to optimize the neuron weights in multiple layers based on the error computed at the output layer. The backpropagation algorithm helps to address this issue [6]. Backpropagation is an old technique which comes under the branch of computer algebra. Here, automatic differentiation is used<U+00A0>to calculate the<U+00A0>gradient<U+00A0>that is needed in the calculation of the<U+00A0>weights<U+00A0>to be used in the network. In a<U+00A0>FFN, based on activation of each linked neuron, the output is obtained. The error is propagated layer by layer. Based on the correctness of the output with the final outcome, the error is calculated. This error is then in turn back propagated to fix errors of internal neurons. For each data instance, the parameters are optimized by going through multiple iterations.  The primary goal of cyber-attacks is to steal the enterprise customer data, sales data, intellectual property documents, source codes and software keys. The adversaries exfiltrate the stolen data to remote servers in encrypted traffic along with the regular traffic. Most often adversaries use an anonymous network that makes it difficult for the security defenders to trace the traffic. Moreover, the exfiltrated data is typically encrypted, rendering rule-based network intrusion tools and firewalls to be ineffective. Recently, anonymous networks have also been used for C&C by specific variants of ransomware/malware. For instance, Onion Ransomware [7] uses the TOR network to communicate with its C&C. Figure 3: An illustration of TOR communication between Alice and a destination server. The communication starts with Alice requesting a path to the server. TOR network gives the path which is AES encrypted. The randomization of the path happens inside the TOR network. The encrypted path of the packet is shown in red. Upon reaching the exit node, which is the periphery node of the TOR network, the plain packet is transferred to the server.  Anonymous network/traffic can be accomplished through various means. They can be broadly classified into: Among them, TOR is one of the more popular choices. TOR is a free software that enables anonymous communication over the internet through a specialized routing protocol known as the onion routing protocol [9]. The protocol depends on redirecting internet traffic over various freely hosted relays across the world. During the relay, like the layers of an onion peel, each HTTP packet is encrypted using the public key of the receiver. At each receiver point, the packet can be decrypted using the private key. Upon decryption, the next destination relay address is revealed. This carries on until the exit node of the TOR network is met, where the decryption of the packet ends, and a plain HTTP packet is forwarded to the original destination server. An example routing scheme between Alice and the server is depicted in the above Figure 3 for illustration.  The original intent of launching TOR was to safeguard the privacy of users. However, adversaries have hijacked the good Samaritan objective to use it for various nefarious means instead. As of 2016, around 20% of the Tor traffic accounts for illegal activities. In an enterprise network, TOR traffic is curtained by not allowing the installation of the TOR client or blocking the Guard or Entry node IP address. However, there are numerous means through which adversaries and malware can get access to the TOR network to transfer data and information. The IP blocking strategy is not a sound strategy. Adversaries can spawn different IPs to carry out the communication. A bad bot landscape report by distil networks [5] shows that 70% of automated attacks in 2015 used multiple IPs, and 20% of automated attacks used over 100 IPs. TOR traffic can be detected by analyzing the traffic packets. This analysis can be on the TOR node, or in between the client and the entry node. The analysis is done on a single flow of packet. Each flow constitutes a tuple of source address, source port, destination address, and destination port. Network flows for different time intervals are extracted and analysis is carried on them. G. He et al. in their paper ¡°Inferring Application Type Information from Tor Encrypted Traffic¡± extracted burst volumes and directions to create a HMM model to detect the TOR applications that might be generating that traffic. Most of the popular works in this area leverage time-based features along with other features like size and port information<U+00A0>to detect TOR traffic. We take inspiration from Habibi et al¡¯s ¡°<U+00A0>Characterization of Tor Traffic using Time based Features¡± paper and follow a time-based approach over extracted network flow to detect TOR traffic for this article. However, our architecture uses a plethora of other meta-information that can be obtained to classify the traffic. This is inherently due to the Deep Learning architecture that has been chosen to solve this problem. We obtained the data from Habibi Lashkari et al. [11] at the University of<U+00A0>New Brunswick<U+00A0>for the data experiments done in this article. Their data consists of features extracted from the analysis of the university internet traffic. Extracted meta information from the data is given in the table below: Table 1: Meta information parameters obtained from [1] Apart from these parameters, other flow-based parameters are also included. A sample instance from the dataset is shown in Figure 4 below: Figure 4: An instance of the dataset used for this article. Please note that source IP/port and destination IP/port, along with the protocol field, have been removed from the instance as they overfit the model. We process all other features using a deep feed forward neural network with N hidden layers. The architecture of the neural network is shown in Figure 5 below. Figure 5: Deep learning network representation used for TOR traffic detection. The hidden layers vary between 2 to 10. We found N=5 to be optimal. For activation, Relu is used for all the hidden layers. Each layer of the Hidden layers is dense in nature and of dimension 100. Figure 6: A Python Code Snippet of the FFN in Keras.  The output node is activated by a sigmoid function. This was used as the output is a binary classification <U+2013> Tor or Non-Tor.  We used<U+00A0>Keras with Tensorflow in the backend to train the DL module. Binary cross entropy loss was used for optimizing the FFN. <U+00A0>The model was trained for different epochs. Figure 7 below shows training simulation for a run depicting the increasing performance and decreasing loss value as the number of epochs increase. Figure 7: Tensorboard generated statics depicting the network training process The results of the deep learning system were compared with various other estimators. Standard classification metrics of Recall, Precision and F-Score were used to measure the efficacy of the estimators. Our DL-based system was able to detect the TOR class well. However, it is the Non-Tor class that we need to give more importance to. It is seen that a Deep Learning-based system can reduce the false positive cases for Non-Tor category samples. The results are shown in the table below: Table 2: The output of ML and DL Models for the Tor Traffic Detection experiment Among various classifiers, Random Forest and Deep learning based approaches perform better than the rest. The result shown is based on 55,000 training instances. The dataset used in this experiment is comparatively smaller than typical DL-based systems. As the training data increases, performance would increase further for both DL-based and Random forest classifier. However, for large datasets, a DL-based classifier typically outperforms other classifiers, and it can be generalised for similar types of applications. For example, if one needs to train a classifier to detect the application used by TOR, then only the output layer needs retraining, and all the other layers can be kept the same. Whereas other ML-classifiers will need to be retrained for the entire dataset. Keep in mind that retraining the model may take significant computing resources for large datasets. Anonymized traffic detection is a nuanced challenge that every enterprise faces. The adversaries use TOR channels to exfiltrate data in anonymous mode. Current approaches by tor traffic detection vendors depend on blocking known entry nodes of the TOR network. This is not a scalable approach and can be easily bypassed. A generic method is to use deep learning-based techniques. In this article, we presented a deep learning-based system to detect the TOR traffic with high recall and precision. Let us know your take on the current state of deep learning, or if you have any alternate approaches, in the comments section below. Dr. Satnam Singh, Chief Data Scientist <U+2013> Acalvio Technologies Dr Satnam Singh is currently leading security data science development at Acalvio Technologies. He has more than a decade of work experience in successfully building data products from concept to production in multiple domains. In 2015, he was named as one of the top 10 data scientists in India.<U+00A0> To his credit, he has 25+ patents and 30+ journal and conference publications. Apart from holding a PhD degree in ECE from University of Connecticut, Satnam also holds a Masters in ECE from University of Wyoming. Satnam is a senior IEEE member and a regular speaker in various Big Data and Data Science conferences. Balamurali A R, Member Technical Staff (Data Science) at Acalvio Balamurali A R is a member of the data science team at Acalvio. He is a graduate from IIT Mumbai, holds a Ph.D in Computer Science and has previously worked with companies like Samsung and IBM."
"vidhya",2018-07-02,"The Top GitHub Repositories & Reddit Threads Every Data Scientist should know (June 2018)","https://www.analyticsvidhya.com/blog/2018/07/top-github-reddit-data-science-machine-learning-june-2018/","Half the year has flown by and that brings us to the June edition of our popular series <U+2013> the top GitHub repositories and Reddit threads from last month. During the course of writing these articles, I have learned so much about machine learning from either open source codes or invaluable discussions among the top data science brains in the world. What makes GitHub special is not just it¡¯s code hosting and social collaboration features for data scientists. It has lowered the entry barrier into the open source world and has played a MASSIVE role in spreading knowledge and expanding the machine learning community. We saw some amazing open source code being released in June. One of the most intriguing repositories was ¡®NLP Progress¡¯ <U+2013> created with the aim of keeping everyone updated regarding the latest updates in this field. Facebook also released the code for it¡¯s popular DensePose framework which could be a game changer in the pose estimation field. When it comes to Reddit, it is so rich in knowledge and perspective from data scientists and ML experts from around the globe. In this article you¡¯ll see discussions on reinforcement learning applications, machine learning setups, a wonderful computer vision example, and much more. I highly recommend participating in this discussions to enhance your skillset. You can check out the top GitHub repositories and top Reddit discussions (from April onwards) for the last five months below: Human pose estimation has garnered a lot of attention in the deep learning community this year. And Facebook took things to a new level when they open sourced the code to ¡®DensePose¡¯, their popular pose estimation framework. This technique identifies more than 5000 nodes in the human body (for context, other approaches operate with 10 or 20 joints). You can get an idea of this node mapping technique in the above image. DensePose has been created in the Detectron framework and is powered by Caffe2. Apart from the code, this repository also contains notebooks to visualize the DensePose-COCO dataset. Read more details about this release here. Natural Language Processing (NLP) is an often difficult field to get into, despite it¡¯s attractions. There is tons of unstructured text lying around which you have to work with, and that is no easy task. This repository has been created especially to track the progress in the NLP field. It¡¯s a very informative list of datasets and current state-of-the-art tasks, like dependency parsing, part-of-speech tagging, reading comprehension, etc. Make sure you star this and follow the progress if you¡¯re even vaguely interested in NLP. There is still a lot that can (and will) be added to this list, like information extraction, relation extraction, grammatical error correction, etc. If you have anything to contribute to this repository, the creator is open to ideas and suggestions so feel free to do that. Getting your model into production is one of the biggest challenges data scientists face when they enter this field. Designing and building the model is what attracts most people to machine learning but if you can¡¯t get that model into production, it essentially becomes just a piece of useless code. So Databricks (founded by the Apache Spark creators) decided to build and open source a solution to all ML framework challenges. Called MLflow, it is a platform that manages the entire machine learning lifecycle (from start to production) and has been designed to work with any library. Ever since it¡¯s release, it has gained a huge following (1,355 stars on GitHub) and you can check out our coverage of the library here. Another NLP entry in this article! When it comes to NLP tasks like sentiment analysis, or machine translation, the norm has been to build models specific to that task. Have you ever built a sentiment analysis model that can also do semantic parsing and question answering at the same time? That¡¯s what Salesforce researchers intend to do with this repository. They have published a research paper that outlines a model which can do 10 different NLP tasks at the same time. In this paper, they have thrown a chalenge (which they are calling decaNLP) to the community <U+2013> can you build such a model and improve on the approach they¡¯ve provided? The model Salesforce have built is being called the ¡°Swiss Army Knife for Natural Language Processing¡±. Read more details about this on AV¡¯s post here. Reinforcement learning is becoming popular by the day and so is the open source community for it. This repository is a collection of reinforcement learning algorithms from Richard Sutton and Andrew Barto¡¯s book and other research papers. These algorithms are presented in the form pf Python notebooks. The creator of the repository recommends using these notebooks when you read the book as they will significantly enhance your understand of what¡¯s being presented. The notes are detailed and anyone entering this field should definitely refer to this collection. Source: Wikipedia Your interest in this thread will be piqued by the above video, which is put together and presented really neatly. It sent the machine learning subreddit into overdrive and received almost 100 comments! The thread has a lot of useful information on how the technique was created (there¡¯s a step-by-step explanation from the developer), how long it took, what kind of other things it can do, etc. You¡¯ll learn a lot about computer vision in this thread. The creator of this technique and video has also open sourced his code on GitHub. So open your Jupyter notebooks and get cracking! OpenAI Five is a group of 5 neural networks designed and developed to beat human opponents in the popular Dota 2 game. It has been developed by the Elon Musk co-founded OpenAI venture, which explains the immediate popularity it has received since it¡¯s release. Why I¡¯m recommending this thread is the rich discussion around what else data scientists want to see from this technique, it¡¯s comparison with the popular DeepMind AlphaGo algorithm, and how much computational power it required to pull this off. There is a lot of perspective in this thread that will greatly benefit you. Additionally, you can also read our article on OpenAI Five here. If this topic didn¡¯t get your attention, the first few comments surely will. This discussion is like a wish list of what data scientists and machine learning practitioners want to see from the community. This thread made my list because of the discussion each idea spawned. Once a person added their idea to the thread, multiple folks replied with their ideas on how to implement it and if similar research was already present. This is a MUST-READ discussion <U+2013> for both enthusiasts and practitioners. Take some time out to go through it and you¡¯ll come out with a lot of knowledge (and perhaps even more questions). What hardware you use for machine learning plays a critical role in determining how good your model will perform, especially when the amount of data to be trained is huge. Read this thread to find out what other data scientists use for building their ML processes and models. The original poster has listed down a structured list of questions which helped keep the thread neat and understandable. There questions are as below: You can also take part in the discussion or use the comments section below this article to let us know your setup! As I mentioned above, reinforcement learning is a popular field these days. But due to the complex nature of the work, most of the research and use cases are limited to games and lab environments. In this thread, people already working in this field give their take on where they see RL penetrating in the near future. Some of the comments are of a more skeptical nature but are worth reading to understand what experts and enthusiasts feel about RL."
"vidhya",2018-06-28,"Understanding and Building an Object Detection Model from Scratch in Python","https://www.analyticsvidhya.com/blog/2018/06/understanding-building-object-detection-model-python/","When we¡¯re shown an image, our brain instantly recognizes the objects contained in it. On the other hand, it takes a lot of time and training data for a machine to identify these objects. But with the recent advances in hardware and deep learning, this computer vision field has become a whole lot easier and more intuitive. Check out the below image as an example. The system is able to identify different objects in the image with incredible accuracy. Object detection technology has seen a rapid adoption rate in various and diverse industries. It helps self-driving cars safely navigate through traffic, spots violent behavior in a crowded place,<U+00A0> assists sports teams analyze and build scouting reports, ensures proper quality control of parts in manufacturing, among many, many other things. And these are just scratching the surface of what object detection technology can do! In this article, we will understand what object detection is and look at a few different approaches one can take to solve problems in this space. Then we will deep dive into building our own object detection system in Python. By the end of the article, you will have enough knowledge to take on different object detection challenges on your own! Note: This tutorial assumes that you know the basics of deep learning and have solved simple image processing problems before. In case you haven¡¯t, or need a refresher, I recommend reading the following articles first: Before we dive into build a state-of-the-art model, let us first try to understand what object detection is. Let¡¯s (hypothetically) build a pedestrian detection system for a self-driving car. Suppose your car captures an image like the one below. How would you describe this image? The image essentially depicts that our car is near a square, and a handful of people are crossing the road in front of our car. As the traffic sign is not clearly visible, the car¡¯s pedestrian detection system should identify exactly where the people are walking so that we can steer clear of them. So what can the car¡¯s system do to ensure this happens? What it can do is create a bounding box around these people, so that the system can pinpoint where in the image the people are, and then accordingly make a decision as to which path to take, in order to avoid any mishaps. Our objective behind doing object detection is two folds: Now that we know what our problem statement is, what can be a possible approach (or multiple approaches) to solve it? In this section, we¡¯ll look at a few techniques that can be used to detect objects in images. We will start from the simplest approach and find our way up from there. If you have any suggestions or alternate approaches to the ones we will see below, do let me know in the comments section! The simplest approach we can take is to divide the image into four parts: Now the next step is to feed each of these parts into an image classifier. This will give us an output of whether that part of the image has a pedestrian or not. If yes, mark that patch in the original image. The output will be somewhat like this: This is a good approach to try out first, but we are looking for a much more accurate and precise system. It needs to identify the entire object (or a person in this case) because only locating parts of an object could lead to catastrophic results. The previous system worked well but what else can we do? We can improve upon it by exponentially increasing the number of patches we input into the system. This is how our output should look like: This ended up being a boon and a curse. Of course our solution seems a bit better than the naive approach, but it is riddled with so many bounding boxes which approximate the same thing. This is an issue, and we need a more structured way to solve our problem. In order to build our object detection system in a more structured way, we can follow the below steps: Step 1:<U+00A0>Divide the image into a 10¡¿10 grid like this: Step 2:<U+00A0>Define the centroids for each patch Step 3:<U+00A0>For each centroid, take three different patches of different heights and aspect ratio: Step 4:<U+00A0>Pass all of the patches created through the image classifier to get predictions So how does the final output look like? A bit more structured and disciplined for sure <U+2013> take a look below: But we can further improve on this! Read on to see yet another approach that will produce even better results. The previous approach we saw is acceptable to quite a good degree, but we can build a system a little more efficient than that. Can you suggest how? Off the top of my mind, I can propose an optimization. If we think about approach #3, we can do two things to make our model better. This again, has its pros and cons. Sure both of the methods will help us go to a more granular level. But it will again create an explosion of all the patches that we have to pass through our image classification model. What we can do is, take selective patches instead of taking all of them. For example, we could build an intermediate classifier which tries to predict if the patch actually has background, or potentially contains an object. This would exponentially decrease the patches that our image classification model has to see. One more optimization that we can do, is to decrease the predictions which say the ¡°same thing¡±. Let¡¯s take the output of approach 3 again: As you can see, both the bounding box predictions are basically of the same person. We have an option to choose any one of them. So to make predictions, we consider all the boxes which ¡°say the same thing¡± and then pick whichever one has the most probability of detecting a person. All of these optimizations have so far given us pretty decent predictions. We almost have all the cards in our hands, but can you guess what is missing? Deep Learning of course! Deep learning has so much potential in the object detection space. Can you recommend where and how can we leverage it for our problem? I have listed a couple of methodologies below: Now instead of training different neural networks for solving each individual problem, we can take a single deep neural network model which will attempt to solve all the problems by itself. The advantage of doing this, is that each of the smaller components of a neural network will help in optimizing the other parts of the same neural network. This will help us in jointly training the entire deep model. Our output would give us the best performance out of all the approaches we have seen so far, somewhat similar to the image below. We will see how to create this using Python in the next section. Now that we know what object detection is and the best approach to solve the problem, let¡¯s build our own object detection system! We will be using ImageAI, a python library which supports state-of-the-art machine learning algorithms for computer vision tasks. Running an object detection model to get predictions is fairly simple. We don¡¯t have to go through complex installation scripts to get started. We don¡¯t even need a GPU to generate predictions! We will use this ImageAI library to get the output prediction we saw above in approach #5. I highly recommend following along with the code below (on your own machine) as this will enable you to gain the maximum knowledge out of this section. Please note that you need to set up your system before creating the object detection model. Once you have Anaconda installed in your local system, you can get started with the below steps. Step 1: Create an Anaconda environment with python version 3.6. Step 2: Activate the environment and install the necessary packages. Step 3: Then install the ImageAI library. Step 4: Now download the pretrained model required to generate predictions. This model is based on RetinaNet (a subject of a future article). Click on the link to download <U+2013><U+00A0>RetinaNet Pretrained model<U+00A0> Step 5: Copy the downloaded file to your current working folder Step 6: Download the image from this link. Name the image as image.png Step 7: Open jupyter notebook (type jupyter notebook in your terminal) and run the following codes: This will create a modified image file named image_new.png, which contains the bounding box for your image. Step 8: To print the image use the following code: Congratulations! You have created your own object detection model for pedestrian detection. How awesome is that? In this article, we learned what is object detection, and the intuition behind creating an object detection model. We also saw how to build this object detection model for pedestrian detection using the ImageAI library. By just tweaking the code a bit, you can easily transform the model to solve your own object detection challenges. If you do solve such a problem using the approach above, especially for a social cause, do let me know in the comments below! Really nice article wanted this and its is simple..
Keep doing the great work The second and the third link before the table of contents are pointing to the same page. Hi Vaibhav, Thanks for bringing this to our notice. The links have been updated. you didnt tell about other packages using in that code ,many errors are coming for it Hi Abhihek, Can you please tell us what error are you getting? That would help us to clarify your doubt in a better way. Hi Pulkit,
I am implementing the above code using jupyter notebook . I have gone through all the steps mentioned above but when i executed the above code,i got an error saying ¡°no module named imageai¡± Hi Rajat, The code given in the article is to run in the script. If you want to do any modification to it, like if you want to use it in jupyter notebook, you first have to install jupyter notebook in the same environment. So, once all the installations are done including jupyter notebook in same environment, run the code. It will work. Try this in a cell of your jupyter notebook: !pip install https://github.com/OlafenwaMoses/ImageAI/releases/download/2.0.1/imageai-2.0.1-py3-none-any.whl For the model download, in another cell:
import urllib.request
url = ¡°https://github.com/OlafenwaMoses/ImageAI/releases/download/1.0/resnet50_coco_best_v2.0.1.h5¡±
file_name = ¡°resnet50_coco_best_v2.0.1.h5¡±
urllib.request.urlretrieve(url, file_name) For the image download, I used this: import urllib.request
url = ¡°https://orig00.deviantart.net/f170/f/2013/087/e/0/wizards_of_waverly_place_png_by_ivygo-d5zjoqx.png¡±
file_name = ¡°image.png¡±
urllib.request.urlretrieve(url, file_name) And i got a good result, but 7 people instead of 6. However, great work Rajat, thank you. Hi ,
As above mentioned i have done with every
when i executing getting ¡± No Module Named imageai¡±
Kindly give me the solutions Hi Suryam, The steps have been updated. Please go through them and run the steps again."
